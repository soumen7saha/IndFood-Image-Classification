{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using ResNet152"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Setting GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:00:59.173381Z",
     "iopub.status.busy": "2025-12-28T16:00:59.161870Z",
     "iopub.status.idle": "2025-12-28T16:01:08.440742Z",
     "shell.execute_reply": "2025-12-28T16:01:08.438981Z",
     "shell.execute_reply.started": "2025-12-28T16:00:59.173381Z"
    },
    "id": "z2M0QAc8lM6L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.442770Z",
     "iopub.status.busy": "2025-12-28T16:01:08.442770Z",
     "iopub.status.idle": "2025-12-28T16:01:08.451394Z",
     "shell.execute_reply": "2025-12-28T16:01:08.449355Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.442770Z"
    },
    "id": "sUJ2veuxq87G"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.452398Z",
     "iopub.status.busy": "2025-12-28T16:01:08.452398Z",
     "iopub.status.idle": "2025-12-28T16:01:08.465094Z",
     "shell.execute_reply": "2025-12-28T16:01:08.463972Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.452398Z"
    },
    "id": "gcUvLHOqlgrI"
   },
   "outputs": [],
   "source": [
    "# /content/drive/MyDrive/M9/cp/indfood-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.468105Z",
     "iopub.status.busy": "2025-12-28T16:01:08.467092Z",
     "iopub.status.idle": "2025-12-28T16:01:08.483690Z",
     "shell.execute_reply": "2025-12-28T16:01:08.481672Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.468105Z"
    },
    "id": "yhhYvJP9lkPb",
    "outputId": "4c21fdcf-d4fc-4b80-a1b8-c416d780f9ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1+cu126'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.485800Z",
     "iopub.status.busy": "2025-12-28T16:01:08.484796Z",
     "iopub.status.idle": "2025-12-28T16:01:08.564367Z",
     "shell.execute_reply": "2025-12-28T16:01:08.562165Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.485800Z"
    },
    "id": "ZzuB4xXGlj7U",
    "outputId": "70610007-b0a4-4be0-a77e-e34d0681209e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.566536Z",
     "iopub.status.busy": "2025-12-28T16:01:08.565429Z",
     "iopub.status.idle": "2025-12-28T16:01:08.574804Z",
     "shell.execute_reply": "2025-12-28T16:01:08.572785Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.566536Z"
    },
    "id": "UgcoNnAEljWu"
   },
   "outputs": [],
   "source": [
    "# models.resnet152(weights='IMAGENET1K_V2')\n",
    "# models.convnext_small(weights='IMAGENET1K_V1')\n",
    "# models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "# models.mobilenet_v2(weights='IMAGENET1K_V2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading & Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.576912Z",
     "iopub.status.busy": "2025-12-28T16:01:08.575916Z",
     "iopub.status.idle": "2025-12-28T16:01:08.590118Z",
     "shell.execute_reply": "2025-12-28T16:01:08.587994Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.576912Z"
    },
    "id": "of6zV-9gljKm"
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: i for i,cls in enumerate(self.classes)}\n",
    "\n",
    "        for label_name in self.classes:\n",
    "            label_dir = os.path.join(data_dir, label_name)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.592066Z",
     "iopub.status.busy": "2025-12-28T16:01:08.591111Z",
     "iopub.status.idle": "2025-12-28T16:01:08.601096Z",
     "shell.execute_reply": "2025-12-28T16:01:08.600782Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.592066Z"
    },
    "id": "vp10h51AliOh"
   },
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "\n",
    "# ImageNet Normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms - just resize and normalize\n",
    "train_transforms = transforms.Compose([\n",
    "    # transforms.Resize((input_size, input_size))\n",
    "    transforms.RandomRotation(15),           # Rotate up to 10 degrees\n",
    "    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),  # Zoom\n",
    "    transforms.RandomHorizontalFlip(),       # Horizontal flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:08.601096Z",
     "iopub.status.busy": "2025-12-28T16:01:08.601096Z",
     "iopub.status.idle": "2025-12-28T16:01:09.377742Z",
     "shell.execute_reply": "2025-12-28T16:01:09.375619Z",
     "shell.execute_reply.started": "2025-12-28T16:01:08.601096Z"
    },
    "id": "my34RRe26bf4"
   },
   "outputs": [],
   "source": [
    "train_dataset = FoodDataset(\n",
    "    data_dir='../data/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = FoodDataset(\n",
    "    data_dir='../data/val',\n",
    "    transform=val_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.379740Z",
     "iopub.status.busy": "2025-12-28T16:01:09.378725Z",
     "iopub.status.idle": "2025-12-28T16:01:09.406554Z",
     "shell.execute_reply": "2025-12-28T16:01:09.406554Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.379740Z"
    },
    "id": "D2rOPgGG6MP-"
   },
   "outputs": [],
   "source": [
    "total_train_len = len(train_dataset)\n",
    "total_val_len = len(val_dataset)\n",
    "\n",
    "# Define the length of the smaller dataset you want to use\n",
    "subset_train_len = 25000\n",
    "subset_val_len = 6000\n",
    "\n",
    "# Define the lengths for the split: [desired_length, remaining_length]\n",
    "train_lengths = [subset_train_len, total_train_len - subset_train_len]\n",
    "val_lengths = [subset_val_len, total_val_len - subset_val_len]\n",
    "\n",
    "# Randomly split the original dataset into two new datasets, You get a list of datasets; take the first one [0]\n",
    "smaller_train_dataset = random_split(train_dataset, train_lengths)[0]\n",
    "smaller_val_dataset = random_split(val_dataset, val_lengths)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.406554Z",
     "iopub.status.busy": "2025-12-28T16:01:09.406554Z",
     "iopub.status.idle": "2025-12-28T16:01:09.416173Z",
     "shell.execute_reply": "2025-12-28T16:01:09.416173Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.406554Z"
    },
    "id": "EKd3tzd9l-PB"
   },
   "outputs": [],
   "source": [
    "# Create the DataLoader with the smaller, randomly split dataset\n",
    "train_loader = DataLoader(smaller_train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(smaller_val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.416173Z",
     "iopub.status.busy": "2025-12-28T16:01:09.416173Z",
     "iopub.status.idle": "2025-12-28T16:01:09.436771Z",
     "shell.execute_reply": "2025-12-28T16:01:09.436771Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.416173Z"
    },
    "id": "sw1SRNGCl-DB",
    "outputId": "bd20a63a-fdb2-48f8-e8ea-501510587848"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aloo_gobi',\n",
       " 'aloo_matar',\n",
       " 'aloo_methi',\n",
       " 'aloo_paratha',\n",
       " 'aloo_shimla_mirch',\n",
       " 'aloo_tikki',\n",
       " 'amritsari_kulcha',\n",
       " 'anda_curry',\n",
       " 'ariselu',\n",
       " 'balushahi',\n",
       " 'banana_chips',\n",
       " 'bandar_laddu',\n",
       " 'basundi',\n",
       " 'besan_laddu',\n",
       " 'bhindi_masala',\n",
       " 'biryani',\n",
       " 'boondi',\n",
       " 'boondi_laddu',\n",
       " 'butter_chicken',\n",
       " 'chaas',\n",
       " 'chak_hao_kheer',\n",
       " 'cham_cham',\n",
       " 'chana_masala',\n",
       " 'chapati',\n",
       " 'chicken_pizza',\n",
       " 'chicken_razala',\n",
       " 'chicken_tikka',\n",
       " 'chicken_tikka_masala',\n",
       " 'chicken_wings',\n",
       " 'chikki',\n",
       " 'chivda',\n",
       " 'chole_bhature',\n",
       " 'daal_baati_churma',\n",
       " 'daal_puri',\n",
       " 'dabeli',\n",
       " 'dal_khichdi',\n",
       " 'dal_makhani',\n",
       " 'dal_tadka',\n",
       " 'dharwad_pedha',\n",
       " 'dhokla',\n",
       " 'double_ka_meetha',\n",
       " 'dum_aloo',\n",
       " 'falooda',\n",
       " 'fish_curry',\n",
       " 'gajar_ka_halwa',\n",
       " 'garlic_bread',\n",
       " 'gavvalu',\n",
       " 'ghevar',\n",
       " 'grilled_sandwich',\n",
       " 'gujhia',\n",
       " 'gulab_jamun',\n",
       " 'hara_bhara_kabab',\n",
       " 'idiyappam',\n",
       " 'idli',\n",
       " 'imarti',\n",
       " 'jalebi',\n",
       " 'kachori',\n",
       " 'kadai_paneer',\n",
       " 'kadhi_pakoda',\n",
       " 'kaju_katli',\n",
       " 'kakinada_khaja',\n",
       " 'kalakand',\n",
       " 'karela_bharta',\n",
       " 'khakhra',\n",
       " 'kheer',\n",
       " 'kofta',\n",
       " 'kulfi',\n",
       " 'lassi',\n",
       " 'ledikeni',\n",
       " 'litti_chokha',\n",
       " 'lyangcha',\n",
       " 'maach_jhol',\n",
       " 'makki_di_roti_sarson_da_saag',\n",
       " 'malpua',\n",
       " 'margherita_pizza',\n",
       " 'masala_dosa',\n",
       " 'masala_papad',\n",
       " 'medu_vada',\n",
       " 'misal_pav',\n",
       " 'misi_roti',\n",
       " 'misti_doi',\n",
       " 'modak',\n",
       " 'moong_dal_halwa',\n",
       " 'murukku',\n",
       " 'mysore_pak',\n",
       " 'naan',\n",
       " 'navratan_korma',\n",
       " 'neer_dosa',\n",
       " 'onion_pakoda',\n",
       " 'palak_paneer',\n",
       " 'paneer_masala',\n",
       " 'paneer_pizza',\n",
       " 'pani_puri',\n",
       " 'paniyaram',\n",
       " 'papdi_chaat',\n",
       " 'patrode',\n",
       " 'pav_bhaji',\n",
       " 'pepperoni_pizza',\n",
       " 'phirni',\n",
       " 'pithe',\n",
       " 'poha',\n",
       " 'pongal',\n",
       " 'poornalu',\n",
       " 'pootharekulu',\n",
       " 'puri_bhaji',\n",
       " 'qubani_ka_meetha',\n",
       " 'rabri',\n",
       " 'rajma_chawal',\n",
       " 'ras_malai',\n",
       " 'rasgulla',\n",
       " 'rava_dosa',\n",
       " 'sabudana_khichdi',\n",
       " 'sabudana_vada',\n",
       " 'samosa',\n",
       " 'sandesh',\n",
       " 'seekh_kebab',\n",
       " 'set_dosa',\n",
       " 'sev_puri',\n",
       " 'shankarpali',\n",
       " 'sheer_korma',\n",
       " 'sheera',\n",
       " 'shrikhand',\n",
       " 'soan_papdi',\n",
       " 'solkadhi',\n",
       " 'steamed_momo',\n",
       " 'sutar_feni',\n",
       " 'thali',\n",
       " 'thukpa',\n",
       " 'unni_appam',\n",
       " 'uttapam',\n",
       " 'vada_pav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_dataset.class_to_idx)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.436771Z",
     "iopub.status.busy": "2025-12-28T16:01:09.436771Z",
     "iopub.status.idle": "2025-12-28T16:01:09.449767Z",
     "shell.execute_reply": "2025-12-28T16:01:09.449767Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.436771Z"
    },
    "id": "j2glE4s6TiVi",
    "outputId": "87aa3d24-c62c-4cfa-d471-3b2a8522e50d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114964, 20370)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.449767Z",
     "iopub.status.busy": "2025-12-28T16:01:09.449767Z",
     "iopub.status.idle": "2025-12-28T16:01:09.461089Z",
     "shell.execute_reply": "2025-12-28T16:01:09.461089Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.449767Z"
    },
    "id": "XI96b7RK8YBm",
    "outputId": "6f728ee0-4c21-4007-efc7-1a2621514f59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 6000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smaller_train_dataset), len(smaller_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.464991Z",
     "iopub.status.busy": "2025-12-28T16:01:09.463973Z",
     "iopub.status.idle": "2025-12-28T16:01:09.471893Z",
     "shell.execute_reply": "2025-12-28T16:01:09.471893Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.464991Z"
    },
    "id": "sLgKcE1Yl92T",
    "outputId": "352aee0c-868a-4690-af69-6536eed84bd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.471893Z",
     "iopub.status.busy": "2025-12-28T16:01:09.471893Z",
     "iopub.status.idle": "2025-12-28T16:01:09.492037Z",
     "shell.execute_reply": "2025-12-28T16:01:09.492037Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.471893Z"
    },
    "id": "PpziiDjBl9mx"
   },
   "outputs": [],
   "source": [
    "class FoodClassifierResNet(nn.Module):\n",
    "    def __init__(self, num_classes=131, unfreeze_layers=0):\n",
    "        super(FoodClassifierResNet, self).__init__()\n",
    "\n",
    "        # load pre-trained ResNet-152\n",
    "        self.base_model = models.resnet152(weights='IMAGENET1K_V2')\n",
    "\n",
    "        # Freeze all base model parameters initially\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze specified number of 'layer' blocks from the end\n",
    "        # For ResNet, layer4 is the last convolutional block, then layer3, etc.\n",
    "        # unfreeze_layers=1 -> unfreeze layer4\n",
    "        # unfreeze_layers=2 -> unfreeze layer4, layer3\n",
    "        # unfreeze_layers=3 -> unfreeze layer4, layer3, layer2\n",
    "        # unfreeze_layers=4 -> unfreeze layer4, layer3, layer2, layer1\n",
    "        named_layer_blocks = ['layer4', 'layer3', 'layer2', 'layer1']\n",
    "\n",
    "        for i in range(min(unfreeze_layers, len(named_layer_blocks))):\n",
    "            layer_name = named_layer_blocks[i]\n",
    "            if hasattr(self.base_model, layer_name):\n",
    "                layer = getattr(self.base_model, layer_name)\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        # Extract features (everything up to the adaptive average pooling, excluding the original FC layer)\n",
    "        # The `base_model`'s `avgpool` is included in `features_extractor`.\n",
    "        self.features_extractor = nn.Sequential(\n",
    "            self.base_model.conv1,\n",
    "            self.base_model.bn1,\n",
    "            self.base_model.relu,\n",
    "            self.base_model.maxpool,\n",
    "            self.base_model.layer1,\n",
    "            self.base_model.layer2,\n",
    "            self.base_model.layer3,\n",
    "            self.base_model.layer4,\n",
    "            self.base_model.avgpool # Include the original avgpool\n",
    "        )\n",
    "\n",
    "        # add custom output layer\n",
    "        # The input features to the linear layer will be from the base_model's final feature map size after avgpool\n",
    "        self.output_layer = nn.Linear(self.base_model.fc.in_features, num_classes) # ResNet-152 has 2048 features before FC\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features_extractor(x)\n",
    "        x = torch.flatten(x, 1) # Flatten the (batch_size, 2048, 1, 1) to (batch_size, 2048)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:09.492037Z",
     "iopub.status.busy": "2025-12-28T16:01:09.492037Z",
     "iopub.status.idle": "2025-12-28T16:01:13.615739Z",
     "shell.execute_reply": "2025-12-28T16:01:13.613657Z",
     "shell.execute_reply.started": "2025-12-28T16:01:09.492037Z"
    },
    "id": "_KfXVi0Hl9Wg",
    "outputId": "ec6c2dac-8074-4a8b-a513-c6288ea4b5a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FoodClassifierResNet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (23): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (24): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (25): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (26): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (27): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (28): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (29): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (30): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (31): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (32): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (33): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (34): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (35): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (features_extractor): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (23): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (24): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (25): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (26): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (27): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (28): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (29): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (30): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (31): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (32): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (33): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (34): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (35): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (output_layer): Linear(in_features=2048, out_features=131, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FoodClassifierResNet(num_classes=131)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Learning rate and Unfreezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:13.617781Z",
     "iopub.status.busy": "2025-12-28T16:01:13.616675Z",
     "iopub.status.idle": "2025-12-28T16:01:13.625864Z",
     "shell.execute_reply": "2025-12-28T16:01:13.623735Z",
     "shell.execute_reply.started": "2025-12-28T16:01:13.617781Z"
    },
    "id": "GaQLHPlXmYlt"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:13.626854Z",
     "iopub.status.busy": "2025-12-28T16:01:13.626854Z",
     "iopub.status.idle": "2025-12-28T16:01:13.641514Z",
     "shell.execute_reply": "2025-12-28T16:01:13.639390Z",
     "shell.execute_reply.started": "2025-12-28T16:01:13.626854Z"
    },
    "id": "PIXRwoKWmZr6"
   },
   "outputs": [],
   "source": [
    "# tuning the learning rate and unfreezing layers\n",
    "def make_model(learning_rate=0.01, unfreeze_layers=0, scheduler_step_size=5, scheduler_gamma=0.1):\n",
    "    model = FoodClassifierResNet(num_classes=131, unfreeze_layers=unfreeze_layers)\n",
    "    model.to(device)\n",
    "\n",
    "    # Only optimize parameters that require gradients (unfrozen layers and new head)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n",
    "\n",
    "    # Add a learning rate scheduler\n",
    "    # StepLR decreases the learning rate by a factor of gamma every step_size epochs\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "\n",
    "    return model, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:13.643523Z",
     "iopub.status.busy": "2025-12-28T16:01:13.642464Z",
     "iopub.status.idle": "2025-12-28T16:01:13.659193Z",
     "shell.execute_reply": "2025-12-28T16:01:13.657071Z",
     "shell.execute_reply.started": "2025-12-28T16:01:13.643523Z"
    },
    "id": "CPVft8XxmaAr"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, optimizer, scheduler, train_loader, val_loader, criterion, num_epochs, device):\n",
    "    best_val_accuracy = 0.0  # Initialize variable to track the best validation accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        # Step the learning rate scheduler after each epoch\n",
    "        scheduler.step()\n",
    "\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            checkpoint_path = f'food_resnet_v42_{epoch+1:02d}_{val_acc:.3f}.pth'\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Checkpoint saved: {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-28T16:01:13.661196Z",
     "iopub.status.busy": "2025-12-28T16:01:13.660200Z",
     "iopub.status.idle": "2025-12-30T06:59:09.823982Z",
     "shell.execute_reply": "2025-12-30T06:59:09.822029Z",
     "shell.execute_reply.started": "2025-12-28T16:01:13.661196Z"
    },
    "id": "qJiU5c6cmaM2",
    "outputId": "403eca3e-cdd4-494d-ee6e-f01fbeaf18af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training with Learning Rate: 0.001, Unfrozen Layers: 2 ---\n",
      "Epoch 1/14\n",
      "  Train Loss: 1.2552, Train Acc: 0.6817\n",
      "  Val Loss: 0.8083, Val Acc: 0.7757\n",
      "Checkpoint saved: food_resnet_v42_01_0.776.pth\n",
      "Epoch 2/14\n",
      "  Train Loss: 0.6511, Train Acc: 0.8107\n",
      "  Val Loss: 0.6906, Val Acc: 0.8095\n",
      "Checkpoint saved: food_resnet_v42_02_0.809.pth\n",
      "Epoch 3/14\n",
      "  Train Loss: 0.4858, Train Acc: 0.8541\n",
      "  Val Loss: 0.6814, Val Acc: 0.8132\n",
      "Checkpoint saved: food_resnet_v42_03_0.813.pth\n",
      "Epoch 4/14\n",
      "  Train Loss: 0.3938, Train Acc: 0.8794\n",
      "  Val Loss: 0.5949, Val Acc: 0.8382\n",
      "Checkpoint saved: food_resnet_v42_04_0.838.pth\n",
      "Epoch 5/14\n",
      "  Train Loss: 0.3119, Train Acc: 0.9030\n",
      "  Val Loss: 0.5619, Val Acc: 0.8473\n",
      "Checkpoint saved: food_resnet_v42_05_0.847.pth\n",
      "Epoch 6/14\n",
      "  Train Loss: 0.1426, Train Acc: 0.9577\n",
      "  Val Loss: 0.4562, Val Acc: 0.8815\n",
      "Checkpoint saved: food_resnet_v42_06_0.881.pth\n",
      "Epoch 7/14\n",
      "  Train Loss: 0.0957, Train Acc: 0.9716\n",
      "  Val Loss: 0.4633, Val Acc: 0.8827\n",
      "Checkpoint saved: food_resnet_v42_07_0.883.pth\n",
      "Epoch 8/14\n",
      "  Train Loss: 0.0763, Train Acc: 0.9775\n",
      "  Val Loss: 0.4756, Val Acc: 0.8815\n",
      "Epoch 9/14\n",
      "  Train Loss: 0.0569, Train Acc: 0.9830\n",
      "  Val Loss: 0.4991, Val Acc: 0.8835\n",
      "Checkpoint saved: food_resnet_v42_09_0.883.pth\n",
      "Epoch 10/14\n",
      "  Train Loss: 0.0440, Train Acc: 0.9869\n",
      "  Val Loss: 0.5339, Val Acc: 0.8822\n",
      "Epoch 11/14\n",
      "  Train Loss: 0.0304, Train Acc: 0.9918\n",
      "  Val Loss: 0.5232, Val Acc: 0.8867\n",
      "Checkpoint saved: food_resnet_v42_11_0.887.pth\n",
      "Epoch 12/14\n",
      "  Train Loss: 0.0273, Train Acc: 0.9930\n",
      "  Val Loss: 0.5202, Val Acc: 0.8868\n",
      "Checkpoint saved: food_resnet_v42_12_0.887.pth\n",
      "Epoch 13/14\n",
      "  Train Loss: 0.0248, Train Acc: 0.9941\n",
      "  Val Loss: 0.5272, Val Acc: 0.8848\n",
      "Epoch 14/14\n",
      "  Train Loss: 0.0236, Train Acc: 0.9948\n",
      "  Val Loss: 0.5306, Val Acc: 0.8858\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "# Iterate over different learning rates and also different numbers of unfrozen layers\n",
    "# Example: Try unfreezing the last 1 or 2 convolutional blocks (layer4, layer3)\n",
    "for lr in [0.001, 0.0001]: # Smaller learning rates are often better for fine-tuning unfrozen layers\n",
    "    for unfreeze in [0, 1, 2]: # 0: freeze all base layers, 1: unfreeze layer4, 2: unfreeze layer4 & layer3\n",
    "        print(f\"--- Training with Learning Rate: {lr}, Unfrozen Layers: {unfreeze} ---\")\n",
    "        model, optimizer, scheduler = make_model(learning_rate=lr, unfreeze_layers=unfreeze)\n",
    "        train_and_evaluate(model, optimizer, scheduler, train_loader, val_loader, criterion, num_epochs, device)\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T06:59:09.826122Z",
     "iopub.status.busy": "2025-12-30T06:59:09.825039Z",
     "iopub.status.idle": "2025-12-30T06:59:09.830427Z",
     "shell.execute_reply": "2025-12-30T06:59:09.830427Z",
     "shell.execute_reply.started": "2025-12-30T06:59:09.826122Z"
    },
    "id": "B6_noW_9mYTb"
   },
   "outputs": [],
   "source": [
    "# best lr: 0.001, unfrozen layers: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T06:59:09.830427Z",
     "iopub.status.busy": "2025-12-30T06:59:09.830427Z",
     "iopub.status.idle": "2025-12-30T06:59:09.839139Z",
     "shell.execute_reply": "2025-12-30T06:59:09.839139Z",
     "shell.execute_reply.started": "2025-12-30T06:59:09.830427Z"
    },
    "id": "Pf31lr7MXF1R"
   },
   "outputs": [],
   "source": [
    "# # final training\n",
    "# model, optimizer, scheduler = make_model(learning_rate=xxxxx, unfreeze_layers=yyyyy)\n",
    "# train_and_evaluate(model, optimizer, scheduler, train_loader, val_loader, criterion, num_epochs=50, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T06:59:09.839139Z",
     "iopub.status.busy": "2025-12-30T06:59:09.839139Z",
     "iopub.status.idle": "2025-12-30T06:59:09.846382Z",
     "shell.execute_reply": "2025-12-30T06:59:09.846382Z",
     "shell.execute_reply.started": "2025-12-30T06:59:09.839139Z"
    },
    "id": "OuKQfi20Y525"
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T07:21:57.062201Z",
     "iopub.status.busy": "2025-12-30T07:21:57.062201Z",
     "iopub.status.idle": "2025-12-30T07:21:57.749623Z",
     "shell.execute_reply": "2025-12-30T07:21:57.747056Z",
     "shell.execute_reply.started": "2025-12-30T07:21:57.062201Z"
    },
    "id": "_0TzX_pgYPet"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "            Conv2d-2         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "       BatchNorm2d-4         [-1, 64, 112, 112]             128\n",
      "              ReLU-5         [-1, 64, 112, 112]               0\n",
      "              ReLU-6         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-7           [-1, 64, 56, 56]               0\n",
      "         MaxPool2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9           [-1, 64, 56, 56]           4,096\n",
      "           Conv2d-10           [-1, 64, 56, 56]           4,096\n",
      "      BatchNorm2d-11           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
      "             ReLU-13           [-1, 64, 56, 56]               0\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-16           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-17           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]          16,384\n",
      "           Conv2d-22          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-23          [-1, 256, 56, 56]             512\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "           Conv2d-25          [-1, 256, 56, 56]          16,384\n",
      "           Conv2d-26          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-27          [-1, 256, 56, 56]             512\n",
      "      BatchNorm2d-28          [-1, 256, 56, 56]             512\n",
      "             ReLU-29          [-1, 256, 56, 56]               0\n",
      "             ReLU-30          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-31          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-32          [-1, 256, 56, 56]               0\n",
      "           Conv2d-33           [-1, 64, 56, 56]          16,384\n",
      "           Conv2d-34           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-36           [-1, 64, 56, 56]             128\n",
      "             ReLU-37           [-1, 64, 56, 56]               0\n",
      "             ReLU-38           [-1, 64, 56, 56]               0\n",
      "           Conv2d-39           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-40           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-41           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-42           [-1, 64, 56, 56]             128\n",
      "             ReLU-43           [-1, 64, 56, 56]               0\n",
      "             ReLU-44           [-1, 64, 56, 56]               0\n",
      "           Conv2d-45          [-1, 256, 56, 56]          16,384\n",
      "           Conv2d-46          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-47          [-1, 256, 56, 56]             512\n",
      "      BatchNorm2d-48          [-1, 256, 56, 56]             512\n",
      "             ReLU-49          [-1, 256, 56, 56]               0\n",
      "             ReLU-50          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-51          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-52          [-1, 256, 56, 56]               0\n",
      "           Conv2d-53           [-1, 64, 56, 56]          16,384\n",
      "           Conv2d-54           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-55           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-56           [-1, 64, 56, 56]             128\n",
      "             ReLU-57           [-1, 64, 56, 56]               0\n",
      "             ReLU-58           [-1, 64, 56, 56]               0\n",
      "           Conv2d-59           [-1, 64, 56, 56]          36,864\n",
      "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-61           [-1, 64, 56, 56]             128\n",
      "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
      "             ReLU-63           [-1, 64, 56, 56]               0\n",
      "             ReLU-64           [-1, 64, 56, 56]               0\n",
      "           Conv2d-65          [-1, 256, 56, 56]          16,384\n",
      "           Conv2d-66          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-67          [-1, 256, 56, 56]             512\n",
      "      BatchNorm2d-68          [-1, 256, 56, 56]             512\n",
      "             ReLU-69          [-1, 256, 56, 56]               0\n",
      "             ReLU-70          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-71          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-72          [-1, 256, 56, 56]               0\n",
      "           Conv2d-73          [-1, 128, 56, 56]          32,768\n",
      "           Conv2d-74          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-75          [-1, 128, 56, 56]             256\n",
      "      BatchNorm2d-76          [-1, 128, 56, 56]             256\n",
      "             ReLU-77          [-1, 128, 56, 56]               0\n",
      "             ReLU-78          [-1, 128, 56, 56]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]         147,456\n",
      "           Conv2d-80          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-81          [-1, 128, 28, 28]             256\n",
      "      BatchNorm2d-82          [-1, 128, 28, 28]             256\n",
      "             ReLU-83          [-1, 128, 28, 28]               0\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "           Conv2d-86          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-87          [-1, 512, 28, 28]           1,024\n",
      "      BatchNorm2d-88          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-89          [-1, 512, 28, 28]         131,072\n",
      "           Conv2d-90          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-91          [-1, 512, 28, 28]           1,024\n",
      "      BatchNorm2d-92          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-93          [-1, 512, 28, 28]               0\n",
      "             ReLU-94          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-95          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-96          [-1, 512, 28, 28]               0\n",
      "           Conv2d-97          [-1, 128, 28, 28]          65,536\n",
      "           Conv2d-98          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "            ReLU-102          [-1, 128, 28, 28]               0\n",
      "          Conv2d-103          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-104          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-105          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-106          [-1, 128, 28, 28]             256\n",
      "            ReLU-107          [-1, 128, 28, 28]               0\n",
      "            ReLU-108          [-1, 128, 28, 28]               0\n",
      "          Conv2d-109          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-110          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-111          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-112          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-113          [-1, 512, 28, 28]               0\n",
      "            ReLU-114          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-115          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-116          [-1, 512, 28, 28]               0\n",
      "          Conv2d-117          [-1, 128, 28, 28]          65,536\n",
      "          Conv2d-118          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-119          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-120          [-1, 128, 28, 28]             256\n",
      "            ReLU-121          [-1, 128, 28, 28]               0\n",
      "            ReLU-122          [-1, 128, 28, 28]               0\n",
      "          Conv2d-123          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-124          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-125          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-126          [-1, 128, 28, 28]             256\n",
      "            ReLU-127          [-1, 128, 28, 28]               0\n",
      "            ReLU-128          [-1, 128, 28, 28]               0\n",
      "          Conv2d-129          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-130          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-131          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-132          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-133          [-1, 512, 28, 28]               0\n",
      "            ReLU-134          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-135          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-136          [-1, 512, 28, 28]               0\n",
      "          Conv2d-137          [-1, 128, 28, 28]          65,536\n",
      "          Conv2d-138          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-139          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-140          [-1, 128, 28, 28]             256\n",
      "            ReLU-141          [-1, 128, 28, 28]               0\n",
      "            ReLU-142          [-1, 128, 28, 28]               0\n",
      "          Conv2d-143          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-144          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-145          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-146          [-1, 128, 28, 28]             256\n",
      "            ReLU-147          [-1, 128, 28, 28]               0\n",
      "            ReLU-148          [-1, 128, 28, 28]               0\n",
      "          Conv2d-149          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-150          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-151          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-152          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-153          [-1, 512, 28, 28]               0\n",
      "            ReLU-154          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-155          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-156          [-1, 512, 28, 28]               0\n",
      "          Conv2d-157          [-1, 128, 28, 28]          65,536\n",
      "          Conv2d-158          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-159          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-160          [-1, 128, 28, 28]             256\n",
      "            ReLU-161          [-1, 128, 28, 28]               0\n",
      "            ReLU-162          [-1, 128, 28, 28]               0\n",
      "          Conv2d-163          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-164          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-165          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-166          [-1, 128, 28, 28]             256\n",
      "            ReLU-167          [-1, 128, 28, 28]               0\n",
      "            ReLU-168          [-1, 128, 28, 28]               0\n",
      "          Conv2d-169          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-170          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-171          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-172          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-173          [-1, 512, 28, 28]               0\n",
      "            ReLU-174          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-175          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-176          [-1, 512, 28, 28]               0\n",
      "          Conv2d-177          [-1, 128, 28, 28]          65,536\n",
      "          Conv2d-178          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-179          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-180          [-1, 128, 28, 28]             256\n",
      "            ReLU-181          [-1, 128, 28, 28]               0\n",
      "            ReLU-182          [-1, 128, 28, 28]               0\n",
      "          Conv2d-183          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-184          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-185          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-186          [-1, 128, 28, 28]             256\n",
      "            ReLU-187          [-1, 128, 28, 28]               0\n",
      "            ReLU-188          [-1, 128, 28, 28]               0\n",
      "          Conv2d-189          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-190          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-191          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-192          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-193          [-1, 512, 28, 28]               0\n",
      "            ReLU-194          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-195          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-196          [-1, 512, 28, 28]               0\n",
      "          Conv2d-197          [-1, 128, 28, 28]          65,536\n",
      "          Conv2d-198          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-199          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-200          [-1, 128, 28, 28]             256\n",
      "            ReLU-201          [-1, 128, 28, 28]               0\n",
      "            ReLU-202          [-1, 128, 28, 28]               0\n",
      "          Conv2d-203          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-204          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-205          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-206          [-1, 128, 28, 28]             256\n",
      "            ReLU-207          [-1, 128, 28, 28]               0\n",
      "            ReLU-208          [-1, 128, 28, 28]               0\n",
      "          Conv2d-209          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-210          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-211          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-212          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-213          [-1, 512, 28, 28]               0\n",
      "            ReLU-214          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-215          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-216          [-1, 512, 28, 28]               0\n",
      "          Conv2d-217          [-1, 128, 28, 28]          65,536\n",
      "          Conv2d-218          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-219          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-220          [-1, 128, 28, 28]             256\n",
      "            ReLU-221          [-1, 128, 28, 28]               0\n",
      "            ReLU-222          [-1, 128, 28, 28]               0\n",
      "          Conv2d-223          [-1, 128, 28, 28]         147,456\n",
      "          Conv2d-224          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-225          [-1, 128, 28, 28]             256\n",
      "     BatchNorm2d-226          [-1, 128, 28, 28]             256\n",
      "            ReLU-227          [-1, 128, 28, 28]               0\n",
      "            ReLU-228          [-1, 128, 28, 28]               0\n",
      "          Conv2d-229          [-1, 512, 28, 28]          65,536\n",
      "          Conv2d-230          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-231          [-1, 512, 28, 28]           1,024\n",
      "     BatchNorm2d-232          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-233          [-1, 512, 28, 28]               0\n",
      "            ReLU-234          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-235          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-236          [-1, 512, 28, 28]               0\n",
      "          Conv2d-237          [-1, 256, 28, 28]         131,072\n",
      "          Conv2d-238          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-239          [-1, 256, 28, 28]             512\n",
      "     BatchNorm2d-240          [-1, 256, 28, 28]             512\n",
      "            ReLU-241          [-1, 256, 28, 28]               0\n",
      "            ReLU-242          [-1, 256, 28, 28]               0\n",
      "          Conv2d-243          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-246          [-1, 256, 14, 14]             512\n",
      "            ReLU-247          [-1, 256, 14, 14]               0\n",
      "            ReLU-248          [-1, 256, 14, 14]               0\n",
      "          Conv2d-249         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-250         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-251         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-252         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-253         [-1, 1024, 14, 14]         524,288\n",
      "          Conv2d-254         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-255         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-256         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-257         [-1, 1024, 14, 14]               0\n",
      "            ReLU-258         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-262          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-263          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-264          [-1, 256, 14, 14]             512\n",
      "            ReLU-265          [-1, 256, 14, 14]               0\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-268          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-269          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-270          [-1, 256, 14, 14]             512\n",
      "            ReLU-271          [-1, 256, 14, 14]               0\n",
      "            ReLU-272          [-1, 256, 14, 14]               0\n",
      "          Conv2d-273         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-274         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-275         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-276         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-277         [-1, 1024, 14, 14]               0\n",
      "            ReLU-278         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-282          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-283          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-284          [-1, 256, 14, 14]             512\n",
      "            ReLU-285          [-1, 256, 14, 14]               0\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-288          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-289          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-290          [-1, 256, 14, 14]             512\n",
      "            ReLU-291          [-1, 256, 14, 14]               0\n",
      "            ReLU-292          [-1, 256, 14, 14]               0\n",
      "          Conv2d-293         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-294         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-295         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-296         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-297         [-1, 1024, 14, 14]               0\n",
      "            ReLU-298         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-302          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-303          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-304          [-1, 256, 14, 14]             512\n",
      "            ReLU-305          [-1, 256, 14, 14]               0\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-308          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-309          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-310          [-1, 256, 14, 14]             512\n",
      "            ReLU-311          [-1, 256, 14, 14]               0\n",
      "            ReLU-312          [-1, 256, 14, 14]               0\n",
      "          Conv2d-313         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-314         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-315         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-316         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-317         [-1, 1024, 14, 14]               0\n",
      "            ReLU-318         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-322          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-323          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-324          [-1, 256, 14, 14]             512\n",
      "            ReLU-325          [-1, 256, 14, 14]               0\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-328          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-329          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-330          [-1, 256, 14, 14]             512\n",
      "            ReLU-331          [-1, 256, 14, 14]               0\n",
      "            ReLU-332          [-1, 256, 14, 14]               0\n",
      "          Conv2d-333         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-334         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-335         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-336         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-337         [-1, 1024, 14, 14]               0\n",
      "            ReLU-338         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-342          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-343          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-344          [-1, 256, 14, 14]             512\n",
      "            ReLU-345          [-1, 256, 14, 14]               0\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-348          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-349          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-350          [-1, 256, 14, 14]             512\n",
      "            ReLU-351          [-1, 256, 14, 14]               0\n",
      "            ReLU-352          [-1, 256, 14, 14]               0\n",
      "          Conv2d-353         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-354         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-355         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-356         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-357         [-1, 1024, 14, 14]               0\n",
      "            ReLU-358         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-362          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-363          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-364          [-1, 256, 14, 14]             512\n",
      "            ReLU-365          [-1, 256, 14, 14]               0\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-368          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-369          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-370          [-1, 256, 14, 14]             512\n",
      "            ReLU-371          [-1, 256, 14, 14]               0\n",
      "            ReLU-372          [-1, 256, 14, 14]               0\n",
      "          Conv2d-373         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-374         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-375         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-376         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-377         [-1, 1024, 14, 14]               0\n",
      "            ReLU-378         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-382          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-383          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-384          [-1, 256, 14, 14]             512\n",
      "            ReLU-385          [-1, 256, 14, 14]               0\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-388          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-389          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-390          [-1, 256, 14, 14]             512\n",
      "            ReLU-391          [-1, 256, 14, 14]               0\n",
      "            ReLU-392          [-1, 256, 14, 14]               0\n",
      "          Conv2d-393         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-394         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-395         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-396         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-397         [-1, 1024, 14, 14]               0\n",
      "            ReLU-398         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-402          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-403          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-404          [-1, 256, 14, 14]             512\n",
      "            ReLU-405          [-1, 256, 14, 14]               0\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-408          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-409          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-410          [-1, 256, 14, 14]             512\n",
      "            ReLU-411          [-1, 256, 14, 14]               0\n",
      "            ReLU-412          [-1, 256, 14, 14]               0\n",
      "          Conv2d-413         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-414         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-415         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-416         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-417         [-1, 1024, 14, 14]               0\n",
      "            ReLU-418         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-422          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-423          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-424          [-1, 256, 14, 14]             512\n",
      "            ReLU-425          [-1, 256, 14, 14]               0\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-428          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-429          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-430          [-1, 256, 14, 14]             512\n",
      "            ReLU-431          [-1, 256, 14, 14]               0\n",
      "            ReLU-432          [-1, 256, 14, 14]               0\n",
      "          Conv2d-433         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-434         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-435         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-436         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-437         [-1, 1024, 14, 14]               0\n",
      "            ReLU-438         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-442          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-443          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-444          [-1, 256, 14, 14]             512\n",
      "            ReLU-445          [-1, 256, 14, 14]               0\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-448          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-449          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-450          [-1, 256, 14, 14]             512\n",
      "            ReLU-451          [-1, 256, 14, 14]               0\n",
      "            ReLU-452          [-1, 256, 14, 14]               0\n",
      "          Conv2d-453         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-454         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-455         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-456         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-457         [-1, 1024, 14, 14]               0\n",
      "            ReLU-458         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-462          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-463          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-464          [-1, 256, 14, 14]             512\n",
      "            ReLU-465          [-1, 256, 14, 14]               0\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-468          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-469          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-470          [-1, 256, 14, 14]             512\n",
      "            ReLU-471          [-1, 256, 14, 14]               0\n",
      "            ReLU-472          [-1, 256, 14, 14]               0\n",
      "          Conv2d-473         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-474         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-475         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-476         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-477         [-1, 1024, 14, 14]               0\n",
      "            ReLU-478         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-482          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-483          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-484          [-1, 256, 14, 14]             512\n",
      "            ReLU-485          [-1, 256, 14, 14]               0\n",
      "            ReLU-486          [-1, 256, 14, 14]               0\n",
      "          Conv2d-487          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-488          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-489          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-490          [-1, 256, 14, 14]             512\n",
      "            ReLU-491          [-1, 256, 14, 14]               0\n",
      "            ReLU-492          [-1, 256, 14, 14]               0\n",
      "          Conv2d-493         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-494         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-495         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-496         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-497         [-1, 1024, 14, 14]               0\n",
      "            ReLU-498         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-499         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-500         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-501          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-502          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-503          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-504          [-1, 256, 14, 14]             512\n",
      "            ReLU-505          [-1, 256, 14, 14]               0\n",
      "            ReLU-506          [-1, 256, 14, 14]               0\n",
      "          Conv2d-507          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-508          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-509          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-510          [-1, 256, 14, 14]             512\n",
      "            ReLU-511          [-1, 256, 14, 14]               0\n",
      "            ReLU-512          [-1, 256, 14, 14]               0\n",
      "          Conv2d-513         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-514         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-515         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-516         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-517         [-1, 1024, 14, 14]               0\n",
      "            ReLU-518         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-519         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-520         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-521          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-522          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-523          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-524          [-1, 256, 14, 14]             512\n",
      "            ReLU-525          [-1, 256, 14, 14]               0\n",
      "            ReLU-526          [-1, 256, 14, 14]               0\n",
      "          Conv2d-527          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-528          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-529          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-530          [-1, 256, 14, 14]             512\n",
      "            ReLU-531          [-1, 256, 14, 14]               0\n",
      "            ReLU-532          [-1, 256, 14, 14]               0\n",
      "          Conv2d-533         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-534         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-535         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-536         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-537         [-1, 1024, 14, 14]               0\n",
      "            ReLU-538         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-539         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-540         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-541          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-542          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-543          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-544          [-1, 256, 14, 14]             512\n",
      "            ReLU-545          [-1, 256, 14, 14]               0\n",
      "            ReLU-546          [-1, 256, 14, 14]               0\n",
      "          Conv2d-547          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-548          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-549          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-550          [-1, 256, 14, 14]             512\n",
      "            ReLU-551          [-1, 256, 14, 14]               0\n",
      "            ReLU-552          [-1, 256, 14, 14]               0\n",
      "          Conv2d-553         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-554         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-555         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-556         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-557         [-1, 1024, 14, 14]               0\n",
      "            ReLU-558         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-559         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-560         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-561          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-562          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-563          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-564          [-1, 256, 14, 14]             512\n",
      "            ReLU-565          [-1, 256, 14, 14]               0\n",
      "            ReLU-566          [-1, 256, 14, 14]               0\n",
      "          Conv2d-567          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-568          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-569          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-570          [-1, 256, 14, 14]             512\n",
      "            ReLU-571          [-1, 256, 14, 14]               0\n",
      "            ReLU-572          [-1, 256, 14, 14]               0\n",
      "          Conv2d-573         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-574         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-575         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-576         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-577         [-1, 1024, 14, 14]               0\n",
      "            ReLU-578         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-579         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-580         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-581          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-582          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-583          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-584          [-1, 256, 14, 14]             512\n",
      "            ReLU-585          [-1, 256, 14, 14]               0\n",
      "            ReLU-586          [-1, 256, 14, 14]               0\n",
      "          Conv2d-587          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-588          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-589          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-590          [-1, 256, 14, 14]             512\n",
      "            ReLU-591          [-1, 256, 14, 14]               0\n",
      "            ReLU-592          [-1, 256, 14, 14]               0\n",
      "          Conv2d-593         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-594         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-595         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-596         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-597         [-1, 1024, 14, 14]               0\n",
      "            ReLU-598         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-599         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-600         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-601          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-602          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-603          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-604          [-1, 256, 14, 14]             512\n",
      "            ReLU-605          [-1, 256, 14, 14]               0\n",
      "            ReLU-606          [-1, 256, 14, 14]               0\n",
      "          Conv2d-607          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-608          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-609          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-610          [-1, 256, 14, 14]             512\n",
      "            ReLU-611          [-1, 256, 14, 14]               0\n",
      "            ReLU-612          [-1, 256, 14, 14]               0\n",
      "          Conv2d-613         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-614         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-615         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-616         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-617         [-1, 1024, 14, 14]               0\n",
      "            ReLU-618         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-619         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-620         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-621          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-622          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-623          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-624          [-1, 256, 14, 14]             512\n",
      "            ReLU-625          [-1, 256, 14, 14]               0\n",
      "            ReLU-626          [-1, 256, 14, 14]               0\n",
      "          Conv2d-627          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-628          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-629          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-630          [-1, 256, 14, 14]             512\n",
      "            ReLU-631          [-1, 256, 14, 14]               0\n",
      "            ReLU-632          [-1, 256, 14, 14]               0\n",
      "          Conv2d-633         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-634         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-635         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-636         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-637         [-1, 1024, 14, 14]               0\n",
      "            ReLU-638         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-639         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-640         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-641          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-642          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-643          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-644          [-1, 256, 14, 14]             512\n",
      "            ReLU-645          [-1, 256, 14, 14]               0\n",
      "            ReLU-646          [-1, 256, 14, 14]               0\n",
      "          Conv2d-647          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-648          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-649          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-650          [-1, 256, 14, 14]             512\n",
      "            ReLU-651          [-1, 256, 14, 14]               0\n",
      "            ReLU-652          [-1, 256, 14, 14]               0\n",
      "          Conv2d-653         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-654         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-655         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-656         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-657         [-1, 1024, 14, 14]               0\n",
      "            ReLU-658         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-659         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-660         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-661          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-662          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-663          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-664          [-1, 256, 14, 14]             512\n",
      "            ReLU-665          [-1, 256, 14, 14]               0\n",
      "            ReLU-666          [-1, 256, 14, 14]               0\n",
      "          Conv2d-667          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-668          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-669          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-670          [-1, 256, 14, 14]             512\n",
      "            ReLU-671          [-1, 256, 14, 14]               0\n",
      "            ReLU-672          [-1, 256, 14, 14]               0\n",
      "          Conv2d-673         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-674         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-675         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-676         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-677         [-1, 1024, 14, 14]               0\n",
      "            ReLU-678         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-679         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-680         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-681          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-682          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-683          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-684          [-1, 256, 14, 14]             512\n",
      "            ReLU-685          [-1, 256, 14, 14]               0\n",
      "            ReLU-686          [-1, 256, 14, 14]               0\n",
      "          Conv2d-687          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-688          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-689          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-690          [-1, 256, 14, 14]             512\n",
      "            ReLU-691          [-1, 256, 14, 14]               0\n",
      "            ReLU-692          [-1, 256, 14, 14]               0\n",
      "          Conv2d-693         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-694         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-695         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-696         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-697         [-1, 1024, 14, 14]               0\n",
      "            ReLU-698         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-699         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-700         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-701          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-702          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-703          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-704          [-1, 256, 14, 14]             512\n",
      "            ReLU-705          [-1, 256, 14, 14]               0\n",
      "            ReLU-706          [-1, 256, 14, 14]               0\n",
      "          Conv2d-707          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-708          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-709          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-710          [-1, 256, 14, 14]             512\n",
      "            ReLU-711          [-1, 256, 14, 14]               0\n",
      "            ReLU-712          [-1, 256, 14, 14]               0\n",
      "          Conv2d-713         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-714         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-715         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-716         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-717         [-1, 1024, 14, 14]               0\n",
      "            ReLU-718         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-719         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-720         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-721          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-722          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-723          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-724          [-1, 256, 14, 14]             512\n",
      "            ReLU-725          [-1, 256, 14, 14]               0\n",
      "            ReLU-726          [-1, 256, 14, 14]               0\n",
      "          Conv2d-727          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-728          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-729          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-730          [-1, 256, 14, 14]             512\n",
      "            ReLU-731          [-1, 256, 14, 14]               0\n",
      "            ReLU-732          [-1, 256, 14, 14]               0\n",
      "          Conv2d-733         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-734         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-735         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-736         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-737         [-1, 1024, 14, 14]               0\n",
      "            ReLU-738         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-739         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-740         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-741          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-742          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-743          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-744          [-1, 256, 14, 14]             512\n",
      "            ReLU-745          [-1, 256, 14, 14]               0\n",
      "            ReLU-746          [-1, 256, 14, 14]               0\n",
      "          Conv2d-747          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-748          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-749          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-750          [-1, 256, 14, 14]             512\n",
      "            ReLU-751          [-1, 256, 14, 14]               0\n",
      "            ReLU-752          [-1, 256, 14, 14]               0\n",
      "          Conv2d-753         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-754         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-755         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-756         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-757         [-1, 1024, 14, 14]               0\n",
      "            ReLU-758         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-759         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-760         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-761          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-762          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-763          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-764          [-1, 256, 14, 14]             512\n",
      "            ReLU-765          [-1, 256, 14, 14]               0\n",
      "            ReLU-766          [-1, 256, 14, 14]               0\n",
      "          Conv2d-767          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-768          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-769          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-770          [-1, 256, 14, 14]             512\n",
      "            ReLU-771          [-1, 256, 14, 14]               0\n",
      "            ReLU-772          [-1, 256, 14, 14]               0\n",
      "          Conv2d-773         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-774         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-775         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-776         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-777         [-1, 1024, 14, 14]               0\n",
      "            ReLU-778         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-779         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-780         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-781          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-782          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-783          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-784          [-1, 256, 14, 14]             512\n",
      "            ReLU-785          [-1, 256, 14, 14]               0\n",
      "            ReLU-786          [-1, 256, 14, 14]               0\n",
      "          Conv2d-787          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-788          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-789          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-790          [-1, 256, 14, 14]             512\n",
      "            ReLU-791          [-1, 256, 14, 14]               0\n",
      "            ReLU-792          [-1, 256, 14, 14]               0\n",
      "          Conv2d-793         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-794         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-795         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-796         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-797         [-1, 1024, 14, 14]               0\n",
      "            ReLU-798         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-799         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-800         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-801          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-802          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-803          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-804          [-1, 256, 14, 14]             512\n",
      "            ReLU-805          [-1, 256, 14, 14]               0\n",
      "            ReLU-806          [-1, 256, 14, 14]               0\n",
      "          Conv2d-807          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-808          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-809          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-810          [-1, 256, 14, 14]             512\n",
      "            ReLU-811          [-1, 256, 14, 14]               0\n",
      "            ReLU-812          [-1, 256, 14, 14]               0\n",
      "          Conv2d-813         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-814         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-815         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-816         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-817         [-1, 1024, 14, 14]               0\n",
      "            ReLU-818         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-819         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-820         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-821          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-822          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-823          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-824          [-1, 256, 14, 14]             512\n",
      "            ReLU-825          [-1, 256, 14, 14]               0\n",
      "            ReLU-826          [-1, 256, 14, 14]               0\n",
      "          Conv2d-827          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-828          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-829          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-830          [-1, 256, 14, 14]             512\n",
      "            ReLU-831          [-1, 256, 14, 14]               0\n",
      "            ReLU-832          [-1, 256, 14, 14]               0\n",
      "          Conv2d-833         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-834         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-835         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-836         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-837         [-1, 1024, 14, 14]               0\n",
      "            ReLU-838         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-839         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-840         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-841          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-842          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-843          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-844          [-1, 256, 14, 14]             512\n",
      "            ReLU-845          [-1, 256, 14, 14]               0\n",
      "            ReLU-846          [-1, 256, 14, 14]               0\n",
      "          Conv2d-847          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-848          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-849          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-850          [-1, 256, 14, 14]             512\n",
      "            ReLU-851          [-1, 256, 14, 14]               0\n",
      "            ReLU-852          [-1, 256, 14, 14]               0\n",
      "          Conv2d-853         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-854         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-855         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-856         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-857         [-1, 1024, 14, 14]               0\n",
      "            ReLU-858         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-859         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-860         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-861          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-862          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-863          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-864          [-1, 256, 14, 14]             512\n",
      "            ReLU-865          [-1, 256, 14, 14]               0\n",
      "            ReLU-866          [-1, 256, 14, 14]               0\n",
      "          Conv2d-867          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-868          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-869          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-870          [-1, 256, 14, 14]             512\n",
      "            ReLU-871          [-1, 256, 14, 14]               0\n",
      "            ReLU-872          [-1, 256, 14, 14]               0\n",
      "          Conv2d-873         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-874         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-875         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-876         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-877         [-1, 1024, 14, 14]               0\n",
      "            ReLU-878         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-879         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-880         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-881          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-882          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-883          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-884          [-1, 256, 14, 14]             512\n",
      "            ReLU-885          [-1, 256, 14, 14]               0\n",
      "            ReLU-886          [-1, 256, 14, 14]               0\n",
      "          Conv2d-887          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-888          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-889          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-890          [-1, 256, 14, 14]             512\n",
      "            ReLU-891          [-1, 256, 14, 14]               0\n",
      "            ReLU-892          [-1, 256, 14, 14]               0\n",
      "          Conv2d-893         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-894         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-895         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-896         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-897         [-1, 1024, 14, 14]               0\n",
      "            ReLU-898         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-899         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-900         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-901          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-902          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-903          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-904          [-1, 256, 14, 14]             512\n",
      "            ReLU-905          [-1, 256, 14, 14]               0\n",
      "            ReLU-906          [-1, 256, 14, 14]               0\n",
      "          Conv2d-907          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-908          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-909          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-910          [-1, 256, 14, 14]             512\n",
      "            ReLU-911          [-1, 256, 14, 14]               0\n",
      "            ReLU-912          [-1, 256, 14, 14]               0\n",
      "          Conv2d-913         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-914         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-915         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-916         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-917         [-1, 1024, 14, 14]               0\n",
      "            ReLU-918         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-919         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-920         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-921          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-922          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-923          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-924          [-1, 256, 14, 14]             512\n",
      "            ReLU-925          [-1, 256, 14, 14]               0\n",
      "            ReLU-926          [-1, 256, 14, 14]               0\n",
      "          Conv2d-927          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-928          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-929          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-930          [-1, 256, 14, 14]             512\n",
      "            ReLU-931          [-1, 256, 14, 14]               0\n",
      "            ReLU-932          [-1, 256, 14, 14]               0\n",
      "          Conv2d-933         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-934         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-935         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-936         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-937         [-1, 1024, 14, 14]               0\n",
      "            ReLU-938         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-939         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-940         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-941          [-1, 256, 14, 14]         262,144\n",
      "          Conv2d-942          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-943          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-944          [-1, 256, 14, 14]             512\n",
      "            ReLU-945          [-1, 256, 14, 14]               0\n",
      "            ReLU-946          [-1, 256, 14, 14]               0\n",
      "          Conv2d-947          [-1, 256, 14, 14]         589,824\n",
      "          Conv2d-948          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-949          [-1, 256, 14, 14]             512\n",
      "     BatchNorm2d-950          [-1, 256, 14, 14]             512\n",
      "            ReLU-951          [-1, 256, 14, 14]               0\n",
      "            ReLU-952          [-1, 256, 14, 14]               0\n",
      "          Conv2d-953         [-1, 1024, 14, 14]         262,144\n",
      "          Conv2d-954         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-955         [-1, 1024, 14, 14]           2,048\n",
      "     BatchNorm2d-956         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-957         [-1, 1024, 14, 14]               0\n",
      "            ReLU-958         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-959         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-960         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-961          [-1, 512, 14, 14]         524,288\n",
      "          Conv2d-962          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-963          [-1, 512, 14, 14]           1,024\n",
      "     BatchNorm2d-964          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-965          [-1, 512, 14, 14]               0\n",
      "            ReLU-966          [-1, 512, 14, 14]               0\n",
      "          Conv2d-967            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-968            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-969            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-970            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-971            [-1, 512, 7, 7]               0\n",
      "            ReLU-972            [-1, 512, 7, 7]               0\n",
      "          Conv2d-973           [-1, 2048, 7, 7]       1,048,576\n",
      "          Conv2d-974           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-975           [-1, 2048, 7, 7]           4,096\n",
      "     BatchNorm2d-976           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-977           [-1, 2048, 7, 7]       2,097,152\n",
      "          Conv2d-978           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-979           [-1, 2048, 7, 7]           4,096\n",
      "     BatchNorm2d-980           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-981           [-1, 2048, 7, 7]               0\n",
      "            ReLU-982           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-983           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-984           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-985            [-1, 512, 7, 7]       1,048,576\n",
      "          Conv2d-986            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-987            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-988            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-989            [-1, 512, 7, 7]               0\n",
      "            ReLU-990            [-1, 512, 7, 7]               0\n",
      "          Conv2d-991            [-1, 512, 7, 7]       2,359,296\n",
      "          Conv2d-992            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-993            [-1, 512, 7, 7]           1,024\n",
      "     BatchNorm2d-994            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-995            [-1, 512, 7, 7]               0\n",
      "            ReLU-996            [-1, 512, 7, 7]               0\n",
      "          Conv2d-997           [-1, 2048, 7, 7]       1,048,576\n",
      "          Conv2d-998           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-999           [-1, 2048, 7, 7]           4,096\n",
      "    BatchNorm2d-1000           [-1, 2048, 7, 7]           4,096\n",
      "           ReLU-1001           [-1, 2048, 7, 7]               0\n",
      "           ReLU-1002           [-1, 2048, 7, 7]               0\n",
      "     Bottleneck-1003           [-1, 2048, 7, 7]               0\n",
      "     Bottleneck-1004           [-1, 2048, 7, 7]               0\n",
      "         Conv2d-1005            [-1, 512, 7, 7]       1,048,576\n",
      "         Conv2d-1006            [-1, 512, 7, 7]       1,048,576\n",
      "    BatchNorm2d-1007            [-1, 512, 7, 7]           1,024\n",
      "    BatchNorm2d-1008            [-1, 512, 7, 7]           1,024\n",
      "           ReLU-1009            [-1, 512, 7, 7]               0\n",
      "           ReLU-1010            [-1, 512, 7, 7]               0\n",
      "         Conv2d-1011            [-1, 512, 7, 7]       2,359,296\n",
      "         Conv2d-1012            [-1, 512, 7, 7]       2,359,296\n",
      "    BatchNorm2d-1013            [-1, 512, 7, 7]           1,024\n",
      "    BatchNorm2d-1014            [-1, 512, 7, 7]           1,024\n",
      "           ReLU-1015            [-1, 512, 7, 7]               0\n",
      "           ReLU-1016            [-1, 512, 7, 7]               0\n",
      "         Conv2d-1017           [-1, 2048, 7, 7]       1,048,576\n",
      "         Conv2d-1018           [-1, 2048, 7, 7]       1,048,576\n",
      "    BatchNorm2d-1019           [-1, 2048, 7, 7]           4,096\n",
      "    BatchNorm2d-1020           [-1, 2048, 7, 7]           4,096\n",
      "           ReLU-1021           [-1, 2048, 7, 7]               0\n",
      "           ReLU-1022           [-1, 2048, 7, 7]               0\n",
      "     Bottleneck-1023           [-1, 2048, 7, 7]               0\n",
      "     Bottleneck-1024           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-1025           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-1026           [-1, 2048, 1, 1]               0\n",
      "         Linear-1027                  [-1, 131]         268,419\n",
      "================================================================\n",
      "Total params: 116,556,035\n",
      "Trainable params: 111,425,667\n",
      "Non-trainable params: 5,130,368\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1213.17\n",
      "Params size (MB): 444.63\n",
      "Estimated Total Size (MB): 1658.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to ONNX for serverles model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T07:22:52.235287Z",
     "iopub.status.busy": "2025-12-30T07:22:52.234287Z",
     "iopub.status.idle": "2025-12-30T07:23:28.449519Z",
     "shell.execute_reply": "2025-12-30T07:23:28.448387Z",
     "shell.execute_reply.started": "2025-12-30T07:22:52.235287Z"
    },
    "id": "53_ucFUwYPRB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `FoodClassifierResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `FoodClassifierResNet([...]` with `torch.export.export(..., strict=False)`... \n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... \n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... \n",
      "Applied 310 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 20},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.1+cu126',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[s77,3,224,224]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,131]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"features_extractor.0.weight\"<FLOAT,[64,3,7,7]>{Tensor(...)},\n",
       "                %\"features_extractor.4.0.conv1.weight\"<FLOAT,[64,64,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.4.0.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.4.0.conv3.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.4.0.downsample.0.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.4.1.conv1.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.4.1.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.4.1.conv3.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.4.2.conv1.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.4.2.conv2.weight\"<FLOAT,[64,64,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.4.2.conv3.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.0.conv1.weight\"<FLOAT,[128,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.0.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.0.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.0.downsample.0.weight\"<FLOAT,[512,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.1.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.1.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.1.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.2.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.2.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.2.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.3.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.3.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.3.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.4.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.4.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.4.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.5.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.5.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.5.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.6.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.6.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.6.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.7.conv1.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.5.7.conv2.weight\"<FLOAT,[128,128,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.5.7.conv3.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.0.conv1.weight\"<FLOAT,[256,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.0.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.0.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.0.downsample.0.weight\"<FLOAT,[1024,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.1.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.1.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.1.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.2.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.2.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.2.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.3.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.3.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.3.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.4.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.4.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.4.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.5.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.5.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.5.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.6.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.6.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.6.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.7.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.7.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.7.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.8.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.8.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.8.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.9.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.9.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.9.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.10.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.10.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.10.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.11.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.11.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.11.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.12.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.12.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.12.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.13.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.13.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.13.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.14.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.14.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.14.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.15.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.15.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.15.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.16.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.16.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.16.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.17.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.17.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.17.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.18.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.18.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.18.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.19.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.19.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.19.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.20.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.20.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.20.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.21.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.21.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.21.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.22.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.22.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.22.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.23.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.23.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.23.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.24.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.24.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.24.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.25.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.25.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.25.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.26.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.26.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.26.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.27.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.27.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.27.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.28.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.28.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.28.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.29.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.29.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.29.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.30.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.30.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.30.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.31.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.31.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.31.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.32.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.32.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.32.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.33.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.33.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.33.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.34.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.34.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.34.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.35.conv1.weight\"<FLOAT,[256,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.6.35.conv2.weight\"<FLOAT,[256,256,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.6.35.conv3.weight\"<FLOAT,[1024,256,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.0.conv1.weight\"<FLOAT,[512,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.0.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.7.0.conv3.weight\"<FLOAT,[2048,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.0.downsample.0.weight\"<FLOAT,[2048,1024,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.1.conv1.weight\"<FLOAT,[512,2048,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.1.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.7.1.conv3.weight\"<FLOAT,[2048,512,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.2.conv1.weight\"<FLOAT,[512,2048,1,1]>{Tensor(...)},\n",
       "                %\"features_extractor.7.2.conv2.weight\"<FLOAT,[512,512,3,3]>{Tensor(...)},\n",
       "                %\"features_extractor.7.2.conv3.weight\"<FLOAT,[2048,512,1,1]>{Tensor(...)},\n",
       "                %\"output_layer.weight\"<FLOAT,[131,2048]>{TorchTensor(...)},\n",
       "                %\"output_layer.bias\"<FLOAT,[131]>{TorchTensor(...)},\n",
       "                %\"val_1401\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_1401')},\n",
       "                %\"val_1405\"<INT64,[2]>{Tensor<INT64,[2]>(array([   1, 2048]), name='val_1405')},\n",
       "                %\"input_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"max_pool2d_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_1_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_2_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_3_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_4_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_5_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_6_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_7_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"relu_8_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_9_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_10_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_11_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_12_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_13_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_14_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_15_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_16_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_17_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_18_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_19_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_20_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_21_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_22_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_23_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_24_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_25_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_26_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_27_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_28_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_29_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_30_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_31_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"relu_32_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_33_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_34_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_35_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_36_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_37_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_38_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_39_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_40_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_41_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_42_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_43_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_44_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_45_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_46_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_47_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_48_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_49_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_50_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_51_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_52_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_53_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_54_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_55_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_56_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_57_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_58_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_59_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_60_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_61_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_62_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_63_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_64_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_65_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_66_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_67_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_68_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_69_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_70_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_71_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_72_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_73_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_74_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_75_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_76_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_77_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_78_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_79_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_80_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_81_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_82_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_83_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_84_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_85_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_86_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_87_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_88_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_89_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_90_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_91_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_92_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_93_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_94_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_95_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_96_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_97_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_98_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_99_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_100_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_101_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_102_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_103_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_104_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_105_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_106_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_107_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_108_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_109_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_110_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_111_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_112_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_113_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_114_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_115_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_116_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_117_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_118_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_119_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_120_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_121_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_122_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_123_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_124_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_125_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_126_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_127_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_128_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_129_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_130_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_131_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_132_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_133_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_134_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_135_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_136_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_137_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_138_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_139_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"relu_140_bias\"<FLOAT,[1024]>{Tensor(...)},\n",
       "                %\"relu_141_bias\"<FLOAT,[2048]>{Tensor(...)},\n",
       "                %\"relu_142_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_143_bias\"<FLOAT,[2048]>{Tensor(...)},\n",
       "                %\"relu_144_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_145_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_146_bias\"<FLOAT,[2048]>{Tensor(...)},\n",
       "                %\"relu_147_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_148_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"relu_149_bias\"<FLOAT,[2048]>{Tensor(...)}\n",
       "            ),\n",
       "        ) {\n",
       "              0 |  # node_Conv_1871\n",
       "                   %\"getitem\"<FLOAT,[s77,64,112,112]>  ::Conv(%\"input\", %\"features_extractor.0.weight\"{...}, %\"input_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(3, 3, 3, 3)}\n",
       "              1 |  # node_relu\n",
       "                   %\"relu\"<FLOAT,[s77,64,112,112]>  ::Relu(%\"getitem\")\n",
       "              2 |  # node_max_pool2d\n",
       "                   %\"max_pool2d\"<FLOAT,[s77,64,56,56]>, %\"\"<?,?>  ::MaxPool(%\"relu\") {kernel_shape=(3, 3), strides=(2, 2), dilations=(1, 1), auto_pad='NOTSET', pads=(1, 1, 1, 1), ceil_mode=0, storage_order=0}\n",
       "              3 |  # node_Conv_1873\n",
       "                   %\"getitem_3\"<FLOAT,[s77,64,56,56]>  ::Conv(%\"max_pool2d\", %\"features_extractor.4.0.conv1.weight\"{...}, %\"max_pool2d_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "              4 |  # node_relu_1\n",
       "                   %\"relu_1\"<FLOAT,[s77,64,56,56]>  ::Relu(%\"getitem_3\")\n",
       "              5 |  # node_Conv_1875\n",
       "                   %\"getitem_6\"<FLOAT,[s77,64,56,56]>  ::Conv(%\"relu_1\", %\"features_extractor.4.0.conv2.weight\"{...}, %\"relu_1_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "              6 |  # node_relu_2\n",
       "                   %\"relu_2\"<FLOAT,[s77,64,56,56]>  ::Relu(%\"getitem_6\")\n",
       "              7 |  # node_Conv_1877\n",
       "                   %\"getitem_9\"<FLOAT,[s77,256,56,56]>  ::Conv(%\"relu_2\", %\"features_extractor.4.0.conv3.weight\"{...}, %\"relu_2_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "              8 |  # node_Conv_1879\n",
       "                   %\"getitem_12\"<FLOAT,[s77,256,56,56]>  ::Conv(%\"max_pool2d\", %\"features_extractor.4.0.downsample.0.weight\"{...}, %\"max_pool2d_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "              9 |  # node_add_95\n",
       "                   %\"add_95\"<FLOAT,[s77,256,56,56]>  ::Add(%\"getitem_9\", %\"getitem_12\")\n",
       "             10 |  # node_relu_3\n",
       "                   %\"relu_3\"<FLOAT,[s77,256,56,56]>  ::Relu(%\"add_95\")\n",
       "             11 |  # node_Conv_1881\n",
       "                   %\"getitem_15\"<FLOAT,[s77,64,56,56]>  ::Conv(%\"relu_3\", %\"features_extractor.4.1.conv1.weight\"{...}, %\"relu_3_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             12 |  # node_relu_4\n",
       "                   %\"relu_4\"<FLOAT,[s77,64,56,56]>  ::Relu(%\"getitem_15\")\n",
       "             13 |  # node_Conv_1883\n",
       "                   %\"getitem_18\"<FLOAT,[s77,64,56,56]>  ::Conv(%\"relu_4\", %\"features_extractor.4.1.conv2.weight\"{...}, %\"relu_4_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             14 |  # node_relu_5\n",
       "                   %\"relu_5\"<FLOAT,[s77,64,56,56]>  ::Relu(%\"getitem_18\")\n",
       "             15 |  # node_Conv_1885\n",
       "                   %\"getitem_21\"<FLOAT,[s77,256,56,56]>  ::Conv(%\"relu_5\", %\"features_extractor.4.1.conv3.weight\"{...}, %\"relu_5_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             16 |  # node_add_171\n",
       "                   %\"add_171\"<FLOAT,[s77,256,56,56]>  ::Add(%\"getitem_21\", %\"relu_3\")\n",
       "             17 |  # node_relu_6\n",
       "                   %\"relu_6\"<FLOAT,[s77,256,56,56]>  ::Relu(%\"add_171\")\n",
       "             18 |  # node_Conv_1887\n",
       "                   %\"getitem_24\"<FLOAT,[s77,64,56,56]>  ::Conv(%\"relu_6\", %\"features_extractor.4.2.conv1.weight\"{...}, %\"relu_6_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             19 |  # node_relu_7\n",
       "                   %\"relu_7\"<FLOAT,[s77,64,56,56]>  ::Relu(%\"getitem_24\")\n",
       "             20 |  # node_Conv_1889\n",
       "                   %\"getitem_27\"<FLOAT,[s77,64,56,56]>  ::Conv(%\"relu_7\", %\"features_extractor.4.2.conv2.weight\"{...}, %\"relu_7_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             21 |  # node_relu_8\n",
       "                   %\"relu_8\"<FLOAT,[s77,64,56,56]>  ::Relu(%\"getitem_27\")\n",
       "             22 |  # node_Conv_1891\n",
       "                   %\"getitem_30\"<FLOAT,[s77,256,56,56]>  ::Conv(%\"relu_8\", %\"features_extractor.4.2.conv3.weight\"{...}, %\"relu_8_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             23 |  # node_add_247\n",
       "                   %\"add_247\"<FLOAT,[s77,256,56,56]>  ::Add(%\"getitem_30\", %\"relu_6\")\n",
       "             24 |  # node_relu_9\n",
       "                   %\"relu_9\"<FLOAT,[s77,256,56,56]>  ::Relu(%\"add_247\")\n",
       "             25 |  # node_Conv_1893\n",
       "                   %\"getitem_33\"<FLOAT,[s77,128,56,56]>  ::Conv(%\"relu_9\", %\"features_extractor.5.0.conv1.weight\"{...}, %\"relu_9_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             26 |  # node_relu_10\n",
       "                   %\"relu_10\"<FLOAT,[s77,128,56,56]>  ::Relu(%\"getitem_33\")\n",
       "             27 |  # node_Conv_1895\n",
       "                   %\"getitem_36\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_10\", %\"features_extractor.5.0.conv2.weight\"{...}, %\"relu_10_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "             28 |  # node_relu_11\n",
       "                   %\"relu_11\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_36\")\n",
       "             29 |  # node_Conv_1897\n",
       "                   %\"getitem_39\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_11\", %\"features_extractor.5.0.conv3.weight\"{...}, %\"relu_11_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             30 |  # node_Conv_1899\n",
       "                   %\"getitem_42\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_9\", %\"features_extractor.5.0.downsample.0.weight\"{...}, %\"relu_9_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "             31 |  # node_add_333\n",
       "                   %\"add_333\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_39\", %\"getitem_42\")\n",
       "             32 |  # node_relu_12\n",
       "                   %\"relu_12\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_333\")\n",
       "             33 |  # node_Conv_1901\n",
       "                   %\"getitem_45\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_12\", %\"features_extractor.5.1.conv1.weight\"{...}, %\"relu_12_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             34 |  # node_relu_13\n",
       "                   %\"relu_13\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_45\")\n",
       "             35 |  # node_Conv_1903\n",
       "                   %\"getitem_48\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_13\", %\"features_extractor.5.1.conv2.weight\"{...}, %\"relu_13_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             36 |  # node_relu_14\n",
       "                   %\"relu_14\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_48\")\n",
       "             37 |  # node_Conv_1905\n",
       "                   %\"getitem_51\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_14\", %\"features_extractor.5.1.conv3.weight\"{...}, %\"relu_14_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             38 |  # node_add_409\n",
       "                   %\"add_409\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_51\", %\"relu_12\")\n",
       "             39 |  # node_relu_15\n",
       "                   %\"relu_15\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_409\")\n",
       "             40 |  # node_Conv_1907\n",
       "                   %\"getitem_54\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_15\", %\"features_extractor.5.2.conv1.weight\"{...}, %\"relu_15_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             41 |  # node_relu_16\n",
       "                   %\"relu_16\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_54\")\n",
       "             42 |  # node_Conv_1909\n",
       "                   %\"getitem_57\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_16\", %\"features_extractor.5.2.conv2.weight\"{...}, %\"relu_16_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             43 |  # node_relu_17\n",
       "                   %\"relu_17\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_57\")\n",
       "             44 |  # node_Conv_1911\n",
       "                   %\"getitem_60\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_17\", %\"features_extractor.5.2.conv3.weight\"{...}, %\"relu_17_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             45 |  # node_add_485\n",
       "                   %\"add_485\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_60\", %\"relu_15\")\n",
       "             46 |  # node_relu_18\n",
       "                   %\"relu_18\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_485\")\n",
       "             47 |  # node_Conv_1913\n",
       "                   %\"getitem_63\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_18\", %\"features_extractor.5.3.conv1.weight\"{...}, %\"relu_18_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             48 |  # node_relu_19\n",
       "                   %\"relu_19\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_63\")\n",
       "             49 |  # node_Conv_1915\n",
       "                   %\"getitem_66\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_19\", %\"features_extractor.5.3.conv2.weight\"{...}, %\"relu_19_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             50 |  # node_relu_20\n",
       "                   %\"relu_20\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_66\")\n",
       "             51 |  # node_Conv_1917\n",
       "                   %\"getitem_69\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_20\", %\"features_extractor.5.3.conv3.weight\"{...}, %\"relu_20_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             52 |  # node_add_561\n",
       "                   %\"add_561\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_69\", %\"relu_18\")\n",
       "             53 |  # node_relu_21\n",
       "                   %\"relu_21\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_561\")\n",
       "             54 |  # node_Conv_1919\n",
       "                   %\"getitem_72\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_21\", %\"features_extractor.5.4.conv1.weight\"{...}, %\"relu_21_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             55 |  # node_relu_22\n",
       "                   %\"relu_22\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_72\")\n",
       "             56 |  # node_Conv_1921\n",
       "                   %\"getitem_75\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_22\", %\"features_extractor.5.4.conv2.weight\"{...}, %\"relu_22_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             57 |  # node_relu_23\n",
       "                   %\"relu_23\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_75\")\n",
       "             58 |  # node_Conv_1923\n",
       "                   %\"getitem_78\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_23\", %\"features_extractor.5.4.conv3.weight\"{...}, %\"relu_23_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             59 |  # node_add_637\n",
       "                   %\"add_637\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_78\", %\"relu_21\")\n",
       "             60 |  # node_relu_24\n",
       "                   %\"relu_24\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_637\")\n",
       "             61 |  # node_Conv_1925\n",
       "                   %\"getitem_81\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_24\", %\"features_extractor.5.5.conv1.weight\"{...}, %\"relu_24_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             62 |  # node_relu_25\n",
       "                   %\"relu_25\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_81\")\n",
       "             63 |  # node_Conv_1927\n",
       "                   %\"getitem_84\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_25\", %\"features_extractor.5.5.conv2.weight\"{...}, %\"relu_25_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             64 |  # node_relu_26\n",
       "                   %\"relu_26\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_84\")\n",
       "             65 |  # node_Conv_1929\n",
       "                   %\"getitem_87\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_26\", %\"features_extractor.5.5.conv3.weight\"{...}, %\"relu_26_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             66 |  # node_add_713\n",
       "                   %\"add_713\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_87\", %\"relu_24\")\n",
       "             67 |  # node_relu_27\n",
       "                   %\"relu_27\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_713\")\n",
       "             68 |  # node_Conv_1931\n",
       "                   %\"getitem_90\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_27\", %\"features_extractor.5.6.conv1.weight\"{...}, %\"relu_27_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             69 |  # node_relu_28\n",
       "                   %\"relu_28\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_90\")\n",
       "             70 |  # node_Conv_1933\n",
       "                   %\"getitem_93\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_28\", %\"features_extractor.5.6.conv2.weight\"{...}, %\"relu_28_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             71 |  # node_relu_29\n",
       "                   %\"relu_29\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_93\")\n",
       "             72 |  # node_Conv_1935\n",
       "                   %\"getitem_96\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_29\", %\"features_extractor.5.6.conv3.weight\"{...}, %\"relu_29_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             73 |  # node_add_789\n",
       "                   %\"add_789\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_96\", %\"relu_27\")\n",
       "             74 |  # node_relu_30\n",
       "                   %\"relu_30\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_789\")\n",
       "             75 |  # node_Conv_1937\n",
       "                   %\"getitem_99\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_30\", %\"features_extractor.5.7.conv1.weight\"{...}, %\"relu_30_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             76 |  # node_relu_31\n",
       "                   %\"relu_31\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_99\")\n",
       "             77 |  # node_Conv_1939\n",
       "                   %\"getitem_102\"<FLOAT,[s77,128,28,28]>  ::Conv(%\"relu_31\", %\"features_extractor.5.7.conv2.weight\"{...}, %\"relu_31_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             78 |  # node_relu_32\n",
       "                   %\"relu_32\"<FLOAT,[s77,128,28,28]>  ::Relu(%\"getitem_102\")\n",
       "             79 |  # node_Conv_1941\n",
       "                   %\"getitem_105\"<FLOAT,[s77,512,28,28]>  ::Conv(%\"relu_32\", %\"features_extractor.5.7.conv3.weight\"{...}, %\"relu_32_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             80 |  # node_add_865\n",
       "                   %\"add_865\"<FLOAT,[s77,512,28,28]>  ::Add(%\"getitem_105\", %\"relu_30\")\n",
       "             81 |  # node_relu_33\n",
       "                   %\"relu_33\"<FLOAT,[s77,512,28,28]>  ::Relu(%\"add_865\")\n",
       "             82 |  # node_Conv_1943\n",
       "                   %\"getitem_108\"<FLOAT,[1,256,28,28]>  ::Conv(%\"relu_33\", %\"features_extractor.6.0.conv1.weight\"{...}, %\"relu_33_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             83 |  # node_relu_34\n",
       "                   %\"relu_34\"<FLOAT,[1,256,28,28]>  ::Relu(%\"getitem_108\")\n",
       "             84 |  # node_Conv_1945\n",
       "                   %\"getitem_111\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_34\", %\"features_extractor.6.0.conv2.weight\"{...}, %\"relu_34_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "             85 |  # node_relu_35\n",
       "                   %\"relu_35\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_111\")\n",
       "             86 |  # node_Conv_1947\n",
       "                   %\"getitem_114\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_35\", %\"features_extractor.6.0.conv3.weight\"{...}, %\"relu_35_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             87 |  # node_Conv_1949\n",
       "                   %\"getitem_117\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_33\", %\"features_extractor.6.0.downsample.0.weight\"{...}, %\"relu_33_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "             88 |  # node_add_891\n",
       "                   %\"add_891\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_114\", %\"getitem_117\")\n",
       "             89 |  # node_relu_36\n",
       "                   %\"relu_36\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_891\")\n",
       "             90 |  # node_Conv_1951\n",
       "                   %\"getitem_120\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_36\", %\"features_extractor.6.1.conv1.weight\"{...}, %\"relu_36_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             91 |  # node_relu_37\n",
       "                   %\"relu_37\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_120\")\n",
       "             92 |  # node_Conv_1953\n",
       "                   %\"getitem_123\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_37\", %\"features_extractor.6.1.conv2.weight\"{...}, %\"relu_37_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "             93 |  # node_relu_38\n",
       "                   %\"relu_38\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_123\")\n",
       "             94 |  # node_Conv_1955\n",
       "                   %\"getitem_126\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_38\", %\"features_extractor.6.1.conv3.weight\"{...}, %\"relu_38_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             95 |  # node_add_892\n",
       "                   %\"add_892\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_126\", %\"relu_36\")\n",
       "             96 |  # node_relu_39\n",
       "                   %\"relu_39\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_892\")\n",
       "             97 |  # node_Conv_1957\n",
       "                   %\"getitem_129\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_39\", %\"features_extractor.6.2.conv1.weight\"{...}, %\"relu_39_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "             98 |  # node_relu_40\n",
       "                   %\"relu_40\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_129\")\n",
       "             99 |  # node_Conv_1959\n",
       "                   %\"getitem_132\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_40\", %\"features_extractor.6.2.conv2.weight\"{...}, %\"relu_40_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            100 |  # node_relu_41\n",
       "                   %\"relu_41\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_132\")\n",
       "            101 |  # node_Conv_1961\n",
       "                   %\"getitem_135\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_41\", %\"features_extractor.6.2.conv3.weight\"{...}, %\"relu_41_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            102 |  # node_add_893\n",
       "                   %\"add_893\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_135\", %\"relu_39\")\n",
       "            103 |  # node_relu_42\n",
       "                   %\"relu_42\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_893\")\n",
       "            104 |  # node_Conv_1963\n",
       "                   %\"getitem_138\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_42\", %\"features_extractor.6.3.conv1.weight\"{...}, %\"relu_42_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            105 |  # node_relu_43\n",
       "                   %\"relu_43\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_138\")\n",
       "            106 |  # node_Conv_1965\n",
       "                   %\"getitem_141\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_43\", %\"features_extractor.6.3.conv2.weight\"{...}, %\"relu_43_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            107 |  # node_relu_44\n",
       "                   %\"relu_44\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_141\")\n",
       "            108 |  # node_Conv_1967\n",
       "                   %\"getitem_144\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_44\", %\"features_extractor.6.3.conv3.weight\"{...}, %\"relu_44_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            109 |  # node_add_894\n",
       "                   %\"add_894\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_144\", %\"relu_42\")\n",
       "            110 |  # node_relu_45\n",
       "                   %\"relu_45\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_894\")\n",
       "            111 |  # node_Conv_1969\n",
       "                   %\"getitem_147\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_45\", %\"features_extractor.6.4.conv1.weight\"{...}, %\"relu_45_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            112 |  # node_relu_46\n",
       "                   %\"relu_46\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_147\")\n",
       "            113 |  # node_Conv_1971\n",
       "                   %\"getitem_150\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_46\", %\"features_extractor.6.4.conv2.weight\"{...}, %\"relu_46_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            114 |  # node_relu_47\n",
       "                   %\"relu_47\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_150\")\n",
       "            115 |  # node_Conv_1973\n",
       "                   %\"getitem_153\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_47\", %\"features_extractor.6.4.conv3.weight\"{...}, %\"relu_47_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            116 |  # node_add_895\n",
       "                   %\"add_895\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_153\", %\"relu_45\")\n",
       "            117 |  # node_relu_48\n",
       "                   %\"relu_48\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_895\")\n",
       "            118 |  # node_Conv_1975\n",
       "                   %\"getitem_156\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_48\", %\"features_extractor.6.5.conv1.weight\"{...}, %\"relu_48_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            119 |  # node_relu_49\n",
       "                   %\"relu_49\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_156\")\n",
       "            120 |  # node_Conv_1977\n",
       "                   %\"getitem_159\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_49\", %\"features_extractor.6.5.conv2.weight\"{...}, %\"relu_49_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            121 |  # node_relu_50\n",
       "                   %\"relu_50\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_159\")\n",
       "            122 |  # node_Conv_1979\n",
       "                   %\"getitem_162\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_50\", %\"features_extractor.6.5.conv3.weight\"{...}, %\"relu_50_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            123 |  # node_add_896\n",
       "                   %\"add_896\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_162\", %\"relu_48\")\n",
       "            124 |  # node_relu_51\n",
       "                   %\"relu_51\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_896\")\n",
       "            125 |  # node_Conv_1981\n",
       "                   %\"getitem_165\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_51\", %\"features_extractor.6.6.conv1.weight\"{...}, %\"relu_51_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            126 |  # node_relu_52\n",
       "                   %\"relu_52\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_165\")\n",
       "            127 |  # node_Conv_1983\n",
       "                   %\"getitem_168\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_52\", %\"features_extractor.6.6.conv2.weight\"{...}, %\"relu_52_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            128 |  # node_relu_53\n",
       "                   %\"relu_53\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_168\")\n",
       "            129 |  # node_Conv_1985\n",
       "                   %\"getitem_171\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_53\", %\"features_extractor.6.6.conv3.weight\"{...}, %\"relu_53_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            130 |  # node_add_897\n",
       "                   %\"add_897\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_171\", %\"relu_51\")\n",
       "            131 |  # node_relu_54\n",
       "                   %\"relu_54\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_897\")\n",
       "            132 |  # node_Conv_1987\n",
       "                   %\"getitem_174\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_54\", %\"features_extractor.6.7.conv1.weight\"{...}, %\"relu_54_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            133 |  # node_relu_55\n",
       "                   %\"relu_55\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_174\")\n",
       "            134 |  # node_Conv_1989\n",
       "                   %\"getitem_177\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_55\", %\"features_extractor.6.7.conv2.weight\"{...}, %\"relu_55_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            135 |  # node_relu_56\n",
       "                   %\"relu_56\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_177\")\n",
       "            136 |  # node_Conv_1991\n",
       "                   %\"getitem_180\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_56\", %\"features_extractor.6.7.conv3.weight\"{...}, %\"relu_56_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            137 |  # node_add_898\n",
       "                   %\"add_898\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_180\", %\"relu_54\")\n",
       "            138 |  # node_relu_57\n",
       "                   %\"relu_57\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_898\")\n",
       "            139 |  # node_Conv_1993\n",
       "                   %\"getitem_183\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_57\", %\"features_extractor.6.8.conv1.weight\"{...}, %\"relu_57_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            140 |  # node_relu_58\n",
       "                   %\"relu_58\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_183\")\n",
       "            141 |  # node_Conv_1995\n",
       "                   %\"getitem_186\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_58\", %\"features_extractor.6.8.conv2.weight\"{...}, %\"relu_58_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            142 |  # node_relu_59\n",
       "                   %\"relu_59\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_186\")\n",
       "            143 |  # node_Conv_1997\n",
       "                   %\"getitem_189\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_59\", %\"features_extractor.6.8.conv3.weight\"{...}, %\"relu_59_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            144 |  # node_add_899\n",
       "                   %\"add_899\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_189\", %\"relu_57\")\n",
       "            145 |  # node_relu_60\n",
       "                   %\"relu_60\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_899\")\n",
       "            146 |  # node_Conv_1999\n",
       "                   %\"getitem_192\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_60\", %\"features_extractor.6.9.conv1.weight\"{...}, %\"relu_60_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            147 |  # node_relu_61\n",
       "                   %\"relu_61\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_192\")\n",
       "            148 |  # node_Conv_2001\n",
       "                   %\"getitem_195\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_61\", %\"features_extractor.6.9.conv2.weight\"{...}, %\"relu_61_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            149 |  # node_relu_62\n",
       "                   %\"relu_62\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_195\")\n",
       "            150 |  # node_Conv_2003\n",
       "                   %\"getitem_198\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_62\", %\"features_extractor.6.9.conv3.weight\"{...}, %\"relu_62_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            151 |  # node_add_900\n",
       "                   %\"add_900\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_198\", %\"relu_60\")\n",
       "            152 |  # node_relu_63\n",
       "                   %\"relu_63\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_900\")\n",
       "            153 |  # node_Conv_2005\n",
       "                   %\"getitem_201\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_63\", %\"features_extractor.6.10.conv1.weight\"{...}, %\"relu_63_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            154 |  # node_relu_64\n",
       "                   %\"relu_64\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_201\")\n",
       "            155 |  # node_Conv_2007\n",
       "                   %\"getitem_204\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_64\", %\"features_extractor.6.10.conv2.weight\"{...}, %\"relu_64_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            156 |  # node_relu_65\n",
       "                   %\"relu_65\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_204\")\n",
       "            157 |  # node_Conv_2009\n",
       "                   %\"getitem_207\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_65\", %\"features_extractor.6.10.conv3.weight\"{...}, %\"relu_65_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            158 |  # node_add_901\n",
       "                   %\"add_901\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_207\", %\"relu_63\")\n",
       "            159 |  # node_relu_66\n",
       "                   %\"relu_66\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_901\")\n",
       "            160 |  # node_Conv_2011\n",
       "                   %\"getitem_210\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_66\", %\"features_extractor.6.11.conv1.weight\"{...}, %\"relu_66_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            161 |  # node_relu_67\n",
       "                   %\"relu_67\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_210\")\n",
       "            162 |  # node_Conv_2013\n",
       "                   %\"getitem_213\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_67\", %\"features_extractor.6.11.conv2.weight\"{...}, %\"relu_67_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            163 |  # node_relu_68\n",
       "                   %\"relu_68\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_213\")\n",
       "            164 |  # node_Conv_2015\n",
       "                   %\"getitem_216\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_68\", %\"features_extractor.6.11.conv3.weight\"{...}, %\"relu_68_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            165 |  # node_add_902\n",
       "                   %\"add_902\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_216\", %\"relu_66\")\n",
       "            166 |  # node_relu_69\n",
       "                   %\"relu_69\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_902\")\n",
       "            167 |  # node_Conv_2017\n",
       "                   %\"getitem_219\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_69\", %\"features_extractor.6.12.conv1.weight\"{...}, %\"relu_69_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            168 |  # node_relu_70\n",
       "                   %\"relu_70\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_219\")\n",
       "            169 |  # node_Conv_2019\n",
       "                   %\"getitem_222\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_70\", %\"features_extractor.6.12.conv2.weight\"{...}, %\"relu_70_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            170 |  # node_relu_71\n",
       "                   %\"relu_71\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_222\")\n",
       "            171 |  # node_Conv_2021\n",
       "                   %\"getitem_225\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_71\", %\"features_extractor.6.12.conv3.weight\"{...}, %\"relu_71_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            172 |  # node_add_903\n",
       "                   %\"add_903\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_225\", %\"relu_69\")\n",
       "            173 |  # node_relu_72\n",
       "                   %\"relu_72\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_903\")\n",
       "            174 |  # node_Conv_2023\n",
       "                   %\"getitem_228\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_72\", %\"features_extractor.6.13.conv1.weight\"{...}, %\"relu_72_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            175 |  # node_relu_73\n",
       "                   %\"relu_73\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_228\")\n",
       "            176 |  # node_Conv_2025\n",
       "                   %\"getitem_231\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_73\", %\"features_extractor.6.13.conv2.weight\"{...}, %\"relu_73_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            177 |  # node_relu_74\n",
       "                   %\"relu_74\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_231\")\n",
       "            178 |  # node_Conv_2027\n",
       "                   %\"getitem_234\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_74\", %\"features_extractor.6.13.conv3.weight\"{...}, %\"relu_74_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            179 |  # node_add_904\n",
       "                   %\"add_904\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_234\", %\"relu_72\")\n",
       "            180 |  # node_relu_75\n",
       "                   %\"relu_75\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_904\")\n",
       "            181 |  # node_Conv_2029\n",
       "                   %\"getitem_237\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_75\", %\"features_extractor.6.14.conv1.weight\"{...}, %\"relu_75_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            182 |  # node_relu_76\n",
       "                   %\"relu_76\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_237\")\n",
       "            183 |  # node_Conv_2031\n",
       "                   %\"getitem_240\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_76\", %\"features_extractor.6.14.conv2.weight\"{...}, %\"relu_76_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            184 |  # node_relu_77\n",
       "                   %\"relu_77\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_240\")\n",
       "            185 |  # node_Conv_2033\n",
       "                   %\"getitem_243\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_77\", %\"features_extractor.6.14.conv3.weight\"{...}, %\"relu_77_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            186 |  # node_add_905\n",
       "                   %\"add_905\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_243\", %\"relu_75\")\n",
       "            187 |  # node_relu_78\n",
       "                   %\"relu_78\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_905\")\n",
       "            188 |  # node_Conv_2035\n",
       "                   %\"getitem_246\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_78\", %\"features_extractor.6.15.conv1.weight\"{...}, %\"relu_78_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            189 |  # node_relu_79\n",
       "                   %\"relu_79\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_246\")\n",
       "            190 |  # node_Conv_2037\n",
       "                   %\"getitem_249\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_79\", %\"features_extractor.6.15.conv2.weight\"{...}, %\"relu_79_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            191 |  # node_relu_80\n",
       "                   %\"relu_80\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_249\")\n",
       "            192 |  # node_Conv_2039\n",
       "                   %\"getitem_252\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_80\", %\"features_extractor.6.15.conv3.weight\"{...}, %\"relu_80_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            193 |  # node_add_906\n",
       "                   %\"add_906\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_252\", %\"relu_78\")\n",
       "            194 |  # node_relu_81\n",
       "                   %\"relu_81\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_906\")\n",
       "            195 |  # node_Conv_2041\n",
       "                   %\"getitem_255\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_81\", %\"features_extractor.6.16.conv1.weight\"{...}, %\"relu_81_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            196 |  # node_relu_82\n",
       "                   %\"relu_82\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_255\")\n",
       "            197 |  # node_Conv_2043\n",
       "                   %\"getitem_258\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_82\", %\"features_extractor.6.16.conv2.weight\"{...}, %\"relu_82_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            198 |  # node_relu_83\n",
       "                   %\"relu_83\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_258\")\n",
       "            199 |  # node_Conv_2045\n",
       "                   %\"getitem_261\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_83\", %\"features_extractor.6.16.conv3.weight\"{...}, %\"relu_83_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            200 |  # node_add_907\n",
       "                   %\"add_907\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_261\", %\"relu_81\")\n",
       "            201 |  # node_relu_84\n",
       "                   %\"relu_84\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_907\")\n",
       "            202 |  # node_Conv_2047\n",
       "                   %\"getitem_264\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_84\", %\"features_extractor.6.17.conv1.weight\"{...}, %\"relu_84_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            203 |  # node_relu_85\n",
       "                   %\"relu_85\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_264\")\n",
       "            204 |  # node_Conv_2049\n",
       "                   %\"getitem_267\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_85\", %\"features_extractor.6.17.conv2.weight\"{...}, %\"relu_85_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            205 |  # node_relu_86\n",
       "                   %\"relu_86\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_267\")\n",
       "            206 |  # node_Conv_2051\n",
       "                   %\"getitem_270\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_86\", %\"features_extractor.6.17.conv3.weight\"{...}, %\"relu_86_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            207 |  # node_add_908\n",
       "                   %\"add_908\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_270\", %\"relu_84\")\n",
       "            208 |  # node_relu_87\n",
       "                   %\"relu_87\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_908\")\n",
       "            209 |  # node_Conv_2053\n",
       "                   %\"getitem_273\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_87\", %\"features_extractor.6.18.conv1.weight\"{...}, %\"relu_87_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            210 |  # node_relu_88\n",
       "                   %\"relu_88\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_273\")\n",
       "            211 |  # node_Conv_2055\n",
       "                   %\"getitem_276\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_88\", %\"features_extractor.6.18.conv2.weight\"{...}, %\"relu_88_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            212 |  # node_relu_89\n",
       "                   %\"relu_89\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_276\")\n",
       "            213 |  # node_Conv_2057\n",
       "                   %\"getitem_279\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_89\", %\"features_extractor.6.18.conv3.weight\"{...}, %\"relu_89_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            214 |  # node_add_909\n",
       "                   %\"add_909\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_279\", %\"relu_87\")\n",
       "            215 |  # node_relu_90\n",
       "                   %\"relu_90\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_909\")\n",
       "            216 |  # node_Conv_2059\n",
       "                   %\"getitem_282\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_90\", %\"features_extractor.6.19.conv1.weight\"{...}, %\"relu_90_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            217 |  # node_relu_91\n",
       "                   %\"relu_91\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_282\")\n",
       "            218 |  # node_Conv_2061\n",
       "                   %\"getitem_285\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_91\", %\"features_extractor.6.19.conv2.weight\"{...}, %\"relu_91_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            219 |  # node_relu_92\n",
       "                   %\"relu_92\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_285\")\n",
       "            220 |  # node_Conv_2063\n",
       "                   %\"getitem_288\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_92\", %\"features_extractor.6.19.conv3.weight\"{...}, %\"relu_92_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            221 |  # node_add_910\n",
       "                   %\"add_910\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_288\", %\"relu_90\")\n",
       "            222 |  # node_relu_93\n",
       "                   %\"relu_93\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_910\")\n",
       "            223 |  # node_Conv_2065\n",
       "                   %\"getitem_291\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_93\", %\"features_extractor.6.20.conv1.weight\"{...}, %\"relu_93_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            224 |  # node_relu_94\n",
       "                   %\"relu_94\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_291\")\n",
       "            225 |  # node_Conv_2067\n",
       "                   %\"getitem_294\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_94\", %\"features_extractor.6.20.conv2.weight\"{...}, %\"relu_94_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            226 |  # node_relu_95\n",
       "                   %\"relu_95\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_294\")\n",
       "            227 |  # node_Conv_2069\n",
       "                   %\"getitem_297\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_95\", %\"features_extractor.6.20.conv3.weight\"{...}, %\"relu_95_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            228 |  # node_add_911\n",
       "                   %\"add_911\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_297\", %\"relu_93\")\n",
       "            229 |  # node_relu_96\n",
       "                   %\"relu_96\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_911\")\n",
       "            230 |  # node_Conv_2071\n",
       "                   %\"getitem_300\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_96\", %\"features_extractor.6.21.conv1.weight\"{...}, %\"relu_96_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            231 |  # node_relu_97\n",
       "                   %\"relu_97\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_300\")\n",
       "            232 |  # node_Conv_2073\n",
       "                   %\"getitem_303\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_97\", %\"features_extractor.6.21.conv2.weight\"{...}, %\"relu_97_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            233 |  # node_relu_98\n",
       "                   %\"relu_98\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_303\")\n",
       "            234 |  # node_Conv_2075\n",
       "                   %\"getitem_306\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_98\", %\"features_extractor.6.21.conv3.weight\"{...}, %\"relu_98_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            235 |  # node_add_912\n",
       "                   %\"add_912\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_306\", %\"relu_96\")\n",
       "            236 |  # node_relu_99\n",
       "                   %\"relu_99\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_912\")\n",
       "            237 |  # node_Conv_2077\n",
       "                   %\"getitem_309\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_99\", %\"features_extractor.6.22.conv1.weight\"{...}, %\"relu_99_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            238 |  # node_relu_100\n",
       "                   %\"relu_100\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_309\")\n",
       "            239 |  # node_Conv_2079\n",
       "                   %\"getitem_312\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_100\", %\"features_extractor.6.22.conv2.weight\"{...}, %\"relu_100_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            240 |  # node_relu_101\n",
       "                   %\"relu_101\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_312\")\n",
       "            241 |  # node_Conv_2081\n",
       "                   %\"getitem_315\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_101\", %\"features_extractor.6.22.conv3.weight\"{...}, %\"relu_101_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            242 |  # node_add_913\n",
       "                   %\"add_913\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_315\", %\"relu_99\")\n",
       "            243 |  # node_relu_102\n",
       "                   %\"relu_102\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_913\")\n",
       "            244 |  # node_Conv_2083\n",
       "                   %\"getitem_318\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_102\", %\"features_extractor.6.23.conv1.weight\"{...}, %\"relu_102_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            245 |  # node_relu_103\n",
       "                   %\"relu_103\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_318\")\n",
       "            246 |  # node_Conv_2085\n",
       "                   %\"getitem_321\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_103\", %\"features_extractor.6.23.conv2.weight\"{...}, %\"relu_103_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            247 |  # node_relu_104\n",
       "                   %\"relu_104\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_321\")\n",
       "            248 |  # node_Conv_2087\n",
       "                   %\"getitem_324\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_104\", %\"features_extractor.6.23.conv3.weight\"{...}, %\"relu_104_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            249 |  # node_add_914\n",
       "                   %\"add_914\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_324\", %\"relu_102\")\n",
       "            250 |  # node_relu_105\n",
       "                   %\"relu_105\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_914\")\n",
       "            251 |  # node_Conv_2089\n",
       "                   %\"getitem_327\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_105\", %\"features_extractor.6.24.conv1.weight\"{...}, %\"relu_105_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            252 |  # node_relu_106\n",
       "                   %\"relu_106\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_327\")\n",
       "            253 |  # node_Conv_2091\n",
       "                   %\"getitem_330\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_106\", %\"features_extractor.6.24.conv2.weight\"{...}, %\"relu_106_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            254 |  # node_relu_107\n",
       "                   %\"relu_107\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_330\")\n",
       "            255 |  # node_Conv_2093\n",
       "                   %\"getitem_333\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_107\", %\"features_extractor.6.24.conv3.weight\"{...}, %\"relu_107_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            256 |  # node_add_915\n",
       "                   %\"add_915\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_333\", %\"relu_105\")\n",
       "            257 |  # node_relu_108\n",
       "                   %\"relu_108\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_915\")\n",
       "            258 |  # node_Conv_2095\n",
       "                   %\"getitem_336\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_108\", %\"features_extractor.6.25.conv1.weight\"{...}, %\"relu_108_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            259 |  # node_relu_109\n",
       "                   %\"relu_109\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_336\")\n",
       "            260 |  # node_Conv_2097\n",
       "                   %\"getitem_339\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_109\", %\"features_extractor.6.25.conv2.weight\"{...}, %\"relu_109_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            261 |  # node_relu_110\n",
       "                   %\"relu_110\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_339\")\n",
       "            262 |  # node_Conv_2099\n",
       "                   %\"getitem_342\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_110\", %\"features_extractor.6.25.conv3.weight\"{...}, %\"relu_110_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            263 |  # node_add_916\n",
       "                   %\"add_916\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_342\", %\"relu_108\")\n",
       "            264 |  # node_relu_111\n",
       "                   %\"relu_111\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_916\")\n",
       "            265 |  # node_Conv_2101\n",
       "                   %\"getitem_345\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_111\", %\"features_extractor.6.26.conv1.weight\"{...}, %\"relu_111_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            266 |  # node_relu_112\n",
       "                   %\"relu_112\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_345\")\n",
       "            267 |  # node_Conv_2103\n",
       "                   %\"getitem_348\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_112\", %\"features_extractor.6.26.conv2.weight\"{...}, %\"relu_112_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            268 |  # node_relu_113\n",
       "                   %\"relu_113\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_348\")\n",
       "            269 |  # node_Conv_2105\n",
       "                   %\"getitem_351\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_113\", %\"features_extractor.6.26.conv3.weight\"{...}, %\"relu_113_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            270 |  # node_add_917\n",
       "                   %\"add_917\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_351\", %\"relu_111\")\n",
       "            271 |  # node_relu_114\n",
       "                   %\"relu_114\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_917\")\n",
       "            272 |  # node_Conv_2107\n",
       "                   %\"getitem_354\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_114\", %\"features_extractor.6.27.conv1.weight\"{...}, %\"relu_114_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            273 |  # node_relu_115\n",
       "                   %\"relu_115\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_354\")\n",
       "            274 |  # node_Conv_2109\n",
       "                   %\"getitem_357\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_115\", %\"features_extractor.6.27.conv2.weight\"{...}, %\"relu_115_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            275 |  # node_relu_116\n",
       "                   %\"relu_116\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_357\")\n",
       "            276 |  # node_Conv_2111\n",
       "                   %\"getitem_360\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_116\", %\"features_extractor.6.27.conv3.weight\"{...}, %\"relu_116_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            277 |  # node_add_918\n",
       "                   %\"add_918\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_360\", %\"relu_114\")\n",
       "            278 |  # node_relu_117\n",
       "                   %\"relu_117\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_918\")\n",
       "            279 |  # node_Conv_2113\n",
       "                   %\"getitem_363\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_117\", %\"features_extractor.6.28.conv1.weight\"{...}, %\"relu_117_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            280 |  # node_relu_118\n",
       "                   %\"relu_118\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_363\")\n",
       "            281 |  # node_Conv_2115\n",
       "                   %\"getitem_366\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_118\", %\"features_extractor.6.28.conv2.weight\"{...}, %\"relu_118_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            282 |  # node_relu_119\n",
       "                   %\"relu_119\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_366\")\n",
       "            283 |  # node_Conv_2117\n",
       "                   %\"getitem_369\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_119\", %\"features_extractor.6.28.conv3.weight\"{...}, %\"relu_119_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            284 |  # node_add_919\n",
       "                   %\"add_919\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_369\", %\"relu_117\")\n",
       "            285 |  # node_relu_120\n",
       "                   %\"relu_120\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_919\")\n",
       "            286 |  # node_Conv_2119\n",
       "                   %\"getitem_372\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_120\", %\"features_extractor.6.29.conv1.weight\"{...}, %\"relu_120_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            287 |  # node_relu_121\n",
       "                   %\"relu_121\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_372\")\n",
       "            288 |  # node_Conv_2121\n",
       "                   %\"getitem_375\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_121\", %\"features_extractor.6.29.conv2.weight\"{...}, %\"relu_121_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            289 |  # node_relu_122\n",
       "                   %\"relu_122\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_375\")\n",
       "            290 |  # node_Conv_2123\n",
       "                   %\"getitem_378\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_122\", %\"features_extractor.6.29.conv3.weight\"{...}, %\"relu_122_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            291 |  # node_add_920\n",
       "                   %\"add_920\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_378\", %\"relu_120\")\n",
       "            292 |  # node_relu_123\n",
       "                   %\"relu_123\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_920\")\n",
       "            293 |  # node_Conv_2125\n",
       "                   %\"getitem_381\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_123\", %\"features_extractor.6.30.conv1.weight\"{...}, %\"relu_123_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            294 |  # node_relu_124\n",
       "                   %\"relu_124\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_381\")\n",
       "            295 |  # node_Conv_2127\n",
       "                   %\"getitem_384\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_124\", %\"features_extractor.6.30.conv2.weight\"{...}, %\"relu_124_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            296 |  # node_relu_125\n",
       "                   %\"relu_125\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_384\")\n",
       "            297 |  # node_Conv_2129\n",
       "                   %\"getitem_387\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_125\", %\"features_extractor.6.30.conv3.weight\"{...}, %\"relu_125_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            298 |  # node_add_921\n",
       "                   %\"add_921\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_387\", %\"relu_123\")\n",
       "            299 |  # node_relu_126\n",
       "                   %\"relu_126\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_921\")\n",
       "            300 |  # node_Conv_2131\n",
       "                   %\"getitem_390\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_126\", %\"features_extractor.6.31.conv1.weight\"{...}, %\"relu_126_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            301 |  # node_relu_127\n",
       "                   %\"relu_127\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_390\")\n",
       "            302 |  # node_Conv_2133\n",
       "                   %\"getitem_393\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_127\", %\"features_extractor.6.31.conv2.weight\"{...}, %\"relu_127_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            303 |  # node_relu_128\n",
       "                   %\"relu_128\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_393\")\n",
       "            304 |  # node_Conv_2135\n",
       "                   %\"getitem_396\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_128\", %\"features_extractor.6.31.conv3.weight\"{...}, %\"relu_128_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            305 |  # node_add_922\n",
       "                   %\"add_922\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_396\", %\"relu_126\")\n",
       "            306 |  # node_relu_129\n",
       "                   %\"relu_129\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_922\")\n",
       "            307 |  # node_Conv_2137\n",
       "                   %\"getitem_399\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_129\", %\"features_extractor.6.32.conv1.weight\"{...}, %\"relu_129_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            308 |  # node_relu_130\n",
       "                   %\"relu_130\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_399\")\n",
       "            309 |  # node_Conv_2139\n",
       "                   %\"getitem_402\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_130\", %\"features_extractor.6.32.conv2.weight\"{...}, %\"relu_130_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            310 |  # node_relu_131\n",
       "                   %\"relu_131\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_402\")\n",
       "            311 |  # node_Conv_2141\n",
       "                   %\"getitem_405\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_131\", %\"features_extractor.6.32.conv3.weight\"{...}, %\"relu_131_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            312 |  # node_add_923\n",
       "                   %\"add_923\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_405\", %\"relu_129\")\n",
       "            313 |  # node_relu_132\n",
       "                   %\"relu_132\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_923\")\n",
       "            314 |  # node_Conv_2143\n",
       "                   %\"getitem_408\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_132\", %\"features_extractor.6.33.conv1.weight\"{...}, %\"relu_132_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            315 |  # node_relu_133\n",
       "                   %\"relu_133\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_408\")\n",
       "            316 |  # node_Conv_2145\n",
       "                   %\"getitem_411\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_133\", %\"features_extractor.6.33.conv2.weight\"{...}, %\"relu_133_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            317 |  # node_relu_134\n",
       "                   %\"relu_134\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_411\")\n",
       "            318 |  # node_Conv_2147\n",
       "                   %\"getitem_414\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_134\", %\"features_extractor.6.33.conv3.weight\"{...}, %\"relu_134_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            319 |  # node_add_924\n",
       "                   %\"add_924\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_414\", %\"relu_132\")\n",
       "            320 |  # node_relu_135\n",
       "                   %\"relu_135\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_924\")\n",
       "            321 |  # node_Conv_2149\n",
       "                   %\"getitem_417\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_135\", %\"features_extractor.6.34.conv1.weight\"{...}, %\"relu_135_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            322 |  # node_relu_136\n",
       "                   %\"relu_136\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_417\")\n",
       "            323 |  # node_Conv_2151\n",
       "                   %\"getitem_420\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_136\", %\"features_extractor.6.34.conv2.weight\"{...}, %\"relu_136_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            324 |  # node_relu_137\n",
       "                   %\"relu_137\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_420\")\n",
       "            325 |  # node_Conv_2153\n",
       "                   %\"getitem_423\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_137\", %\"features_extractor.6.34.conv3.weight\"{...}, %\"relu_137_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            326 |  # node_add_925\n",
       "                   %\"add_925\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_423\", %\"relu_135\")\n",
       "            327 |  # node_relu_138\n",
       "                   %\"relu_138\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_925\")\n",
       "            328 |  # node_Conv_2155\n",
       "                   %\"getitem_426\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_138\", %\"features_extractor.6.35.conv1.weight\"{...}, %\"relu_138_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            329 |  # node_relu_139\n",
       "                   %\"relu_139\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_426\")\n",
       "            330 |  # node_Conv_2157\n",
       "                   %\"getitem_429\"<FLOAT,[1,256,14,14]>  ::Conv(%\"relu_139\", %\"features_extractor.6.35.conv2.weight\"{...}, %\"relu_139_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            331 |  # node_relu_140\n",
       "                   %\"relu_140\"<FLOAT,[1,256,14,14]>  ::Relu(%\"getitem_429\")\n",
       "            332 |  # node_Conv_2159\n",
       "                   %\"getitem_432\"<FLOAT,[1,1024,14,14]>  ::Conv(%\"relu_140\", %\"features_extractor.6.35.conv3.weight\"{...}, %\"relu_140_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            333 |  # node_add_926\n",
       "                   %\"add_926\"<FLOAT,[1,1024,14,14]>  ::Add(%\"getitem_432\", %\"relu_138\")\n",
       "            334 |  # node_relu_141\n",
       "                   %\"relu_141\"<FLOAT,[1,1024,14,14]>  ::Relu(%\"add_926\")\n",
       "            335 |  # node_Conv_2161\n",
       "                   %\"getitem_435\"<FLOAT,[1,512,14,14]>  ::Conv(%\"relu_141\", %\"features_extractor.7.0.conv1.weight\"{...}, %\"relu_141_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            336 |  # node_relu_142\n",
       "                   %\"relu_142\"<FLOAT,[1,512,14,14]>  ::Relu(%\"getitem_435\")\n",
       "            337 |  # node_Conv_2163\n",
       "                   %\"getitem_438\"<FLOAT,[1,512,7,7]>  ::Conv(%\"relu_142\", %\"features_extractor.7.0.conv2.weight\"{...}, %\"relu_142_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(1, 1, 1, 1)}\n",
       "            338 |  # node_relu_143\n",
       "                   %\"relu_143\"<FLOAT,[1,512,7,7]>  ::Relu(%\"getitem_438\")\n",
       "            339 |  # node_Conv_2165\n",
       "                   %\"getitem_441\"<FLOAT,[1,2048,7,7]>  ::Conv(%\"relu_143\", %\"features_extractor.7.0.conv3.weight\"{...}, %\"relu_143_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            340 |  # node_Conv_2167\n",
       "                   %\"getitem_444\"<FLOAT,[1,2048,7,7]>  ::Conv(%\"relu_141\", %\"features_extractor.7.0.downsample.0.weight\"{...}, %\"relu_141_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(2, 2), pads=(0, 0, 0, 0)}\n",
       "            341 |  # node_add_927\n",
       "                   %\"add_927\"<FLOAT,[1,2048,7,7]>  ::Add(%\"getitem_441\", %\"getitem_444\")\n",
       "            342 |  # node_relu_144\n",
       "                   %\"relu_144\"<FLOAT,[1,2048,7,7]>  ::Relu(%\"add_927\")\n",
       "            343 |  # node_Conv_2169\n",
       "                   %\"getitem_447\"<FLOAT,[1,512,7,7]>  ::Conv(%\"relu_144\", %\"features_extractor.7.1.conv1.weight\"{...}, %\"relu_144_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            344 |  # node_relu_145\n",
       "                   %\"relu_145\"<FLOAT,[1,512,7,7]>  ::Relu(%\"getitem_447\")\n",
       "            345 |  # node_Conv_2171\n",
       "                   %\"getitem_450\"<FLOAT,[1,512,7,7]>  ::Conv(%\"relu_145\", %\"features_extractor.7.1.conv2.weight\"{...}, %\"relu_145_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            346 |  # node_relu_146\n",
       "                   %\"relu_146\"<FLOAT,[1,512,7,7]>  ::Relu(%\"getitem_450\")\n",
       "            347 |  # node_Conv_2173\n",
       "                   %\"getitem_453\"<FLOAT,[1,2048,7,7]>  ::Conv(%\"relu_146\", %\"features_extractor.7.1.conv3.weight\"{...}, %\"relu_146_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            348 |  # node_add_928\n",
       "                   %\"add_928\"<FLOAT,[1,2048,7,7]>  ::Add(%\"getitem_453\", %\"relu_144\")\n",
       "            349 |  # node_relu_147\n",
       "                   %\"relu_147\"<FLOAT,[1,2048,7,7]>  ::Relu(%\"add_928\")\n",
       "            350 |  # node_Conv_2175\n",
       "                   %\"getitem_456\"<FLOAT,[1,512,7,7]>  ::Conv(%\"relu_147\", %\"features_extractor.7.2.conv1.weight\"{...}, %\"relu_147_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            351 |  # node_relu_148\n",
       "                   %\"relu_148\"<FLOAT,[1,512,7,7]>  ::Relu(%\"getitem_456\")\n",
       "            352 |  # node_Conv_2177\n",
       "                   %\"getitem_459\"<FLOAT,[1,512,7,7]>  ::Conv(%\"relu_148\", %\"features_extractor.7.2.conv2.weight\"{...}, %\"relu_148_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(1, 1, 1, 1)}\n",
       "            353 |  # node_relu_149\n",
       "                   %\"relu_149\"<FLOAT,[1,512,7,7]>  ::Relu(%\"getitem_459\")\n",
       "            354 |  # node_Conv_2179\n",
       "                   %\"getitem_462\"<FLOAT,[1,2048,7,7]>  ::Conv(%\"relu_149\", %\"features_extractor.7.2.conv3.weight\"{...}, %\"relu_149_bias\"{...}) {group=1, auto_pad='NOTSET', dilations=(1, 1), strides=(1, 1), pads=(0, 0, 0, 0)}\n",
       "            355 |  # node_add_929\n",
       "                   %\"add_929\"<FLOAT,[1,2048,7,7]>  ::Add(%\"getitem_462\", %\"relu_147\")\n",
       "            356 |  # node_relu_150\n",
       "                   %\"relu_150\"<FLOAT,[1,2048,7,7]>  ::Relu(%\"add_929\")\n",
       "            357 |  # node_mean\n",
       "                   %\"mean\"<FLOAT,[1,2048,1,1]>  ::ReduceMean(%\"relu_150\", %\"val_1401\"{[-1, -2]}) {keepdims=1, noop_with_empty_axes=0}\n",
       "            358 |  # node_view\n",
       "                   %\"view\"<FLOAT,[1,2048]>  ::Reshape(%\"mean\", %\"val_1405\"{[1, 2048]}) {allowzero=1}\n",
       "            359 |  # node_linear\n",
       "                   %\"output\"<FLOAT,[1,131]>  ::Gemm(%\"view\", %\"output_layer.weight\"{...}, %\"output_layer.bias\"{...}) {transA=0, transB=1, alpha=1.0, beta=1.0}\n",
       "            return %\"output\"<FLOAT,[1,131]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_base_model_conv1_weight: \"f32[64, 3, 7, 7]\", p_base_model_bn1_weight: \"f32[64]\", p_base_model_bn1_bias: \"f32[64]\", p_base_model_layer1_0_conv1_weight: \"f32[64, 64, 1, 1]\", p_base_model_layer1_0_bn1_weight: \"f32[64]\", p_base_model_layer1_0_bn1_bias: \"f32[64]\", p_base_model_layer1_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_base_model_layer1_0_bn2_weight: \"f32[64]\", p_base_model_layer1_0_bn2_bias: \"f32[64]\", p_base_model_layer1_0_conv3_weight: \"f32[256, 64, 1, 1]\", p_base_model_layer1_0_bn3_weight: \"f32[256]\", p_base_model_layer1_0_bn3_bias: \"f32[256]\", p_base_model_layer1_0_downsample_0_weight: \"f32[256, 64, 1, 1]\", p_base_model_layer1_0_downsample_1_weight: \"f32[256]\", p_base_model_layer1_0_downsample_1_bias: \"f32[256]\", p_base_model_layer1_1_conv1_weight: \"f32[64, 256, 1, 1]\", p_base_model_layer1_1_bn1_weight: \"f32[64]\", p_base_model_layer1_1_bn1_bias: \"f32[64]\", p_base_model_layer1_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_base_model_layer1_1_bn2_weight: \"f32[64]\", p_base_model_layer1_1_bn2_bias: \"f32[64]\", p_base_model_layer1_1_conv3_weight: \"f32[256, 64, 1, 1]\", p_base_model_layer1_1_bn3_weight: \"f32[256]\", p_base_model_layer1_1_bn3_bias: \"f32[256]\", p_base_model_layer1_2_conv1_weight: \"f32[64, 256, 1, 1]\", p_base_model_layer1_2_bn1_weight: \"f32[64]\", p_base_model_layer1_2_bn1_bias: \"f32[64]\", p_base_model_layer1_2_conv2_weight: \"f32[64, 64, 3, 3]\", p_base_model_layer1_2_bn2_weight: \"f32[64]\", p_base_model_layer1_2_bn2_bias: \"f32[64]\", p_base_model_layer1_2_conv3_weight: \"f32[256, 64, 1, 1]\", p_base_model_layer1_2_bn3_weight: \"f32[256]\", p_base_model_layer1_2_bn3_bias: \"f32[256]\", p_base_model_layer2_0_conv1_weight: \"f32[128, 256, 1, 1]\", p_base_model_layer2_0_bn1_weight: \"f32[128]\", p_base_model_layer2_0_bn1_bias: \"f32[128]\", p_base_model_layer2_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_0_bn2_weight: \"f32[128]\", p_base_model_layer2_0_bn2_bias: \"f32[128]\", p_base_model_layer2_0_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_0_bn3_weight: \"f32[512]\", p_base_model_layer2_0_bn3_bias: \"f32[512]\", p_base_model_layer2_0_downsample_0_weight: \"f32[512, 256, 1, 1]\", p_base_model_layer2_0_downsample_1_weight: \"f32[512]\", p_base_model_layer2_0_downsample_1_bias: \"f32[512]\", p_base_model_layer2_1_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_1_bn1_weight: \"f32[128]\", p_base_model_layer2_1_bn1_bias: \"f32[128]\", p_base_model_layer2_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_1_bn2_weight: \"f32[128]\", p_base_model_layer2_1_bn2_bias: \"f32[128]\", p_base_model_layer2_1_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_1_bn3_weight: \"f32[512]\", p_base_model_layer2_1_bn3_bias: \"f32[512]\", p_base_model_layer2_2_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_2_bn1_weight: \"f32[128]\", p_base_model_layer2_2_bn1_bias: \"f32[128]\", p_base_model_layer2_2_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_2_bn2_weight: \"f32[128]\", p_base_model_layer2_2_bn2_bias: \"f32[128]\", p_base_model_layer2_2_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_2_bn3_weight: \"f32[512]\", p_base_model_layer2_2_bn3_bias: \"f32[512]\", p_base_model_layer2_3_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_3_bn1_weight: \"f32[128]\", p_base_model_layer2_3_bn1_bias: \"f32[128]\", p_base_model_layer2_3_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_3_bn2_weight: \"f32[128]\", p_base_model_layer2_3_bn2_bias: \"f32[128]\", p_base_model_layer2_3_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_3_bn3_weight: \"f32[512]\", p_base_model_layer2_3_bn3_bias: \"f32[512]\", p_base_model_layer2_4_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_4_bn1_weight: \"f32[128]\", p_base_model_layer2_4_bn1_bias: \"f32[128]\", p_base_model_layer2_4_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_4_bn2_weight: \"f32[128]\", p_base_model_layer2_4_bn2_bias: \"f32[128]\", p_base_model_layer2_4_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_4_bn3_weight: \"f32[512]\", p_base_model_layer2_4_bn3_bias: \"f32[512]\", p_base_model_layer2_5_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_5_bn1_weight: \"f32[128]\", p_base_model_layer2_5_bn1_bias: \"f32[128]\", p_base_model_layer2_5_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_5_bn2_weight: \"f32[128]\", p_base_model_layer2_5_bn2_bias: \"f32[128]\", p_base_model_layer2_5_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_5_bn3_weight: \"f32[512]\", p_base_model_layer2_5_bn3_bias: \"f32[512]\", p_base_model_layer2_6_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_6_bn1_weight: \"f32[128]\", p_base_model_layer2_6_bn1_bias: \"f32[128]\", p_base_model_layer2_6_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_6_bn2_weight: \"f32[128]\", p_base_model_layer2_6_bn2_bias: \"f32[128]\", p_base_model_layer2_6_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_6_bn3_weight: \"f32[512]\", p_base_model_layer2_6_bn3_bias: \"f32[512]\", p_base_model_layer2_7_conv1_weight: \"f32[128, 512, 1, 1]\", p_base_model_layer2_7_bn1_weight: \"f32[128]\", p_base_model_layer2_7_bn1_bias: \"f32[128]\", p_base_model_layer2_7_conv2_weight: \"f32[128, 128, 3, 3]\", p_base_model_layer2_7_bn2_weight: \"f32[128]\", p_base_model_layer2_7_bn2_bias: \"f32[128]\", p_base_model_layer2_7_conv3_weight: \"f32[512, 128, 1, 1]\", p_base_model_layer2_7_bn3_weight: \"f32[512]\", p_base_model_layer2_7_bn3_bias: \"f32[512]\", p_base_model_layer3_0_conv1_weight: \"f32[256, 512, 1, 1]\", p_base_model_layer3_0_bn1_weight: \"f32[256]\", p_base_model_layer3_0_bn1_bias: \"f32[256]\", p_base_model_layer3_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_0_bn2_weight: \"f32[256]\", p_base_model_layer3_0_bn2_bias: \"f32[256]\", p_base_model_layer3_0_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_0_bn3_weight: \"f32[1024]\", p_base_model_layer3_0_bn3_bias: \"f32[1024]\", p_base_model_layer3_0_downsample_0_weight: \"f32[1024, 512, 1, 1]\", p_base_model_layer3_0_downsample_1_weight: \"f32[1024]\", p_base_model_layer3_0_downsample_1_bias: \"f32[1024]\", p_base_model_layer3_1_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_1_bn1_weight: \"f32[256]\", p_base_model_layer3_1_bn1_bias: \"f32[256]\", p_base_model_layer3_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_1_bn2_weight: \"f32[256]\", p_base_model_layer3_1_bn2_bias: \"f32[256]\", p_base_model_layer3_1_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_1_bn3_weight: \"f32[1024]\", p_base_model_layer3_1_bn3_bias: \"f32[1024]\", p_base_model_layer3_2_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_2_bn1_weight: \"f32[256]\", p_base_model_layer3_2_bn1_bias: \"f32[256]\", p_base_model_layer3_2_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_2_bn2_weight: \"f32[256]\", p_base_model_layer3_2_bn2_bias: \"f32[256]\", p_base_model_layer3_2_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_2_bn3_weight: \"f32[1024]\", p_base_model_layer3_2_bn3_bias: \"f32[1024]\", p_base_model_layer3_3_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_3_bn1_weight: \"f32[256]\", p_base_model_layer3_3_bn1_bias: \"f32[256]\", p_base_model_layer3_3_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_3_bn2_weight: \"f32[256]\", p_base_model_layer3_3_bn2_bias: \"f32[256]\", p_base_model_layer3_3_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_3_bn3_weight: \"f32[1024]\", p_base_model_layer3_3_bn3_bias: \"f32[1024]\", p_base_model_layer3_4_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_4_bn1_weight: \"f32[256]\", p_base_model_layer3_4_bn1_bias: \"f32[256]\", p_base_model_layer3_4_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_4_bn2_weight: \"f32[256]\", p_base_model_layer3_4_bn2_bias: \"f32[256]\", p_base_model_layer3_4_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_4_bn3_weight: \"f32[1024]\", p_base_model_layer3_4_bn3_bias: \"f32[1024]\", p_base_model_layer3_5_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_5_bn1_weight: \"f32[256]\", p_base_model_layer3_5_bn1_bias: \"f32[256]\", p_base_model_layer3_5_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_5_bn2_weight: \"f32[256]\", p_base_model_layer3_5_bn2_bias: \"f32[256]\", p_base_model_layer3_5_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_5_bn3_weight: \"f32[1024]\", p_base_model_layer3_5_bn3_bias: \"f32[1024]\", p_base_model_layer3_6_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_6_bn1_weight: \"f32[256]\", p_base_model_layer3_6_bn1_bias: \"f32[256]\", p_base_model_layer3_6_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_6_bn2_weight: \"f32[256]\", p_base_model_layer3_6_bn2_bias: \"f32[256]\", p_base_model_layer3_6_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_6_bn3_weight: \"f32[1024]\", p_base_model_layer3_6_bn3_bias: \"f32[1024]\", p_base_model_layer3_7_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_7_bn1_weight: \"f32[256]\", p_base_model_layer3_7_bn1_bias: \"f32[256]\", p_base_model_layer3_7_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_7_bn2_weight: \"f32[256]\", p_base_model_layer3_7_bn2_bias: \"f32[256]\", p_base_model_layer3_7_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_7_bn3_weight: \"f32[1024]\", p_base_model_layer3_7_bn3_bias: \"f32[1024]\", p_base_model_layer3_8_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_8_bn1_weight: \"f32[256]\", p_base_model_layer3_8_bn1_bias: \"f32[256]\", p_base_model_layer3_8_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_8_bn2_weight: \"f32[256]\", p_base_model_layer3_8_bn2_bias: \"f32[256]\", p_base_model_layer3_8_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_8_bn3_weight: \"f32[1024]\", p_base_model_layer3_8_bn3_bias: \"f32[1024]\", p_base_model_layer3_9_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_9_bn1_weight: \"f32[256]\", p_base_model_layer3_9_bn1_bias: \"f32[256]\", p_base_model_layer3_9_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_9_bn2_weight: \"f32[256]\", p_base_model_layer3_9_bn2_bias: \"f32[256]\", p_base_model_layer3_9_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_9_bn3_weight: \"f32[1024]\", p_base_model_layer3_9_bn3_bias: \"f32[1024]\", p_base_model_layer3_10_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_10_bn1_weight: \"f32[256]\", p_base_model_layer3_10_bn1_bias: \"f32[256]\", p_base_model_layer3_10_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_10_bn2_weight: \"f32[256]\", p_base_model_layer3_10_bn2_bias: \"f32[256]\", p_base_model_layer3_10_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_10_bn3_weight: \"f32[1024]\", p_base_model_layer3_10_bn3_bias: \"f32[1024]\", p_base_model_layer3_11_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_11_bn1_weight: \"f32[256]\", p_base_model_layer3_11_bn1_bias: \"f32[256]\", p_base_model_layer3_11_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_11_bn2_weight: \"f32[256]\", p_base_model_layer3_11_bn2_bias: \"f32[256]\", p_base_model_layer3_11_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_11_bn3_weight: \"f32[1024]\", p_base_model_layer3_11_bn3_bias: \"f32[1024]\", p_base_model_layer3_12_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_12_bn1_weight: \"f32[256]\", p_base_model_layer3_12_bn1_bias: \"f32[256]\", p_base_model_layer3_12_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_12_bn2_weight: \"f32[256]\", p_base_model_layer3_12_bn2_bias: \"f32[256]\", p_base_model_layer3_12_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_12_bn3_weight: \"f32[1024]\", p_base_model_layer3_12_bn3_bias: \"f32[1024]\", p_base_model_layer3_13_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_13_bn1_weight: \"f32[256]\", p_base_model_layer3_13_bn1_bias: \"f32[256]\", p_base_model_layer3_13_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_13_bn2_weight: \"f32[256]\", p_base_model_layer3_13_bn2_bias: \"f32[256]\", p_base_model_layer3_13_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_13_bn3_weight: \"f32[1024]\", p_base_model_layer3_13_bn3_bias: \"f32[1024]\", p_base_model_layer3_14_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_14_bn1_weight: \"f32[256]\", p_base_model_layer3_14_bn1_bias: \"f32[256]\", p_base_model_layer3_14_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_14_bn2_weight: \"f32[256]\", p_base_model_layer3_14_bn2_bias: \"f32[256]\", p_base_model_layer3_14_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_14_bn3_weight: \"f32[1024]\", p_base_model_layer3_14_bn3_bias: \"f32[1024]\", p_base_model_layer3_15_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_15_bn1_weight: \"f32[256]\", p_base_model_layer3_15_bn1_bias: \"f32[256]\", p_base_model_layer3_15_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_15_bn2_weight: \"f32[256]\", p_base_model_layer3_15_bn2_bias: \"f32[256]\", p_base_model_layer3_15_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_15_bn3_weight: \"f32[1024]\", p_base_model_layer3_15_bn3_bias: \"f32[1024]\", p_base_model_layer3_16_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_16_bn1_weight: \"f32[256]\", p_base_model_layer3_16_bn1_bias: \"f32[256]\", p_base_model_layer3_16_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_16_bn2_weight: \"f32[256]\", p_base_model_layer3_16_bn2_bias: \"f32[256]\", p_base_model_layer3_16_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_16_bn3_weight: \"f32[1024]\", p_base_model_layer3_16_bn3_bias: \"f32[1024]\", p_base_model_layer3_17_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_17_bn1_weight: \"f32[256]\", p_base_model_layer3_17_bn1_bias: \"f32[256]\", p_base_model_layer3_17_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_17_bn2_weight: \"f32[256]\", p_base_model_layer3_17_bn2_bias: \"f32[256]\", p_base_model_layer3_17_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_17_bn3_weight: \"f32[1024]\", p_base_model_layer3_17_bn3_bias: \"f32[1024]\", p_base_model_layer3_18_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_18_bn1_weight: \"f32[256]\", p_base_model_layer3_18_bn1_bias: \"f32[256]\", p_base_model_layer3_18_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_18_bn2_weight: \"f32[256]\", p_base_model_layer3_18_bn2_bias: \"f32[256]\", p_base_model_layer3_18_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_18_bn3_weight: \"f32[1024]\", p_base_model_layer3_18_bn3_bias: \"f32[1024]\", p_base_model_layer3_19_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_19_bn1_weight: \"f32[256]\", p_base_model_layer3_19_bn1_bias: \"f32[256]\", p_base_model_layer3_19_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_19_bn2_weight: \"f32[256]\", p_base_model_layer3_19_bn2_bias: \"f32[256]\", p_base_model_layer3_19_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_19_bn3_weight: \"f32[1024]\", p_base_model_layer3_19_bn3_bias: \"f32[1024]\", p_base_model_layer3_20_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_20_bn1_weight: \"f32[256]\", p_base_model_layer3_20_bn1_bias: \"f32[256]\", p_base_model_layer3_20_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_20_bn2_weight: \"f32[256]\", p_base_model_layer3_20_bn2_bias: \"f32[256]\", p_base_model_layer3_20_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_20_bn3_weight: \"f32[1024]\", p_base_model_layer3_20_bn3_bias: \"f32[1024]\", p_base_model_layer3_21_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_21_bn1_weight: \"f32[256]\", p_base_model_layer3_21_bn1_bias: \"f32[256]\", p_base_model_layer3_21_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_21_bn2_weight: \"f32[256]\", p_base_model_layer3_21_bn2_bias: \"f32[256]\", p_base_model_layer3_21_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_21_bn3_weight: \"f32[1024]\", p_base_model_layer3_21_bn3_bias: \"f32[1024]\", p_base_model_layer3_22_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_22_bn1_weight: \"f32[256]\", p_base_model_layer3_22_bn1_bias: \"f32[256]\", p_base_model_layer3_22_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_22_bn2_weight: \"f32[256]\", p_base_model_layer3_22_bn2_bias: \"f32[256]\", p_base_model_layer3_22_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_22_bn3_weight: \"f32[1024]\", p_base_model_layer3_22_bn3_bias: \"f32[1024]\", p_base_model_layer3_23_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_23_bn1_weight: \"f32[256]\", p_base_model_layer3_23_bn1_bias: \"f32[256]\", p_base_model_layer3_23_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_23_bn2_weight: \"f32[256]\", p_base_model_layer3_23_bn2_bias: \"f32[256]\", p_base_model_layer3_23_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_23_bn3_weight: \"f32[1024]\", p_base_model_layer3_23_bn3_bias: \"f32[1024]\", p_base_model_layer3_24_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_24_bn1_weight: \"f32[256]\", p_base_model_layer3_24_bn1_bias: \"f32[256]\", p_base_model_layer3_24_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_24_bn2_weight: \"f32[256]\", p_base_model_layer3_24_bn2_bias: \"f32[256]\", p_base_model_layer3_24_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_24_bn3_weight: \"f32[1024]\", p_base_model_layer3_24_bn3_bias: \"f32[1024]\", p_base_model_layer3_25_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_25_bn1_weight: \"f32[256]\", p_base_model_layer3_25_bn1_bias: \"f32[256]\", p_base_model_layer3_25_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_25_bn2_weight: \"f32[256]\", p_base_model_layer3_25_bn2_bias: \"f32[256]\", p_base_model_layer3_25_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_25_bn3_weight: \"f32[1024]\", p_base_model_layer3_25_bn3_bias: \"f32[1024]\", p_base_model_layer3_26_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_26_bn1_weight: \"f32[256]\", p_base_model_layer3_26_bn1_bias: \"f32[256]\", p_base_model_layer3_26_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_26_bn2_weight: \"f32[256]\", p_base_model_layer3_26_bn2_bias: \"f32[256]\", p_base_model_layer3_26_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_26_bn3_weight: \"f32[1024]\", p_base_model_layer3_26_bn3_bias: \"f32[1024]\", p_base_model_layer3_27_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_27_bn1_weight: \"f32[256]\", p_base_model_layer3_27_bn1_bias: \"f32[256]\", p_base_model_layer3_27_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_27_bn2_weight: \"f32[256]\", p_base_model_layer3_27_bn2_bias: \"f32[256]\", p_base_model_layer3_27_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_27_bn3_weight: \"f32[1024]\", p_base_model_layer3_27_bn3_bias: \"f32[1024]\", p_base_model_layer3_28_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_28_bn1_weight: \"f32[256]\", p_base_model_layer3_28_bn1_bias: \"f32[256]\", p_base_model_layer3_28_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_28_bn2_weight: \"f32[256]\", p_base_model_layer3_28_bn2_bias: \"f32[256]\", p_base_model_layer3_28_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_28_bn3_weight: \"f32[1024]\", p_base_model_layer3_28_bn3_bias: \"f32[1024]\", p_base_model_layer3_29_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_29_bn1_weight: \"f32[256]\", p_base_model_layer3_29_bn1_bias: \"f32[256]\", p_base_model_layer3_29_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_29_bn2_weight: \"f32[256]\", p_base_model_layer3_29_bn2_bias: \"f32[256]\", p_base_model_layer3_29_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_29_bn3_weight: \"f32[1024]\", p_base_model_layer3_29_bn3_bias: \"f32[1024]\", p_base_model_layer3_30_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_30_bn1_weight: \"f32[256]\", p_base_model_layer3_30_bn1_bias: \"f32[256]\", p_base_model_layer3_30_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_30_bn2_weight: \"f32[256]\", p_base_model_layer3_30_bn2_bias: \"f32[256]\", p_base_model_layer3_30_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_30_bn3_weight: \"f32[1024]\", p_base_model_layer3_30_bn3_bias: \"f32[1024]\", p_base_model_layer3_31_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_31_bn1_weight: \"f32[256]\", p_base_model_layer3_31_bn1_bias: \"f32[256]\", p_base_model_layer3_31_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_31_bn2_weight: \"f32[256]\", p_base_model_layer3_31_bn2_bias: \"f32[256]\", p_base_model_layer3_31_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_31_bn3_weight: \"f32[1024]\", p_base_model_layer3_31_bn3_bias: \"f32[1024]\", p_base_model_layer3_32_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_32_bn1_weight: \"f32[256]\", p_base_model_layer3_32_bn1_bias: \"f32[256]\", p_base_model_layer3_32_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_32_bn2_weight: \"f32[256]\", p_base_model_layer3_32_bn2_bias: \"f32[256]\", p_base_model_layer3_32_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_32_bn3_weight: \"f32[1024]\", p_base_model_layer3_32_bn3_bias: \"f32[1024]\", p_base_model_layer3_33_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_33_bn1_weight: \"f32[256]\", p_base_model_layer3_33_bn1_bias: \"f32[256]\", p_base_model_layer3_33_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_33_bn2_weight: \"f32[256]\", p_base_model_layer3_33_bn2_bias: \"f32[256]\", p_base_model_layer3_33_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_33_bn3_weight: \"f32[1024]\", p_base_model_layer3_33_bn3_bias: \"f32[1024]\", p_base_model_layer3_34_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_34_bn1_weight: \"f32[256]\", p_base_model_layer3_34_bn1_bias: \"f32[256]\", p_base_model_layer3_34_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_34_bn2_weight: \"f32[256]\", p_base_model_layer3_34_bn2_bias: \"f32[256]\", p_base_model_layer3_34_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_34_bn3_weight: \"f32[1024]\", p_base_model_layer3_34_bn3_bias: \"f32[1024]\", p_base_model_layer3_35_conv1_weight: \"f32[256, 1024, 1, 1]\", p_base_model_layer3_35_bn1_weight: \"f32[256]\", p_base_model_layer3_35_bn1_bias: \"f32[256]\", p_base_model_layer3_35_conv2_weight: \"f32[256, 256, 3, 3]\", p_base_model_layer3_35_bn2_weight: \"f32[256]\", p_base_model_layer3_35_bn2_bias: \"f32[256]\", p_base_model_layer3_35_conv3_weight: \"f32[1024, 256, 1, 1]\", p_base_model_layer3_35_bn3_weight: \"f32[1024]\", p_base_model_layer3_35_bn3_bias: \"f32[1024]\", p_base_model_layer4_0_conv1_weight: \"f32[512, 1024, 1, 1]\", p_base_model_layer4_0_bn1_weight: \"f32[512]\", p_base_model_layer4_0_bn1_bias: \"f32[512]\", p_base_model_layer4_0_conv2_weight: \"f32[512, 512, 3, 3]\", p_base_model_layer4_0_bn2_weight: \"f32[512]\", p_base_model_layer4_0_bn2_bias: \"f32[512]\", p_base_model_layer4_0_conv3_weight: \"f32[2048, 512, 1, 1]\", p_base_model_layer4_0_bn3_weight: \"f32[2048]\", p_base_model_layer4_0_bn3_bias: \"f32[2048]\", p_base_model_layer4_0_downsample_0_weight: \"f32[2048, 1024, 1, 1]\", p_base_model_layer4_0_downsample_1_weight: \"f32[2048]\", p_base_model_layer4_0_downsample_1_bias: \"f32[2048]\", p_base_model_layer4_1_conv1_weight: \"f32[512, 2048, 1, 1]\", p_base_model_layer4_1_bn1_weight: \"f32[512]\", p_base_model_layer4_1_bn1_bias: \"f32[512]\", p_base_model_layer4_1_conv2_weight: \"f32[512, 512, 3, 3]\", p_base_model_layer4_1_bn2_weight: \"f32[512]\", p_base_model_layer4_1_bn2_bias: \"f32[512]\", p_base_model_layer4_1_conv3_weight: \"f32[2048, 512, 1, 1]\", p_base_model_layer4_1_bn3_weight: \"f32[2048]\", p_base_model_layer4_1_bn3_bias: \"f32[2048]\", p_base_model_layer4_2_conv1_weight: \"f32[512, 2048, 1, 1]\", p_base_model_layer4_2_bn1_weight: \"f32[512]\", p_base_model_layer4_2_bn1_bias: \"f32[512]\", p_base_model_layer4_2_conv2_weight: \"f32[512, 512, 3, 3]\", p_base_model_layer4_2_bn2_weight: \"f32[512]\", p_base_model_layer4_2_bn2_bias: \"f32[512]\", p_base_model_layer4_2_conv3_weight: \"f32[2048, 512, 1, 1]\", p_base_model_layer4_2_bn3_weight: \"f32[2048]\", p_base_model_layer4_2_bn3_bias: \"f32[2048]\", p_base_model_fc_weight: \"f32[1000, 2048]\", p_base_model_fc_bias: \"f32[1000]\", p_features_extractor_0_weight: \"f32[64, 3, 7, 7]\", p_features_extractor_1_weight: \"f32[64]\", p_features_extractor_1_bias: \"f32[64]\", p_features_extractor_4_0_conv1_weight: \"f32[64, 64, 1, 1]\", p_features_extractor_4_0_bn1_weight: \"f32[64]\", p_features_extractor_4_0_bn1_bias: \"f32[64]\", p_features_extractor_4_0_conv2_weight: \"f32[64, 64, 3, 3]\", p_features_extractor_4_0_bn2_weight: \"f32[64]\", p_features_extractor_4_0_bn2_bias: \"f32[64]\", p_features_extractor_4_0_conv3_weight: \"f32[256, 64, 1, 1]\", p_features_extractor_4_0_bn3_weight: \"f32[256]\", p_features_extractor_4_0_bn3_bias: \"f32[256]\", p_features_extractor_4_0_downsample_0_weight: \"f32[256, 64, 1, 1]\", p_features_extractor_4_0_downsample_1_weight: \"f32[256]\", p_features_extractor_4_0_downsample_1_bias: \"f32[256]\", p_features_extractor_4_1_conv1_weight: \"f32[64, 256, 1, 1]\", p_features_extractor_4_1_bn1_weight: \"f32[64]\", p_features_extractor_4_1_bn1_bias: \"f32[64]\", p_features_extractor_4_1_conv2_weight: \"f32[64, 64, 3, 3]\", p_features_extractor_4_1_bn2_weight: \"f32[64]\", p_features_extractor_4_1_bn2_bias: \"f32[64]\", p_features_extractor_4_1_conv3_weight: \"f32[256, 64, 1, 1]\", p_features_extractor_4_1_bn3_weight: \"f32[256]\", p_features_extractor_4_1_bn3_bias: \"f32[256]\", p_features_extractor_4_2_conv1_weight: \"f32[64, 256, 1, 1]\", p_features_extractor_4_2_bn1_weight: \"f32[64]\", p_features_extractor_4_2_bn1_bias: \"f32[64]\", p_features_extractor_4_2_conv2_weight: \"f32[64, 64, 3, 3]\", p_features_extractor_4_2_bn2_weight: \"f32[64]\", p_features_extractor_4_2_bn2_bias: \"f32[64]\", p_features_extractor_4_2_conv3_weight: \"f32[256, 64, 1, 1]\", p_features_extractor_4_2_bn3_weight: \"f32[256]\", p_features_extractor_4_2_bn3_bias: \"f32[256]\", p_features_extractor_5_0_conv1_weight: \"f32[128, 256, 1, 1]\", p_features_extractor_5_0_bn1_weight: \"f32[128]\", p_features_extractor_5_0_bn1_bias: \"f32[128]\", p_features_extractor_5_0_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_0_bn2_weight: \"f32[128]\", p_features_extractor_5_0_bn2_bias: \"f32[128]\", p_features_extractor_5_0_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_0_bn3_weight: \"f32[512]\", p_features_extractor_5_0_bn3_bias: \"f32[512]\", p_features_extractor_5_0_downsample_0_weight: \"f32[512, 256, 1, 1]\", p_features_extractor_5_0_downsample_1_weight: \"f32[512]\", p_features_extractor_5_0_downsample_1_bias: \"f32[512]\", p_features_extractor_5_1_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_1_bn1_weight: \"f32[128]\", p_features_extractor_5_1_bn1_bias: \"f32[128]\", p_features_extractor_5_1_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_1_bn2_weight: \"f32[128]\", p_features_extractor_5_1_bn2_bias: \"f32[128]\", p_features_extractor_5_1_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_1_bn3_weight: \"f32[512]\", p_features_extractor_5_1_bn3_bias: \"f32[512]\", p_features_extractor_5_2_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_2_bn1_weight: \"f32[128]\", p_features_extractor_5_2_bn1_bias: \"f32[128]\", p_features_extractor_5_2_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_2_bn2_weight: \"f32[128]\", p_features_extractor_5_2_bn2_bias: \"f32[128]\", p_features_extractor_5_2_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_2_bn3_weight: \"f32[512]\", p_features_extractor_5_2_bn3_bias: \"f32[512]\", p_features_extractor_5_3_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_3_bn1_weight: \"f32[128]\", p_features_extractor_5_3_bn1_bias: \"f32[128]\", p_features_extractor_5_3_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_3_bn2_weight: \"f32[128]\", p_features_extractor_5_3_bn2_bias: \"f32[128]\", p_features_extractor_5_3_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_3_bn3_weight: \"f32[512]\", p_features_extractor_5_3_bn3_bias: \"f32[512]\", p_features_extractor_5_4_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_4_bn1_weight: \"f32[128]\", p_features_extractor_5_4_bn1_bias: \"f32[128]\", p_features_extractor_5_4_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_4_bn2_weight: \"f32[128]\", p_features_extractor_5_4_bn2_bias: \"f32[128]\", p_features_extractor_5_4_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_4_bn3_weight: \"f32[512]\", p_features_extractor_5_4_bn3_bias: \"f32[512]\", p_features_extractor_5_5_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_5_bn1_weight: \"f32[128]\", p_features_extractor_5_5_bn1_bias: \"f32[128]\", p_features_extractor_5_5_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_5_bn2_weight: \"f32[128]\", p_features_extractor_5_5_bn2_bias: \"f32[128]\", p_features_extractor_5_5_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_5_bn3_weight: \"f32[512]\", p_features_extractor_5_5_bn3_bias: \"f32[512]\", p_features_extractor_5_6_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_6_bn1_weight: \"f32[128]\", p_features_extractor_5_6_bn1_bias: \"f32[128]\", p_features_extractor_5_6_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_6_bn2_weight: \"f32[128]\", p_features_extractor_5_6_bn2_bias: \"f32[128]\", p_features_extractor_5_6_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_6_bn3_weight: \"f32[512]\", p_features_extractor_5_6_bn3_bias: \"f32[512]\", p_features_extractor_5_7_conv1_weight: \"f32[128, 512, 1, 1]\", p_features_extractor_5_7_bn1_weight: \"f32[128]\", p_features_extractor_5_7_bn1_bias: \"f32[128]\", p_features_extractor_5_7_conv2_weight: \"f32[128, 128, 3, 3]\", p_features_extractor_5_7_bn2_weight: \"f32[128]\", p_features_extractor_5_7_bn2_bias: \"f32[128]\", p_features_extractor_5_7_conv3_weight: \"f32[512, 128, 1, 1]\", p_features_extractor_5_7_bn3_weight: \"f32[512]\", p_features_extractor_5_7_bn3_bias: \"f32[512]\", p_features_extractor_6_0_conv1_weight: \"f32[256, 512, 1, 1]\", p_features_extractor_6_0_bn1_weight: \"f32[256]\", p_features_extractor_6_0_bn1_bias: \"f32[256]\", p_features_extractor_6_0_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_0_bn2_weight: \"f32[256]\", p_features_extractor_6_0_bn2_bias: \"f32[256]\", p_features_extractor_6_0_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_0_bn3_weight: \"f32[1024]\", p_features_extractor_6_0_bn3_bias: \"f32[1024]\", p_features_extractor_6_0_downsample_0_weight: \"f32[1024, 512, 1, 1]\", p_features_extractor_6_0_downsample_1_weight: \"f32[1024]\", p_features_extractor_6_0_downsample_1_bias: \"f32[1024]\", p_features_extractor_6_1_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_1_bn1_weight: \"f32[256]\", p_features_extractor_6_1_bn1_bias: \"f32[256]\", p_features_extractor_6_1_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_1_bn2_weight: \"f32[256]\", p_features_extractor_6_1_bn2_bias: \"f32[256]\", p_features_extractor_6_1_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_1_bn3_weight: \"f32[1024]\", p_features_extractor_6_1_bn3_bias: \"f32[1024]\", p_features_extractor_6_2_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_2_bn1_weight: \"f32[256]\", p_features_extractor_6_2_bn1_bias: \"f32[256]\", p_features_extractor_6_2_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_2_bn2_weight: \"f32[256]\", p_features_extractor_6_2_bn2_bias: \"f32[256]\", p_features_extractor_6_2_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_2_bn3_weight: \"f32[1024]\", p_features_extractor_6_2_bn3_bias: \"f32[1024]\", p_features_extractor_6_3_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_3_bn1_weight: \"f32[256]\", p_features_extractor_6_3_bn1_bias: \"f32[256]\", p_features_extractor_6_3_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_3_bn2_weight: \"f32[256]\", p_features_extractor_6_3_bn2_bias: \"f32[256]\", p_features_extractor_6_3_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_3_bn3_weight: \"f32[1024]\", p_features_extractor_6_3_bn3_bias: \"f32[1024]\", p_features_extractor_6_4_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_4_bn1_weight: \"f32[256]\", p_features_extractor_6_4_bn1_bias: \"f32[256]\", p_features_extractor_6_4_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_4_bn2_weight: \"f32[256]\", p_features_extractor_6_4_bn2_bias: \"f32[256]\", p_features_extractor_6_4_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_4_bn3_weight: \"f32[1024]\", p_features_extractor_6_4_bn3_bias: \"f32[1024]\", p_features_extractor_6_5_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_5_bn1_weight: \"f32[256]\", p_features_extractor_6_5_bn1_bias: \"f32[256]\", p_features_extractor_6_5_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_5_bn2_weight: \"f32[256]\", p_features_extractor_6_5_bn2_bias: \"f32[256]\", p_features_extractor_6_5_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_5_bn3_weight: \"f32[1024]\", p_features_extractor_6_5_bn3_bias: \"f32[1024]\", p_features_extractor_6_6_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_6_bn1_weight: \"f32[256]\", p_features_extractor_6_6_bn1_bias: \"f32[256]\", p_features_extractor_6_6_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_6_bn2_weight: \"f32[256]\", p_features_extractor_6_6_bn2_bias: \"f32[256]\", p_features_extractor_6_6_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_6_bn3_weight: \"f32[1024]\", p_features_extractor_6_6_bn3_bias: \"f32[1024]\", p_features_extractor_6_7_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_7_bn1_weight: \"f32[256]\", p_features_extractor_6_7_bn1_bias: \"f32[256]\", p_features_extractor_6_7_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_7_bn2_weight: \"f32[256]\", p_features_extractor_6_7_bn2_bias: \"f32[256]\", p_features_extractor_6_7_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_7_bn3_weight: \"f32[1024]\", p_features_extractor_6_7_bn3_bias: \"f32[1024]\", p_features_extractor_6_8_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_8_bn1_weight: \"f32[256]\", p_features_extractor_6_8_bn1_bias: \"f32[256]\", p_features_extractor_6_8_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_8_bn2_weight: \"f32[256]\", p_features_extractor_6_8_bn2_bias: \"f32[256]\", p_features_extractor_6_8_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_8_bn3_weight: \"f32[1024]\", p_features_extractor_6_8_bn3_bias: \"f32[1024]\", p_features_extractor_6_9_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_9_bn1_weight: \"f32[256]\", p_features_extractor_6_9_bn1_bias: \"f32[256]\", p_features_extractor_6_9_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_9_bn2_weight: \"f32[256]\", p_features_extractor_6_9_bn2_bias: \"f32[256]\", p_features_extractor_6_9_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_9_bn3_weight: \"f32[1024]\", p_features_extractor_6_9_bn3_bias: \"f32[1024]\", p_features_extractor_6_10_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_10_bn1_weight: \"f32[256]\", p_features_extractor_6_10_bn1_bias: \"f32[256]\", p_features_extractor_6_10_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_10_bn2_weight: \"f32[256]\", p_features_extractor_6_10_bn2_bias: \"f32[256]\", p_features_extractor_6_10_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_10_bn3_weight: \"f32[1024]\", p_features_extractor_6_10_bn3_bias: \"f32[1024]\", p_features_extractor_6_11_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_11_bn1_weight: \"f32[256]\", p_features_extractor_6_11_bn1_bias: \"f32[256]\", p_features_extractor_6_11_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_11_bn2_weight: \"f32[256]\", p_features_extractor_6_11_bn2_bias: \"f32[256]\", p_features_extractor_6_11_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_11_bn3_weight: \"f32[1024]\", p_features_extractor_6_11_bn3_bias: \"f32[1024]\", p_features_extractor_6_12_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_12_bn1_weight: \"f32[256]\", p_features_extractor_6_12_bn1_bias: \"f32[256]\", p_features_extractor_6_12_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_12_bn2_weight: \"f32[256]\", p_features_extractor_6_12_bn2_bias: \"f32[256]\", p_features_extractor_6_12_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_12_bn3_weight: \"f32[1024]\", p_features_extractor_6_12_bn3_bias: \"f32[1024]\", p_features_extractor_6_13_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_13_bn1_weight: \"f32[256]\", p_features_extractor_6_13_bn1_bias: \"f32[256]\", p_features_extractor_6_13_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_13_bn2_weight: \"f32[256]\", p_features_extractor_6_13_bn2_bias: \"f32[256]\", p_features_extractor_6_13_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_13_bn3_weight: \"f32[1024]\", p_features_extractor_6_13_bn3_bias: \"f32[1024]\", p_features_extractor_6_14_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_14_bn1_weight: \"f32[256]\", p_features_extractor_6_14_bn1_bias: \"f32[256]\", p_features_extractor_6_14_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_14_bn2_weight: \"f32[256]\", p_features_extractor_6_14_bn2_bias: \"f32[256]\", p_features_extractor_6_14_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_14_bn3_weight: \"f32[1024]\", p_features_extractor_6_14_bn3_bias: \"f32[1024]\", p_features_extractor_6_15_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_15_bn1_weight: \"f32[256]\", p_features_extractor_6_15_bn1_bias: \"f32[256]\", p_features_extractor_6_15_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_15_bn2_weight: \"f32[256]\", p_features_extractor_6_15_bn2_bias: \"f32[256]\", p_features_extractor_6_15_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_15_bn3_weight: \"f32[1024]\", p_features_extractor_6_15_bn3_bias: \"f32[1024]\", p_features_extractor_6_16_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_16_bn1_weight: \"f32[256]\", p_features_extractor_6_16_bn1_bias: \"f32[256]\", p_features_extractor_6_16_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_16_bn2_weight: \"f32[256]\", p_features_extractor_6_16_bn2_bias: \"f32[256]\", p_features_extractor_6_16_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_16_bn3_weight: \"f32[1024]\", p_features_extractor_6_16_bn3_bias: \"f32[1024]\", p_features_extractor_6_17_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_17_bn1_weight: \"f32[256]\", p_features_extractor_6_17_bn1_bias: \"f32[256]\", p_features_extractor_6_17_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_17_bn2_weight: \"f32[256]\", p_features_extractor_6_17_bn2_bias: \"f32[256]\", p_features_extractor_6_17_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_17_bn3_weight: \"f32[1024]\", p_features_extractor_6_17_bn3_bias: \"f32[1024]\", p_features_extractor_6_18_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_18_bn1_weight: \"f32[256]\", p_features_extractor_6_18_bn1_bias: \"f32[256]\", p_features_extractor_6_18_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_18_bn2_weight: \"f32[256]\", p_features_extractor_6_18_bn2_bias: \"f32[256]\", p_features_extractor_6_18_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_18_bn3_weight: \"f32[1024]\", p_features_extractor_6_18_bn3_bias: \"f32[1024]\", p_features_extractor_6_19_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_19_bn1_weight: \"f32[256]\", p_features_extractor_6_19_bn1_bias: \"f32[256]\", p_features_extractor_6_19_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_19_bn2_weight: \"f32[256]\", p_features_extractor_6_19_bn2_bias: \"f32[256]\", p_features_extractor_6_19_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_19_bn3_weight: \"f32[1024]\", p_features_extractor_6_19_bn3_bias: \"f32[1024]\", p_features_extractor_6_20_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_20_bn1_weight: \"f32[256]\", p_features_extractor_6_20_bn1_bias: \"f32[256]\", p_features_extractor_6_20_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_20_bn2_weight: \"f32[256]\", p_features_extractor_6_20_bn2_bias: \"f32[256]\", p_features_extractor_6_20_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_20_bn3_weight: \"f32[1024]\", p_features_extractor_6_20_bn3_bias: \"f32[1024]\", p_features_extractor_6_21_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_21_bn1_weight: \"f32[256]\", p_features_extractor_6_21_bn1_bias: \"f32[256]\", p_features_extractor_6_21_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_21_bn2_weight: \"f32[256]\", p_features_extractor_6_21_bn2_bias: \"f32[256]\", p_features_extractor_6_21_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_21_bn3_weight: \"f32[1024]\", p_features_extractor_6_21_bn3_bias: \"f32[1024]\", p_features_extractor_6_22_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_22_bn1_weight: \"f32[256]\", p_features_extractor_6_22_bn1_bias: \"f32[256]\", p_features_extractor_6_22_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_22_bn2_weight: \"f32[256]\", p_features_extractor_6_22_bn2_bias: \"f32[256]\", p_features_extractor_6_22_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_22_bn3_weight: \"f32[1024]\", p_features_extractor_6_22_bn3_bias: \"f32[1024]\", p_features_extractor_6_23_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_23_bn1_weight: \"f32[256]\", p_features_extractor_6_23_bn1_bias: \"f32[256]\", p_features_extractor_6_23_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_23_bn2_weight: \"f32[256]\", p_features_extractor_6_23_bn2_bias: \"f32[256]\", p_features_extractor_6_23_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_23_bn3_weight: \"f32[1024]\", p_features_extractor_6_23_bn3_bias: \"f32[1024]\", p_features_extractor_6_24_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_24_bn1_weight: \"f32[256]\", p_features_extractor_6_24_bn1_bias: \"f32[256]\", p_features_extractor_6_24_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_24_bn2_weight: \"f32[256]\", p_features_extractor_6_24_bn2_bias: \"f32[256]\", p_features_extractor_6_24_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_24_bn3_weight: \"f32[1024]\", p_features_extractor_6_24_bn3_bias: \"f32[1024]\", p_features_extractor_6_25_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_25_bn1_weight: \"f32[256]\", p_features_extractor_6_25_bn1_bias: \"f32[256]\", p_features_extractor_6_25_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_25_bn2_weight: \"f32[256]\", p_features_extractor_6_25_bn2_bias: \"f32[256]\", p_features_extractor_6_25_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_25_bn3_weight: \"f32[1024]\", p_features_extractor_6_25_bn3_bias: \"f32[1024]\", p_features_extractor_6_26_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_26_bn1_weight: \"f32[256]\", p_features_extractor_6_26_bn1_bias: \"f32[256]\", p_features_extractor_6_26_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_26_bn2_weight: \"f32[256]\", p_features_extractor_6_26_bn2_bias: \"f32[256]\", p_features_extractor_6_26_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_26_bn3_weight: \"f32[1024]\", p_features_extractor_6_26_bn3_bias: \"f32[1024]\", p_features_extractor_6_27_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_27_bn1_weight: \"f32[256]\", p_features_extractor_6_27_bn1_bias: \"f32[256]\", p_features_extractor_6_27_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_27_bn2_weight: \"f32[256]\", p_features_extractor_6_27_bn2_bias: \"f32[256]\", p_features_extractor_6_27_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_27_bn3_weight: \"f32[1024]\", p_features_extractor_6_27_bn3_bias: \"f32[1024]\", p_features_extractor_6_28_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_28_bn1_weight: \"f32[256]\", p_features_extractor_6_28_bn1_bias: \"f32[256]\", p_features_extractor_6_28_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_28_bn2_weight: \"f32[256]\", p_features_extractor_6_28_bn2_bias: \"f32[256]\", p_features_extractor_6_28_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_28_bn3_weight: \"f32[1024]\", p_features_extractor_6_28_bn3_bias: \"f32[1024]\", p_features_extractor_6_29_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_29_bn1_weight: \"f32[256]\", p_features_extractor_6_29_bn1_bias: \"f32[256]\", p_features_extractor_6_29_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_29_bn2_weight: \"f32[256]\", p_features_extractor_6_29_bn2_bias: \"f32[256]\", p_features_extractor_6_29_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_29_bn3_weight: \"f32[1024]\", p_features_extractor_6_29_bn3_bias: \"f32[1024]\", p_features_extractor_6_30_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_30_bn1_weight: \"f32[256]\", p_features_extractor_6_30_bn1_bias: \"f32[256]\", p_features_extractor_6_30_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_30_bn2_weight: \"f32[256]\", p_features_extractor_6_30_bn2_bias: \"f32[256]\", p_features_extractor_6_30_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_30_bn3_weight: \"f32[1024]\", p_features_extractor_6_30_bn3_bias: \"f32[1024]\", p_features_extractor_6_31_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_31_bn1_weight: \"f32[256]\", p_features_extractor_6_31_bn1_bias: \"f32[256]\", p_features_extractor_6_31_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_31_bn2_weight: \"f32[256]\", p_features_extractor_6_31_bn2_bias: \"f32[256]\", p_features_extractor_6_31_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_31_bn3_weight: \"f32[1024]\", p_features_extractor_6_31_bn3_bias: \"f32[1024]\", p_features_extractor_6_32_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_32_bn1_weight: \"f32[256]\", p_features_extractor_6_32_bn1_bias: \"f32[256]\", p_features_extractor_6_32_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_32_bn2_weight: \"f32[256]\", p_features_extractor_6_32_bn2_bias: \"f32[256]\", p_features_extractor_6_32_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_32_bn3_weight: \"f32[1024]\", p_features_extractor_6_32_bn3_bias: \"f32[1024]\", p_features_extractor_6_33_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_33_bn1_weight: \"f32[256]\", p_features_extractor_6_33_bn1_bias: \"f32[256]\", p_features_extractor_6_33_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_33_bn2_weight: \"f32[256]\", p_features_extractor_6_33_bn2_bias: \"f32[256]\", p_features_extractor_6_33_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_33_bn3_weight: \"f32[1024]\", p_features_extractor_6_33_bn3_bias: \"f32[1024]\", p_features_extractor_6_34_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_34_bn1_weight: \"f32[256]\", p_features_extractor_6_34_bn1_bias: \"f32[256]\", p_features_extractor_6_34_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_34_bn2_weight: \"f32[256]\", p_features_extractor_6_34_bn2_bias: \"f32[256]\", p_features_extractor_6_34_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_34_bn3_weight: \"f32[1024]\", p_features_extractor_6_34_bn3_bias: \"f32[1024]\", p_features_extractor_6_35_conv1_weight: \"f32[256, 1024, 1, 1]\", p_features_extractor_6_35_bn1_weight: \"f32[256]\", p_features_extractor_6_35_bn1_bias: \"f32[256]\", p_features_extractor_6_35_conv2_weight: \"f32[256, 256, 3, 3]\", p_features_extractor_6_35_bn2_weight: \"f32[256]\", p_features_extractor_6_35_bn2_bias: \"f32[256]\", p_features_extractor_6_35_conv3_weight: \"f32[1024, 256, 1, 1]\", p_features_extractor_6_35_bn3_weight: \"f32[1024]\", p_features_extractor_6_35_bn3_bias: \"f32[1024]\", p_features_extractor_7_0_conv1_weight: \"f32[512, 1024, 1, 1]\", p_features_extractor_7_0_bn1_weight: \"f32[512]\", p_features_extractor_7_0_bn1_bias: \"f32[512]\", p_features_extractor_7_0_conv2_weight: \"f32[512, 512, 3, 3]\", p_features_extractor_7_0_bn2_weight: \"f32[512]\", p_features_extractor_7_0_bn2_bias: \"f32[512]\", p_features_extractor_7_0_conv3_weight: \"f32[2048, 512, 1, 1]\", p_features_extractor_7_0_bn3_weight: \"f32[2048]\", p_features_extractor_7_0_bn3_bias: \"f32[2048]\", p_features_extractor_7_0_downsample_0_weight: \"f32[2048, 1024, 1, 1]\", p_features_extractor_7_0_downsample_1_weight: \"f32[2048]\", p_features_extractor_7_0_downsample_1_bias: \"f32[2048]\", p_features_extractor_7_1_conv1_weight: \"f32[512, 2048, 1, 1]\", p_features_extractor_7_1_bn1_weight: \"f32[512]\", p_features_extractor_7_1_bn1_bias: \"f32[512]\", p_features_extractor_7_1_conv2_weight: \"f32[512, 512, 3, 3]\", p_features_extractor_7_1_bn2_weight: \"f32[512]\", p_features_extractor_7_1_bn2_bias: \"f32[512]\", p_features_extractor_7_1_conv3_weight: \"f32[2048, 512, 1, 1]\", p_features_extractor_7_1_bn3_weight: \"f32[2048]\", p_features_extractor_7_1_bn3_bias: \"f32[2048]\", p_features_extractor_7_2_conv1_weight: \"f32[512, 2048, 1, 1]\", p_features_extractor_7_2_bn1_weight: \"f32[512]\", p_features_extractor_7_2_bn1_bias: \"f32[512]\", p_features_extractor_7_2_conv2_weight: \"f32[512, 512, 3, 3]\", p_features_extractor_7_2_bn2_weight: \"f32[512]\", p_features_extractor_7_2_bn2_bias: \"f32[512]\", p_features_extractor_7_2_conv3_weight: \"f32[2048, 512, 1, 1]\", p_features_extractor_7_2_bn3_weight: \"f32[2048]\", p_features_extractor_7_2_bn3_bias: \"f32[2048]\", p_output_layer_weight: \"f32[131, 2048]\", p_output_layer_bias: \"f32[131]\", b_base_model_bn1_running_mean: \"f32[64]\", b_base_model_bn1_running_var: \"f32[64]\", b_base_model_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer1_0_bn1_running_mean: \"f32[64]\", b_base_model_layer1_0_bn1_running_var: \"f32[64]\", b_base_model_layer1_0_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer1_0_bn2_running_mean: \"f32[64]\", b_base_model_layer1_0_bn2_running_var: \"f32[64]\", b_base_model_layer1_0_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer1_0_bn3_running_mean: \"f32[256]\", b_base_model_layer1_0_bn3_running_var: \"f32[256]\", b_base_model_layer1_0_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer1_0_downsample_1_running_mean: \"f32[256]\", b_base_model_layer1_0_downsample_1_running_var: \"f32[256]\", b_base_model_layer1_0_downsample_1_num_batches_tracked: \"i64[]\", b_base_model_layer1_1_bn1_running_mean: \"f32[64]\", b_base_model_layer1_1_bn1_running_var: \"f32[64]\", b_base_model_layer1_1_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer1_1_bn2_running_mean: \"f32[64]\", b_base_model_layer1_1_bn2_running_var: \"f32[64]\", b_base_model_layer1_1_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer1_1_bn3_running_mean: \"f32[256]\", b_base_model_layer1_1_bn3_running_var: \"f32[256]\", b_base_model_layer1_1_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer1_2_bn1_running_mean: \"f32[64]\", b_base_model_layer1_2_bn1_running_var: \"f32[64]\", b_base_model_layer1_2_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer1_2_bn2_running_mean: \"f32[64]\", b_base_model_layer1_2_bn2_running_var: \"f32[64]\", b_base_model_layer1_2_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer1_2_bn3_running_mean: \"f32[256]\", b_base_model_layer1_2_bn3_running_var: \"f32[256]\", b_base_model_layer1_2_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_0_bn1_running_mean: \"f32[128]\", b_base_model_layer2_0_bn1_running_var: \"f32[128]\", b_base_model_layer2_0_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_0_bn2_running_mean: \"f32[128]\", b_base_model_layer2_0_bn2_running_var: \"f32[128]\", b_base_model_layer2_0_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_0_bn3_running_mean: \"f32[512]\", b_base_model_layer2_0_bn3_running_var: \"f32[512]\", b_base_model_layer2_0_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_0_downsample_1_running_mean: \"f32[512]\", b_base_model_layer2_0_downsample_1_running_var: \"f32[512]\", b_base_model_layer2_0_downsample_1_num_batches_tracked: \"i64[]\", b_base_model_layer2_1_bn1_running_mean: \"f32[128]\", b_base_model_layer2_1_bn1_running_var: \"f32[128]\", b_base_model_layer2_1_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_1_bn2_running_mean: \"f32[128]\", b_base_model_layer2_1_bn2_running_var: \"f32[128]\", b_base_model_layer2_1_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_1_bn3_running_mean: \"f32[512]\", b_base_model_layer2_1_bn3_running_var: \"f32[512]\", b_base_model_layer2_1_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_2_bn1_running_mean: \"f32[128]\", b_base_model_layer2_2_bn1_running_var: \"f32[128]\", b_base_model_layer2_2_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_2_bn2_running_mean: \"f32[128]\", b_base_model_layer2_2_bn2_running_var: \"f32[128]\", b_base_model_layer2_2_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_2_bn3_running_mean: \"f32[512]\", b_base_model_layer2_2_bn3_running_var: \"f32[512]\", b_base_model_layer2_2_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_3_bn1_running_mean: \"f32[128]\", b_base_model_layer2_3_bn1_running_var: \"f32[128]\", b_base_model_layer2_3_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_3_bn2_running_mean: \"f32[128]\", b_base_model_layer2_3_bn2_running_var: \"f32[128]\", b_base_model_layer2_3_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_3_bn3_running_mean: \"f32[512]\", b_base_model_layer2_3_bn3_running_var: \"f32[512]\", b_base_model_layer2_3_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_4_bn1_running_mean: \"f32[128]\", b_base_model_layer2_4_bn1_running_var: \"f32[128]\", b_base_model_layer2_4_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_4_bn2_running_mean: \"f32[128]\", b_base_model_layer2_4_bn2_running_var: \"f32[128]\", b_base_model_layer2_4_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_4_bn3_running_mean: \"f32[512]\", b_base_model_layer2_4_bn3_running_var: \"f32[512]\", b_base_model_layer2_4_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_5_bn1_running_mean: \"f32[128]\", b_base_model_layer2_5_bn1_running_var: \"f32[128]\", b_base_model_layer2_5_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_5_bn2_running_mean: \"f32[128]\", b_base_model_layer2_5_bn2_running_var: \"f32[128]\", b_base_model_layer2_5_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_5_bn3_running_mean: \"f32[512]\", b_base_model_layer2_5_bn3_running_var: \"f32[512]\", b_base_model_layer2_5_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_6_bn1_running_mean: \"f32[128]\", b_base_model_layer2_6_bn1_running_var: \"f32[128]\", b_base_model_layer2_6_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_6_bn2_running_mean: \"f32[128]\", b_base_model_layer2_6_bn2_running_var: \"f32[128]\", b_base_model_layer2_6_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_6_bn3_running_mean: \"f32[512]\", b_base_model_layer2_6_bn3_running_var: \"f32[512]\", b_base_model_layer2_6_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer2_7_bn1_running_mean: \"f32[128]\", b_base_model_layer2_7_bn1_running_var: \"f32[128]\", b_base_model_layer2_7_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer2_7_bn2_running_mean: \"f32[128]\", b_base_model_layer2_7_bn2_running_var: \"f32[128]\", b_base_model_layer2_7_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer2_7_bn3_running_mean: \"f32[512]\", b_base_model_layer2_7_bn3_running_var: \"f32[512]\", b_base_model_layer2_7_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_0_bn1_running_mean: \"f32[256]\", b_base_model_layer3_0_bn1_running_var: \"f32[256]\", b_base_model_layer3_0_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_0_bn2_running_mean: \"f32[256]\", b_base_model_layer3_0_bn2_running_var: \"f32[256]\", b_base_model_layer3_0_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_0_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_0_bn3_running_var: \"f32[1024]\", b_base_model_layer3_0_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_0_downsample_1_running_mean: \"f32[1024]\", b_base_model_layer3_0_downsample_1_running_var: \"f32[1024]\", b_base_model_layer3_0_downsample_1_num_batches_tracked: \"i64[]\", b_base_model_layer3_1_bn1_running_mean: \"f32[256]\", b_base_model_layer3_1_bn1_running_var: \"f32[256]\", b_base_model_layer3_1_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_1_bn2_running_mean: \"f32[256]\", b_base_model_layer3_1_bn2_running_var: \"f32[256]\", b_base_model_layer3_1_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_1_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_1_bn3_running_var: \"f32[1024]\", b_base_model_layer3_1_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_2_bn1_running_mean: \"f32[256]\", b_base_model_layer3_2_bn1_running_var: \"f32[256]\", b_base_model_layer3_2_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_2_bn2_running_mean: \"f32[256]\", b_base_model_layer3_2_bn2_running_var: \"f32[256]\", b_base_model_layer3_2_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_2_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_2_bn3_running_var: \"f32[1024]\", b_base_model_layer3_2_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_3_bn1_running_mean: \"f32[256]\", b_base_model_layer3_3_bn1_running_var: \"f32[256]\", b_base_model_layer3_3_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_3_bn2_running_mean: \"f32[256]\", b_base_model_layer3_3_bn2_running_var: \"f32[256]\", b_base_model_layer3_3_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_3_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_3_bn3_running_var: \"f32[1024]\", b_base_model_layer3_3_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_4_bn1_running_mean: \"f32[256]\", b_base_model_layer3_4_bn1_running_var: \"f32[256]\", b_base_model_layer3_4_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_4_bn2_running_mean: \"f32[256]\", b_base_model_layer3_4_bn2_running_var: \"f32[256]\", b_base_model_layer3_4_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_4_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_4_bn3_running_var: \"f32[1024]\", b_base_model_layer3_4_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_5_bn1_running_mean: \"f32[256]\", b_base_model_layer3_5_bn1_running_var: \"f32[256]\", b_base_model_layer3_5_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_5_bn2_running_mean: \"f32[256]\", b_base_model_layer3_5_bn2_running_var: \"f32[256]\", b_base_model_layer3_5_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_5_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_5_bn3_running_var: \"f32[1024]\", b_base_model_layer3_5_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_6_bn1_running_mean: \"f32[256]\", b_base_model_layer3_6_bn1_running_var: \"f32[256]\", b_base_model_layer3_6_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_6_bn2_running_mean: \"f32[256]\", b_base_model_layer3_6_bn2_running_var: \"f32[256]\", b_base_model_layer3_6_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_6_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_6_bn3_running_var: \"f32[1024]\", b_base_model_layer3_6_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_7_bn1_running_mean: \"f32[256]\", b_base_model_layer3_7_bn1_running_var: \"f32[256]\", b_base_model_layer3_7_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_7_bn2_running_mean: \"f32[256]\", b_base_model_layer3_7_bn2_running_var: \"f32[256]\", b_base_model_layer3_7_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_7_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_7_bn3_running_var: \"f32[1024]\", b_base_model_layer3_7_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_8_bn1_running_mean: \"f32[256]\", b_base_model_layer3_8_bn1_running_var: \"f32[256]\", b_base_model_layer3_8_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_8_bn2_running_mean: \"f32[256]\", b_base_model_layer3_8_bn2_running_var: \"f32[256]\", b_base_model_layer3_8_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_8_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_8_bn3_running_var: \"f32[1024]\", b_base_model_layer3_8_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_9_bn1_running_mean: \"f32[256]\", b_base_model_layer3_9_bn1_running_var: \"f32[256]\", b_base_model_layer3_9_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_9_bn2_running_mean: \"f32[256]\", b_base_model_layer3_9_bn2_running_var: \"f32[256]\", b_base_model_layer3_9_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_9_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_9_bn3_running_var: \"f32[1024]\", b_base_model_layer3_9_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_10_bn1_running_mean: \"f32[256]\", b_base_model_layer3_10_bn1_running_var: \"f32[256]\", b_base_model_layer3_10_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_10_bn2_running_mean: \"f32[256]\", b_base_model_layer3_10_bn2_running_var: \"f32[256]\", b_base_model_layer3_10_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_10_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_10_bn3_running_var: \"f32[1024]\", b_base_model_layer3_10_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_11_bn1_running_mean: \"f32[256]\", b_base_model_layer3_11_bn1_running_var: \"f32[256]\", b_base_model_layer3_11_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_11_bn2_running_mean: \"f32[256]\", b_base_model_layer3_11_bn2_running_var: \"f32[256]\", b_base_model_layer3_11_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_11_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_11_bn3_running_var: \"f32[1024]\", b_base_model_layer3_11_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_12_bn1_running_mean: \"f32[256]\", b_base_model_layer3_12_bn1_running_var: \"f32[256]\", b_base_model_layer3_12_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_12_bn2_running_mean: \"f32[256]\", b_base_model_layer3_12_bn2_running_var: \"f32[256]\", b_base_model_layer3_12_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_12_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_12_bn3_running_var: \"f32[1024]\", b_base_model_layer3_12_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_13_bn1_running_mean: \"f32[256]\", b_base_model_layer3_13_bn1_running_var: \"f32[256]\", b_base_model_layer3_13_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_13_bn2_running_mean: \"f32[256]\", b_base_model_layer3_13_bn2_running_var: \"f32[256]\", b_base_model_layer3_13_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_13_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_13_bn3_running_var: \"f32[1024]\", b_base_model_layer3_13_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_14_bn1_running_mean: \"f32[256]\", b_base_model_layer3_14_bn1_running_var: \"f32[256]\", b_base_model_layer3_14_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_14_bn2_running_mean: \"f32[256]\", b_base_model_layer3_14_bn2_running_var: \"f32[256]\", b_base_model_layer3_14_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_14_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_14_bn3_running_var: \"f32[1024]\", b_base_model_layer3_14_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_15_bn1_running_mean: \"f32[256]\", b_base_model_layer3_15_bn1_running_var: \"f32[256]\", b_base_model_layer3_15_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_15_bn2_running_mean: \"f32[256]\", b_base_model_layer3_15_bn2_running_var: \"f32[256]\", b_base_model_layer3_15_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_15_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_15_bn3_running_var: \"f32[1024]\", b_base_model_layer3_15_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_16_bn1_running_mean: \"f32[256]\", b_base_model_layer3_16_bn1_running_var: \"f32[256]\", b_base_model_layer3_16_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_16_bn2_running_mean: \"f32[256]\", b_base_model_layer3_16_bn2_running_var: \"f32[256]\", b_base_model_layer3_16_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_16_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_16_bn3_running_var: \"f32[1024]\", b_base_model_layer3_16_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_17_bn1_running_mean: \"f32[256]\", b_base_model_layer3_17_bn1_running_var: \"f32[256]\", b_base_model_layer3_17_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_17_bn2_running_mean: \"f32[256]\", b_base_model_layer3_17_bn2_running_var: \"f32[256]\", b_base_model_layer3_17_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_17_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_17_bn3_running_var: \"f32[1024]\", b_base_model_layer3_17_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_18_bn1_running_mean: \"f32[256]\", b_base_model_layer3_18_bn1_running_var: \"f32[256]\", b_base_model_layer3_18_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_18_bn2_running_mean: \"f32[256]\", b_base_model_layer3_18_bn2_running_var: \"f32[256]\", b_base_model_layer3_18_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_18_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_18_bn3_running_var: \"f32[1024]\", b_base_model_layer3_18_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_19_bn1_running_mean: \"f32[256]\", b_base_model_layer3_19_bn1_running_var: \"f32[256]\", b_base_model_layer3_19_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_19_bn2_running_mean: \"f32[256]\", b_base_model_layer3_19_bn2_running_var: \"f32[256]\", b_base_model_layer3_19_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_19_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_19_bn3_running_var: \"f32[1024]\", b_base_model_layer3_19_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_20_bn1_running_mean: \"f32[256]\", b_base_model_layer3_20_bn1_running_var: \"f32[256]\", b_base_model_layer3_20_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_20_bn2_running_mean: \"f32[256]\", b_base_model_layer3_20_bn2_running_var: \"f32[256]\", b_base_model_layer3_20_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_20_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_20_bn3_running_var: \"f32[1024]\", b_base_model_layer3_20_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_21_bn1_running_mean: \"f32[256]\", b_base_model_layer3_21_bn1_running_var: \"f32[256]\", b_base_model_layer3_21_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_21_bn2_running_mean: \"f32[256]\", b_base_model_layer3_21_bn2_running_var: \"f32[256]\", b_base_model_layer3_21_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_21_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_21_bn3_running_var: \"f32[1024]\", b_base_model_layer3_21_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_22_bn1_running_mean: \"f32[256]\", b_base_model_layer3_22_bn1_running_var: \"f32[256]\", b_base_model_layer3_22_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_22_bn2_running_mean: \"f32[256]\", b_base_model_layer3_22_bn2_running_var: \"f32[256]\", b_base_model_layer3_22_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_22_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_22_bn3_running_var: \"f32[1024]\", b_base_model_layer3_22_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_23_bn1_running_mean: \"f32[256]\", b_base_model_layer3_23_bn1_running_var: \"f32[256]\", b_base_model_layer3_23_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_23_bn2_running_mean: \"f32[256]\", b_base_model_layer3_23_bn2_running_var: \"f32[256]\", b_base_model_layer3_23_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_23_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_23_bn3_running_var: \"f32[1024]\", b_base_model_layer3_23_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_24_bn1_running_mean: \"f32[256]\", b_base_model_layer3_24_bn1_running_var: \"f32[256]\", b_base_model_layer3_24_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_24_bn2_running_mean: \"f32[256]\", b_base_model_layer3_24_bn2_running_var: \"f32[256]\", b_base_model_layer3_24_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_24_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_24_bn3_running_var: \"f32[1024]\", b_base_model_layer3_24_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_25_bn1_running_mean: \"f32[256]\", b_base_model_layer3_25_bn1_running_var: \"f32[256]\", b_base_model_layer3_25_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_25_bn2_running_mean: \"f32[256]\", b_base_model_layer3_25_bn2_running_var: \"f32[256]\", b_base_model_layer3_25_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_25_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_25_bn3_running_var: \"f32[1024]\", b_base_model_layer3_25_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_26_bn1_running_mean: \"f32[256]\", b_base_model_layer3_26_bn1_running_var: \"f32[256]\", b_base_model_layer3_26_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_26_bn2_running_mean: \"f32[256]\", b_base_model_layer3_26_bn2_running_var: \"f32[256]\", b_base_model_layer3_26_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_26_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_26_bn3_running_var: \"f32[1024]\", b_base_model_layer3_26_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_27_bn1_running_mean: \"f32[256]\", b_base_model_layer3_27_bn1_running_var: \"f32[256]\", b_base_model_layer3_27_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_27_bn2_running_mean: \"f32[256]\", b_base_model_layer3_27_bn2_running_var: \"f32[256]\", b_base_model_layer3_27_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_27_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_27_bn3_running_var: \"f32[1024]\", b_base_model_layer3_27_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_28_bn1_running_mean: \"f32[256]\", b_base_model_layer3_28_bn1_running_var: \"f32[256]\", b_base_model_layer3_28_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_28_bn2_running_mean: \"f32[256]\", b_base_model_layer3_28_bn2_running_var: \"f32[256]\", b_base_model_layer3_28_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_28_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_28_bn3_running_var: \"f32[1024]\", b_base_model_layer3_28_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_29_bn1_running_mean: \"f32[256]\", b_base_model_layer3_29_bn1_running_var: \"f32[256]\", b_base_model_layer3_29_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_29_bn2_running_mean: \"f32[256]\", b_base_model_layer3_29_bn2_running_var: \"f32[256]\", b_base_model_layer3_29_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_29_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_29_bn3_running_var: \"f32[1024]\", b_base_model_layer3_29_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_30_bn1_running_mean: \"f32[256]\", b_base_model_layer3_30_bn1_running_var: \"f32[256]\", b_base_model_layer3_30_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_30_bn2_running_mean: \"f32[256]\", b_base_model_layer3_30_bn2_running_var: \"f32[256]\", b_base_model_layer3_30_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_30_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_30_bn3_running_var: \"f32[1024]\", b_base_model_layer3_30_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_31_bn1_running_mean: \"f32[256]\", b_base_model_layer3_31_bn1_running_var: \"f32[256]\", b_base_model_layer3_31_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_31_bn2_running_mean: \"f32[256]\", b_base_model_layer3_31_bn2_running_var: \"f32[256]\", b_base_model_layer3_31_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_31_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_31_bn3_running_var: \"f32[1024]\", b_base_model_layer3_31_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_32_bn1_running_mean: \"f32[256]\", b_base_model_layer3_32_bn1_running_var: \"f32[256]\", b_base_model_layer3_32_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_32_bn2_running_mean: \"f32[256]\", b_base_model_layer3_32_bn2_running_var: \"f32[256]\", b_base_model_layer3_32_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_32_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_32_bn3_running_var: \"f32[1024]\", b_base_model_layer3_32_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_33_bn1_running_mean: \"f32[256]\", b_base_model_layer3_33_bn1_running_var: \"f32[256]\", b_base_model_layer3_33_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_33_bn2_running_mean: \"f32[256]\", b_base_model_layer3_33_bn2_running_var: \"f32[256]\", b_base_model_layer3_33_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_33_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_33_bn3_running_var: \"f32[1024]\", b_base_model_layer3_33_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_34_bn1_running_mean: \"f32[256]\", b_base_model_layer3_34_bn1_running_var: \"f32[256]\", b_base_model_layer3_34_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_34_bn2_running_mean: \"f32[256]\", b_base_model_layer3_34_bn2_running_var: \"f32[256]\", b_base_model_layer3_34_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_34_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_34_bn3_running_var: \"f32[1024]\", b_base_model_layer3_34_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer3_35_bn1_running_mean: \"f32[256]\", b_base_model_layer3_35_bn1_running_var: \"f32[256]\", b_base_model_layer3_35_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer3_35_bn2_running_mean: \"f32[256]\", b_base_model_layer3_35_bn2_running_var: \"f32[256]\", b_base_model_layer3_35_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer3_35_bn3_running_mean: \"f32[1024]\", b_base_model_layer3_35_bn3_running_var: \"f32[1024]\", b_base_model_layer3_35_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer4_0_bn1_running_mean: \"f32[512]\", b_base_model_layer4_0_bn1_running_var: \"f32[512]\", b_base_model_layer4_0_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer4_0_bn2_running_mean: \"f32[512]\", b_base_model_layer4_0_bn2_running_var: \"f32[512]\", b_base_model_layer4_0_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer4_0_bn3_running_mean: \"f32[2048]\", b_base_model_layer4_0_bn3_running_var: \"f32[2048]\", b_base_model_layer4_0_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer4_0_downsample_1_running_mean: \"f32[2048]\", b_base_model_layer4_0_downsample_1_running_var: \"f32[2048]\", b_base_model_layer4_0_downsample_1_num_batches_tracked: \"i64[]\", b_base_model_layer4_1_bn1_running_mean: \"f32[512]\", b_base_model_layer4_1_bn1_running_var: \"f32[512]\", b_base_model_layer4_1_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer4_1_bn2_running_mean: \"f32[512]\", b_base_model_layer4_1_bn2_running_var: \"f32[512]\", b_base_model_layer4_1_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer4_1_bn3_running_mean: \"f32[2048]\", b_base_model_layer4_1_bn3_running_var: \"f32[2048]\", b_base_model_layer4_1_bn3_num_batches_tracked: \"i64[]\", b_base_model_layer4_2_bn1_running_mean: \"f32[512]\", b_base_model_layer4_2_bn1_running_var: \"f32[512]\", b_base_model_layer4_2_bn1_num_batches_tracked: \"i64[]\", b_base_model_layer4_2_bn2_running_mean: \"f32[512]\", b_base_model_layer4_2_bn2_running_var: \"f32[512]\", b_base_model_layer4_2_bn2_num_batches_tracked: \"i64[]\", b_base_model_layer4_2_bn3_running_mean: \"f32[2048]\", b_base_model_layer4_2_bn3_running_var: \"f32[2048]\", b_base_model_layer4_2_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_1_running_mean: \"f32[64]\", b_features_extractor_1_running_var: \"f32[64]\", b_features_extractor_1_num_batches_tracked: \"i64[]\", b_features_extractor_4_0_bn1_running_mean: \"f32[64]\", b_features_extractor_4_0_bn1_running_var: \"f32[64]\", b_features_extractor_4_0_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_4_0_bn2_running_mean: \"f32[64]\", b_features_extractor_4_0_bn2_running_var: \"f32[64]\", b_features_extractor_4_0_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_4_0_bn3_running_mean: \"f32[256]\", b_features_extractor_4_0_bn3_running_var: \"f32[256]\", b_features_extractor_4_0_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_4_0_downsample_1_running_mean: \"f32[256]\", b_features_extractor_4_0_downsample_1_running_var: \"f32[256]\", b_features_extractor_4_0_downsample_1_num_batches_tracked: \"i64[]\", b_features_extractor_4_1_bn1_running_mean: \"f32[64]\", b_features_extractor_4_1_bn1_running_var: \"f32[64]\", b_features_extractor_4_1_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_4_1_bn2_running_mean: \"f32[64]\", b_features_extractor_4_1_bn2_running_var: \"f32[64]\", b_features_extractor_4_1_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_4_1_bn3_running_mean: \"f32[256]\", b_features_extractor_4_1_bn3_running_var: \"f32[256]\", b_features_extractor_4_1_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_4_2_bn1_running_mean: \"f32[64]\", b_features_extractor_4_2_bn1_running_var: \"f32[64]\", b_features_extractor_4_2_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_4_2_bn2_running_mean: \"f32[64]\", b_features_extractor_4_2_bn2_running_var: \"f32[64]\", b_features_extractor_4_2_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_4_2_bn3_running_mean: \"f32[256]\", b_features_extractor_4_2_bn3_running_var: \"f32[256]\", b_features_extractor_4_2_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_0_bn1_running_mean: \"f32[128]\", b_features_extractor_5_0_bn1_running_var: \"f32[128]\", b_features_extractor_5_0_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_0_bn2_running_mean: \"f32[128]\", b_features_extractor_5_0_bn2_running_var: \"f32[128]\", b_features_extractor_5_0_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_0_bn3_running_mean: \"f32[512]\", b_features_extractor_5_0_bn3_running_var: \"f32[512]\", b_features_extractor_5_0_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_0_downsample_1_running_mean: \"f32[512]\", b_features_extractor_5_0_downsample_1_running_var: \"f32[512]\", b_features_extractor_5_0_downsample_1_num_batches_tracked: \"i64[]\", b_features_extractor_5_1_bn1_running_mean: \"f32[128]\", b_features_extractor_5_1_bn1_running_var: \"f32[128]\", b_features_extractor_5_1_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_1_bn2_running_mean: \"f32[128]\", b_features_extractor_5_1_bn2_running_var: \"f32[128]\", b_features_extractor_5_1_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_1_bn3_running_mean: \"f32[512]\", b_features_extractor_5_1_bn3_running_var: \"f32[512]\", b_features_extractor_5_1_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_2_bn1_running_mean: \"f32[128]\", b_features_extractor_5_2_bn1_running_var: \"f32[128]\", b_features_extractor_5_2_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_2_bn2_running_mean: \"f32[128]\", b_features_extractor_5_2_bn2_running_var: \"f32[128]\", b_features_extractor_5_2_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_2_bn3_running_mean: \"f32[512]\", b_features_extractor_5_2_bn3_running_var: \"f32[512]\", b_features_extractor_5_2_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_3_bn1_running_mean: \"f32[128]\", b_features_extractor_5_3_bn1_running_var: \"f32[128]\", b_features_extractor_5_3_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_3_bn2_running_mean: \"f32[128]\", b_features_extractor_5_3_bn2_running_var: \"f32[128]\", b_features_extractor_5_3_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_3_bn3_running_mean: \"f32[512]\", b_features_extractor_5_3_bn3_running_var: \"f32[512]\", b_features_extractor_5_3_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_4_bn1_running_mean: \"f32[128]\", b_features_extractor_5_4_bn1_running_var: \"f32[128]\", b_features_extractor_5_4_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_4_bn2_running_mean: \"f32[128]\", b_features_extractor_5_4_bn2_running_var: \"f32[128]\", b_features_extractor_5_4_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_4_bn3_running_mean: \"f32[512]\", b_features_extractor_5_4_bn3_running_var: \"f32[512]\", b_features_extractor_5_4_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_5_bn1_running_mean: \"f32[128]\", b_features_extractor_5_5_bn1_running_var: \"f32[128]\", b_features_extractor_5_5_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_5_bn2_running_mean: \"f32[128]\", b_features_extractor_5_5_bn2_running_var: \"f32[128]\", b_features_extractor_5_5_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_5_bn3_running_mean: \"f32[512]\", b_features_extractor_5_5_bn3_running_var: \"f32[512]\", b_features_extractor_5_5_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_6_bn1_running_mean: \"f32[128]\", b_features_extractor_5_6_bn1_running_var: \"f32[128]\", b_features_extractor_5_6_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_6_bn2_running_mean: \"f32[128]\", b_features_extractor_5_6_bn2_running_var: \"f32[128]\", b_features_extractor_5_6_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_6_bn3_running_mean: \"f32[512]\", b_features_extractor_5_6_bn3_running_var: \"f32[512]\", b_features_extractor_5_6_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_5_7_bn1_running_mean: \"f32[128]\", b_features_extractor_5_7_bn1_running_var: \"f32[128]\", b_features_extractor_5_7_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_5_7_bn2_running_mean: \"f32[128]\", b_features_extractor_5_7_bn2_running_var: \"f32[128]\", b_features_extractor_5_7_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_5_7_bn3_running_mean: \"f32[512]\", b_features_extractor_5_7_bn3_running_var: \"f32[512]\", b_features_extractor_5_7_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_0_bn1_running_mean: \"f32[256]\", b_features_extractor_6_0_bn1_running_var: \"f32[256]\", b_features_extractor_6_0_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_0_bn2_running_mean: \"f32[256]\", b_features_extractor_6_0_bn2_running_var: \"f32[256]\", b_features_extractor_6_0_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_0_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_0_bn3_running_var: \"f32[1024]\", b_features_extractor_6_0_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_0_downsample_1_running_mean: \"f32[1024]\", b_features_extractor_6_0_downsample_1_running_var: \"f32[1024]\", b_features_extractor_6_0_downsample_1_num_batches_tracked: \"i64[]\", b_features_extractor_6_1_bn1_running_mean: \"f32[256]\", b_features_extractor_6_1_bn1_running_var: \"f32[256]\", b_features_extractor_6_1_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_1_bn2_running_mean: \"f32[256]\", b_features_extractor_6_1_bn2_running_var: \"f32[256]\", b_features_extractor_6_1_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_1_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_1_bn3_running_var: \"f32[1024]\", b_features_extractor_6_1_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_2_bn1_running_mean: \"f32[256]\", b_features_extractor_6_2_bn1_running_var: \"f32[256]\", b_features_extractor_6_2_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_2_bn2_running_mean: \"f32[256]\", b_features_extractor_6_2_bn2_running_var: \"f32[256]\", b_features_extractor_6_2_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_2_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_2_bn3_running_var: \"f32[1024]\", b_features_extractor_6_2_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_3_bn1_running_mean: \"f32[256]\", b_features_extractor_6_3_bn1_running_var: \"f32[256]\", b_features_extractor_6_3_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_3_bn2_running_mean: \"f32[256]\", b_features_extractor_6_3_bn2_running_var: \"f32[256]\", b_features_extractor_6_3_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_3_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_3_bn3_running_var: \"f32[1024]\", b_features_extractor_6_3_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_4_bn1_running_mean: \"f32[256]\", b_features_extractor_6_4_bn1_running_var: \"f32[256]\", b_features_extractor_6_4_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_4_bn2_running_mean: \"f32[256]\", b_features_extractor_6_4_bn2_running_var: \"f32[256]\", b_features_extractor_6_4_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_4_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_4_bn3_running_var: \"f32[1024]\", b_features_extractor_6_4_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_5_bn1_running_mean: \"f32[256]\", b_features_extractor_6_5_bn1_running_var: \"f32[256]\", b_features_extractor_6_5_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_5_bn2_running_mean: \"f32[256]\", b_features_extractor_6_5_bn2_running_var: \"f32[256]\", b_features_extractor_6_5_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_5_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_5_bn3_running_var: \"f32[1024]\", b_features_extractor_6_5_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_6_bn1_running_mean: \"f32[256]\", b_features_extractor_6_6_bn1_running_var: \"f32[256]\", b_features_extractor_6_6_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_6_bn2_running_mean: \"f32[256]\", b_features_extractor_6_6_bn2_running_var: \"f32[256]\", b_features_extractor_6_6_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_6_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_6_bn3_running_var: \"f32[1024]\", b_features_extractor_6_6_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_7_bn1_running_mean: \"f32[256]\", b_features_extractor_6_7_bn1_running_var: \"f32[256]\", b_features_extractor_6_7_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_7_bn2_running_mean: \"f32[256]\", b_features_extractor_6_7_bn2_running_var: \"f32[256]\", b_features_extractor_6_7_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_7_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_7_bn3_running_var: \"f32[1024]\", b_features_extractor_6_7_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_8_bn1_running_mean: \"f32[256]\", b_features_extractor_6_8_bn1_running_var: \"f32[256]\", b_features_extractor_6_8_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_8_bn2_running_mean: \"f32[256]\", b_features_extractor_6_8_bn2_running_var: \"f32[256]\", b_features_extractor_6_8_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_8_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_8_bn3_running_var: \"f32[1024]\", b_features_extractor_6_8_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_9_bn1_running_mean: \"f32[256]\", b_features_extractor_6_9_bn1_running_var: \"f32[256]\", b_features_extractor_6_9_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_9_bn2_running_mean: \"f32[256]\", b_features_extractor_6_9_bn2_running_var: \"f32[256]\", b_features_extractor_6_9_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_9_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_9_bn3_running_var: \"f32[1024]\", b_features_extractor_6_9_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_10_bn1_running_mean: \"f32[256]\", b_features_extractor_6_10_bn1_running_var: \"f32[256]\", b_features_extractor_6_10_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_10_bn2_running_mean: \"f32[256]\", b_features_extractor_6_10_bn2_running_var: \"f32[256]\", b_features_extractor_6_10_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_10_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_10_bn3_running_var: \"f32[1024]\", b_features_extractor_6_10_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_11_bn1_running_mean: \"f32[256]\", b_features_extractor_6_11_bn1_running_var: \"f32[256]\", b_features_extractor_6_11_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_11_bn2_running_mean: \"f32[256]\", b_features_extractor_6_11_bn2_running_var: \"f32[256]\", b_features_extractor_6_11_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_11_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_11_bn3_running_var: \"f32[1024]\", b_features_extractor_6_11_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_12_bn1_running_mean: \"f32[256]\", b_features_extractor_6_12_bn1_running_var: \"f32[256]\", b_features_extractor_6_12_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_12_bn2_running_mean: \"f32[256]\", b_features_extractor_6_12_bn2_running_var: \"f32[256]\", b_features_extractor_6_12_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_12_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_12_bn3_running_var: \"f32[1024]\", b_features_extractor_6_12_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_13_bn1_running_mean: \"f32[256]\", b_features_extractor_6_13_bn1_running_var: \"f32[256]\", b_features_extractor_6_13_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_13_bn2_running_mean: \"f32[256]\", b_features_extractor_6_13_bn2_running_var: \"f32[256]\", b_features_extractor_6_13_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_13_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_13_bn3_running_var: \"f32[1024]\", b_features_extractor_6_13_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_14_bn1_running_mean: \"f32[256]\", b_features_extractor_6_14_bn1_running_var: \"f32[256]\", b_features_extractor_6_14_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_14_bn2_running_mean: \"f32[256]\", b_features_extractor_6_14_bn2_running_var: \"f32[256]\", b_features_extractor_6_14_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_14_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_14_bn3_running_var: \"f32[1024]\", b_features_extractor_6_14_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_15_bn1_running_mean: \"f32[256]\", b_features_extractor_6_15_bn1_running_var: \"f32[256]\", b_features_extractor_6_15_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_15_bn2_running_mean: \"f32[256]\", b_features_extractor_6_15_bn2_running_var: \"f32[256]\", b_features_extractor_6_15_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_15_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_15_bn3_running_var: \"f32[1024]\", b_features_extractor_6_15_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_16_bn1_running_mean: \"f32[256]\", b_features_extractor_6_16_bn1_running_var: \"f32[256]\", b_features_extractor_6_16_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_16_bn2_running_mean: \"f32[256]\", b_features_extractor_6_16_bn2_running_var: \"f32[256]\", b_features_extractor_6_16_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_16_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_16_bn3_running_var: \"f32[1024]\", b_features_extractor_6_16_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_17_bn1_running_mean: \"f32[256]\", b_features_extractor_6_17_bn1_running_var: \"f32[256]\", b_features_extractor_6_17_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_17_bn2_running_mean: \"f32[256]\", b_features_extractor_6_17_bn2_running_var: \"f32[256]\", b_features_extractor_6_17_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_17_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_17_bn3_running_var: \"f32[1024]\", b_features_extractor_6_17_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_18_bn1_running_mean: \"f32[256]\", b_features_extractor_6_18_bn1_running_var: \"f32[256]\", b_features_extractor_6_18_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_18_bn2_running_mean: \"f32[256]\", b_features_extractor_6_18_bn2_running_var: \"f32[256]\", b_features_extractor_6_18_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_18_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_18_bn3_running_var: \"f32[1024]\", b_features_extractor_6_18_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_19_bn1_running_mean: \"f32[256]\", b_features_extractor_6_19_bn1_running_var: \"f32[256]\", b_features_extractor_6_19_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_19_bn2_running_mean: \"f32[256]\", b_features_extractor_6_19_bn2_running_var: \"f32[256]\", b_features_extractor_6_19_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_19_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_19_bn3_running_var: \"f32[1024]\", b_features_extractor_6_19_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_20_bn1_running_mean: \"f32[256]\", b_features_extractor_6_20_bn1_running_var: \"f32[256]\", b_features_extractor_6_20_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_20_bn2_running_mean: \"f32[256]\", b_features_extractor_6_20_bn2_running_var: \"f32[256]\", b_features_extractor_6_20_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_20_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_20_bn3_running_var: \"f32[1024]\", b_features_extractor_6_20_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_21_bn1_running_mean: \"f32[256]\", b_features_extractor_6_21_bn1_running_var: \"f32[256]\", b_features_extractor_6_21_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_21_bn2_running_mean: \"f32[256]\", b_features_extractor_6_21_bn2_running_var: \"f32[256]\", b_features_extractor_6_21_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_21_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_21_bn3_running_var: \"f32[1024]\", b_features_extractor_6_21_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_22_bn1_running_mean: \"f32[256]\", b_features_extractor_6_22_bn1_running_var: \"f32[256]\", b_features_extractor_6_22_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_22_bn2_running_mean: \"f32[256]\", b_features_extractor_6_22_bn2_running_var: \"f32[256]\", b_features_extractor_6_22_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_22_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_22_bn3_running_var: \"f32[1024]\", b_features_extractor_6_22_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_23_bn1_running_mean: \"f32[256]\", b_features_extractor_6_23_bn1_running_var: \"f32[256]\", b_features_extractor_6_23_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_23_bn2_running_mean: \"f32[256]\", b_features_extractor_6_23_bn2_running_var: \"f32[256]\", b_features_extractor_6_23_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_23_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_23_bn3_running_var: \"f32[1024]\", b_features_extractor_6_23_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_24_bn1_running_mean: \"f32[256]\", b_features_extractor_6_24_bn1_running_var: \"f32[256]\", b_features_extractor_6_24_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_24_bn2_running_mean: \"f32[256]\", b_features_extractor_6_24_bn2_running_var: \"f32[256]\", b_features_extractor_6_24_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_24_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_24_bn3_running_var: \"f32[1024]\", b_features_extractor_6_24_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_25_bn1_running_mean: \"f32[256]\", b_features_extractor_6_25_bn1_running_var: \"f32[256]\", b_features_extractor_6_25_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_25_bn2_running_mean: \"f32[256]\", b_features_extractor_6_25_bn2_running_var: \"f32[256]\", b_features_extractor_6_25_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_25_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_25_bn3_running_var: \"f32[1024]\", b_features_extractor_6_25_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_26_bn1_running_mean: \"f32[256]\", b_features_extractor_6_26_bn1_running_var: \"f32[256]\", b_features_extractor_6_26_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_26_bn2_running_mean: \"f32[256]\", b_features_extractor_6_26_bn2_running_var: \"f32[256]\", b_features_extractor_6_26_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_26_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_26_bn3_running_var: \"f32[1024]\", b_features_extractor_6_26_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_27_bn1_running_mean: \"f32[256]\", b_features_extractor_6_27_bn1_running_var: \"f32[256]\", b_features_extractor_6_27_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_27_bn2_running_mean: \"f32[256]\", b_features_extractor_6_27_bn2_running_var: \"f32[256]\", b_features_extractor_6_27_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_27_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_27_bn3_running_var: \"f32[1024]\", b_features_extractor_6_27_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_28_bn1_running_mean: \"f32[256]\", b_features_extractor_6_28_bn1_running_var: \"f32[256]\", b_features_extractor_6_28_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_28_bn2_running_mean: \"f32[256]\", b_features_extractor_6_28_bn2_running_var: \"f32[256]\", b_features_extractor_6_28_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_28_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_28_bn3_running_var: \"f32[1024]\", b_features_extractor_6_28_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_29_bn1_running_mean: \"f32[256]\", b_features_extractor_6_29_bn1_running_var: \"f32[256]\", b_features_extractor_6_29_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_29_bn2_running_mean: \"f32[256]\", b_features_extractor_6_29_bn2_running_var: \"f32[256]\", b_features_extractor_6_29_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_29_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_29_bn3_running_var: \"f32[1024]\", b_features_extractor_6_29_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_30_bn1_running_mean: \"f32[256]\", b_features_extractor_6_30_bn1_running_var: \"f32[256]\", b_features_extractor_6_30_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_30_bn2_running_mean: \"f32[256]\", b_features_extractor_6_30_bn2_running_var: \"f32[256]\", b_features_extractor_6_30_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_30_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_30_bn3_running_var: \"f32[1024]\", b_features_extractor_6_30_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_31_bn1_running_mean: \"f32[256]\", b_features_extractor_6_31_bn1_running_var: \"f32[256]\", b_features_extractor_6_31_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_31_bn2_running_mean: \"f32[256]\", b_features_extractor_6_31_bn2_running_var: \"f32[256]\", b_features_extractor_6_31_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_31_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_31_bn3_running_var: \"f32[1024]\", b_features_extractor_6_31_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_32_bn1_running_mean: \"f32[256]\", b_features_extractor_6_32_bn1_running_var: \"f32[256]\", b_features_extractor_6_32_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_32_bn2_running_mean: \"f32[256]\", b_features_extractor_6_32_bn2_running_var: \"f32[256]\", b_features_extractor_6_32_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_32_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_32_bn3_running_var: \"f32[1024]\", b_features_extractor_6_32_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_33_bn1_running_mean: \"f32[256]\", b_features_extractor_6_33_bn1_running_var: \"f32[256]\", b_features_extractor_6_33_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_33_bn2_running_mean: \"f32[256]\", b_features_extractor_6_33_bn2_running_var: \"f32[256]\", b_features_extractor_6_33_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_33_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_33_bn3_running_var: \"f32[1024]\", b_features_extractor_6_33_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_34_bn1_running_mean: \"f32[256]\", b_features_extractor_6_34_bn1_running_var: \"f32[256]\", b_features_extractor_6_34_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_34_bn2_running_mean: \"f32[256]\", b_features_extractor_6_34_bn2_running_var: \"f32[256]\", b_features_extractor_6_34_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_34_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_34_bn3_running_var: \"f32[1024]\", b_features_extractor_6_34_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_6_35_bn1_running_mean: \"f32[256]\", b_features_extractor_6_35_bn1_running_var: \"f32[256]\", b_features_extractor_6_35_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_6_35_bn2_running_mean: \"f32[256]\", b_features_extractor_6_35_bn2_running_var: \"f32[256]\", b_features_extractor_6_35_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_6_35_bn3_running_mean: \"f32[1024]\", b_features_extractor_6_35_bn3_running_var: \"f32[1024]\", b_features_extractor_6_35_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_7_0_bn1_running_mean: \"f32[512]\", b_features_extractor_7_0_bn1_running_var: \"f32[512]\", b_features_extractor_7_0_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_7_0_bn2_running_mean: \"f32[512]\", b_features_extractor_7_0_bn2_running_var: \"f32[512]\", b_features_extractor_7_0_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_7_0_bn3_running_mean: \"f32[2048]\", b_features_extractor_7_0_bn3_running_var: \"f32[2048]\", b_features_extractor_7_0_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_7_0_downsample_1_running_mean: \"f32[2048]\", b_features_extractor_7_0_downsample_1_running_var: \"f32[2048]\", b_features_extractor_7_0_downsample_1_num_batches_tracked: \"i64[]\", b_features_extractor_7_1_bn1_running_mean: \"f32[512]\", b_features_extractor_7_1_bn1_running_var: \"f32[512]\", b_features_extractor_7_1_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_7_1_bn2_running_mean: \"f32[512]\", b_features_extractor_7_1_bn2_running_var: \"f32[512]\", b_features_extractor_7_1_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_7_1_bn3_running_mean: \"f32[2048]\", b_features_extractor_7_1_bn3_running_var: \"f32[2048]\", b_features_extractor_7_1_bn3_num_batches_tracked: \"i64[]\", b_features_extractor_7_2_bn1_running_mean: \"f32[512]\", b_features_extractor_7_2_bn1_running_var: \"f32[512]\", b_features_extractor_7_2_bn1_num_batches_tracked: \"i64[]\", b_features_extractor_7_2_bn2_running_mean: \"f32[512]\", b_features_extractor_7_2_bn2_running_var: \"f32[512]\", b_features_extractor_7_2_bn2_num_batches_tracked: \"i64[]\", b_features_extractor_7_2_bn3_running_mean: \"f32[2048]\", b_features_extractor_7_2_bn3_running_var: \"f32[2048]\", b_features_extractor_7_2_bn3_num_batches_tracked: \"i64[]\", x: \"f32[s77, 3, 224, 224]\"):\n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[s77, 64, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_features_extractor_0_weight, None, [2, 2], [3, 3]);  x = p_features_extractor_0_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_features_extractor_1_weight, p_features_extractor_1_bias, b_features_extractor_1_running_mean, b_features_extractor_1_running_var, 0.1, 1e-05);  conv2d = p_features_extractor_1_weight = p_features_extractor_1_bias = b_features_extractor_1_running_mean = b_features_extractor_1_running_var = None\n",
       "                    getitem: \"f32[s77, 64, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu: \"f32[s77, 64, 112, 112]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:226 in forward, code: return F.max_pool2d(\n",
       "                    max_pool2d: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.max_pool2d.default(relu, [3, 3], [2, 2], [1, 1]);  relu = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_features_extractor_4_0_conv1_weight);  p_features_extractor_4_0_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_features_extractor_4_0_bn1_weight, p_features_extractor_4_0_bn1_bias, b_features_extractor_4_0_bn1_running_mean, b_features_extractor_4_0_bn1_running_var, 0.1, 1e-05);  conv2d_1 = p_features_extractor_4_0_bn1_weight = p_features_extractor_4_0_bn1_bias = b_features_extractor_4_0_bn1_running_mean = b_features_extractor_4_0_bn1_running_var = None\n",
       "                    getitem_3: \"f32[s77, 64, 56, 56]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_1: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_1, p_features_extractor_4_0_conv2_weight, None, [1, 1], [1, 1]);  relu_1 = p_features_extractor_4_0_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_features_extractor_4_0_bn2_weight, p_features_extractor_4_0_bn2_bias, b_features_extractor_4_0_bn2_running_mean, b_features_extractor_4_0_bn2_running_var, 0.1, 1e-05);  conv2d_2 = p_features_extractor_4_0_bn2_weight = p_features_extractor_4_0_bn2_bias = b_features_extractor_4_0_bn2_running_mean = b_features_extractor_4_0_bn2_running_var = None\n",
       "                    getitem_6: \"f32[s77, 64, 56, 56]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_2: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_6);  getitem_6 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.conv2d.default(relu_2, p_features_extractor_4_0_conv3_weight);  relu_2 = p_features_extractor_4_0_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_features_extractor_4_0_bn3_weight, p_features_extractor_4_0_bn3_bias, b_features_extractor_4_0_bn3_running_mean, b_features_extractor_4_0_bn3_running_var, 0.1, 1e-05);  conv2d_3 = p_features_extractor_4_0_bn3_weight = p_features_extractor_4_0_bn3_bias = b_features_extractor_4_0_bn3_running_mean = b_features_extractor_4_0_bn3_running_var = None\n",
       "                    getitem_9: \"f32[s77, 256, 56, 56]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.conv2d.default(max_pool2d, p_features_extractor_4_0_downsample_0_weight);  max_pool2d = p_features_extractor_4_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_features_extractor_4_0_downsample_1_weight, p_features_extractor_4_0_downsample_1_bias, b_features_extractor_4_0_downsample_1_running_mean, b_features_extractor_4_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_4 = p_features_extractor_4_0_downsample_1_weight = p_features_extractor_4_0_downsample_1_bias = b_features_extractor_4_0_downsample_1_running_mean = b_features_extractor_4_0_downsample_1_running_var = None\n",
       "                    getitem_12: \"f32[s77, 256, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_95: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_9, getitem_12);  getitem_9 = getitem_12 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_3: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.relu.default(add_95);  add_95 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_3, p_features_extractor_4_1_conv1_weight);  p_features_extractor_4_1_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_features_extractor_4_1_bn1_weight, p_features_extractor_4_1_bn1_bias, b_features_extractor_4_1_bn1_running_mean, b_features_extractor_4_1_bn1_running_var, 0.1, 1e-05);  conv2d_5 = p_features_extractor_4_1_bn1_weight = p_features_extractor_4_1_bn1_bias = b_features_extractor_4_1_bn1_running_mean = b_features_extractor_4_1_bn1_running_var = None\n",
       "                    getitem_15: \"f32[s77, 64, 56, 56]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_4: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_4, p_features_extractor_4_1_conv2_weight, None, [1, 1], [1, 1]);  relu_4 = p_features_extractor_4_1_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_features_extractor_4_1_bn2_weight, p_features_extractor_4_1_bn2_bias, b_features_extractor_4_1_bn2_running_mean, b_features_extractor_4_1_bn2_running_var, 0.1, 1e-05);  conv2d_6 = p_features_extractor_4_1_bn2_weight = p_features_extractor_4_1_bn2_bias = b_features_extractor_4_1_bn2_running_mean = b_features_extractor_4_1_bn2_running_var = None\n",
       "                    getitem_18: \"f32[s77, 64, 56, 56]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_5: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_18);  getitem_18 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.conv2d.default(relu_5, p_features_extractor_4_1_conv3_weight);  relu_5 = p_features_extractor_4_1_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_features_extractor_4_1_bn3_weight, p_features_extractor_4_1_bn3_bias, b_features_extractor_4_1_bn3_running_mean, b_features_extractor_4_1_bn3_running_var, 0.1, 1e-05);  conv2d_7 = p_features_extractor_4_1_bn3_weight = p_features_extractor_4_1_bn3_bias = b_features_extractor_4_1_bn3_running_mean = b_features_extractor_4_1_bn3_running_var = None\n",
       "                    getitem_21: \"f32[s77, 256, 56, 56]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_171: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_21, relu_3);  getitem_21 = relu_3 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_6: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.relu.default(add_171);  add_171 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_6, p_features_extractor_4_2_conv1_weight);  p_features_extractor_4_2_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_features_extractor_4_2_bn1_weight, p_features_extractor_4_2_bn1_bias, b_features_extractor_4_2_bn1_running_mean, b_features_extractor_4_2_bn1_running_var, 0.1, 1e-05);  conv2d_8 = p_features_extractor_4_2_bn1_weight = p_features_extractor_4_2_bn1_bias = b_features_extractor_4_2_bn1_running_mean = b_features_extractor_4_2_bn1_running_var = None\n",
       "                    getitem_24: \"f32[s77, 64, 56, 56]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_7: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.conv2d.default(relu_7, p_features_extractor_4_2_conv2_weight, None, [1, 1], [1, 1]);  relu_7 = p_features_extractor_4_2_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_features_extractor_4_2_bn2_weight, p_features_extractor_4_2_bn2_bias, b_features_extractor_4_2_bn2_running_mean, b_features_extractor_4_2_bn2_running_var, 0.1, 1e-05);  conv2d_9 = p_features_extractor_4_2_bn2_weight = p_features_extractor_4_2_bn2_bias = b_features_extractor_4_2_bn2_running_mean = b_features_extractor_4_2_bn2_running_var = None\n",
       "                    getitem_27: \"f32[s77, 64, 56, 56]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_8: \"f32[s77, 64, 56, 56]\" = torch.ops.aten.relu.default(getitem_27);  getitem_27 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.conv2d.default(relu_8, p_features_extractor_4_2_conv3_weight);  relu_8 = p_features_extractor_4_2_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_features_extractor_4_2_bn3_weight, p_features_extractor_4_2_bn3_bias, b_features_extractor_4_2_bn3_running_mean, b_features_extractor_4_2_bn3_running_var, 0.1, 1e-05);  conv2d_10 = p_features_extractor_4_2_bn3_weight = p_features_extractor_4_2_bn3_bias = b_features_extractor_4_2_bn3_running_mean = b_features_extractor_4_2_bn3_running_var = None\n",
       "                    getitem_30: \"f32[s77, 256, 56, 56]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_247: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_30, relu_6);  getitem_30 = relu_6 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_9: \"f32[s77, 256, 56, 56]\" = torch.ops.aten.relu.default(add_247);  add_247 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[s77, 128, 56, 56]\" = torch.ops.aten.conv2d.default(relu_9, p_features_extractor_5_0_conv1_weight);  p_features_extractor_5_0_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_features_extractor_5_0_bn1_weight, p_features_extractor_5_0_bn1_bias, b_features_extractor_5_0_bn1_running_mean, b_features_extractor_5_0_bn1_running_var, 0.1, 1e-05);  conv2d_11 = p_features_extractor_5_0_bn1_weight = p_features_extractor_5_0_bn1_bias = b_features_extractor_5_0_bn1_running_mean = b_features_extractor_5_0_bn1_running_var = None\n",
       "                    getitem_33: \"f32[s77, 128, 56, 56]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_10: \"f32[s77, 128, 56, 56]\" = torch.ops.aten.relu.default(getitem_33);  getitem_33 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_10, p_features_extractor_5_0_conv2_weight, None, [2, 2], [1, 1]);  relu_10 = p_features_extractor_5_0_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_features_extractor_5_0_bn2_weight, p_features_extractor_5_0_bn2_bias, b_features_extractor_5_0_bn2_running_mean, b_features_extractor_5_0_bn2_running_var, 0.1, 1e-05);  conv2d_12 = p_features_extractor_5_0_bn2_weight = p_features_extractor_5_0_bn2_bias = b_features_extractor_5_0_bn2_running_mean = b_features_extractor_5_0_bn2_running_var = None\n",
       "                    getitem_36: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_11: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_36);  getitem_36 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_11, p_features_extractor_5_0_conv3_weight);  relu_11 = p_features_extractor_5_0_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_features_extractor_5_0_bn3_weight, p_features_extractor_5_0_bn3_bias, b_features_extractor_5_0_bn3_running_mean, b_features_extractor_5_0_bn3_running_var, 0.1, 1e-05);  conv2d_13 = p_features_extractor_5_0_bn3_weight = p_features_extractor_5_0_bn3_bias = b_features_extractor_5_0_bn3_running_mean = b_features_extractor_5_0_bn3_running_var = None\n",
       "                    getitem_39: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_9, p_features_extractor_5_0_downsample_0_weight, None, [2, 2]);  relu_9 = p_features_extractor_5_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_features_extractor_5_0_downsample_1_weight, p_features_extractor_5_0_downsample_1_bias, b_features_extractor_5_0_downsample_1_running_mean, b_features_extractor_5_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_14 = p_features_extractor_5_0_downsample_1_weight = p_features_extractor_5_0_downsample_1_bias = b_features_extractor_5_0_downsample_1_running_mean = b_features_extractor_5_0_downsample_1_running_var = None\n",
       "                    getitem_42: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_333: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_39, getitem_42);  getitem_39 = getitem_42 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_12: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_333);  add_333 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_15: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_12, p_features_extractor_5_1_conv1_weight);  p_features_extractor_5_1_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_features_extractor_5_1_bn1_weight, p_features_extractor_5_1_bn1_bias, b_features_extractor_5_1_bn1_running_mean, b_features_extractor_5_1_bn1_running_var, 0.1, 1e-05);  conv2d_15 = p_features_extractor_5_1_bn1_weight = p_features_extractor_5_1_bn1_bias = b_features_extractor_5_1_bn1_running_mean = b_features_extractor_5_1_bn1_running_var = None\n",
       "                    getitem_45: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_13: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_16: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_13, p_features_extractor_5_1_conv2_weight, None, [1, 1], [1, 1]);  relu_13 = p_features_extractor_5_1_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_features_extractor_5_1_bn2_weight, p_features_extractor_5_1_bn2_bias, b_features_extractor_5_1_bn2_running_mean, b_features_extractor_5_1_bn2_running_var, 0.1, 1e-05);  conv2d_16 = p_features_extractor_5_1_bn2_weight = p_features_extractor_5_1_bn2_bias = b_features_extractor_5_1_bn2_running_mean = b_features_extractor_5_1_bn2_running_var = None\n",
       "                    getitem_48: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_14: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_48);  getitem_48 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_17: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_14, p_features_extractor_5_1_conv3_weight);  relu_14 = p_features_extractor_5_1_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_features_extractor_5_1_bn3_weight, p_features_extractor_5_1_bn3_bias, b_features_extractor_5_1_bn3_running_mean, b_features_extractor_5_1_bn3_running_var, 0.1, 1e-05);  conv2d_17 = p_features_extractor_5_1_bn3_weight = p_features_extractor_5_1_bn3_bias = b_features_extractor_5_1_bn3_running_mean = b_features_extractor_5_1_bn3_running_var = None\n",
       "                    getitem_51: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_409: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_51, relu_12);  getitem_51 = relu_12 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_15: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_409);  add_409 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_18: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_15, p_features_extractor_5_2_conv1_weight);  p_features_extractor_5_2_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_features_extractor_5_2_bn1_weight, p_features_extractor_5_2_bn1_bias, b_features_extractor_5_2_bn1_running_mean, b_features_extractor_5_2_bn1_running_var, 0.1, 1e-05);  conv2d_18 = p_features_extractor_5_2_bn1_weight = p_features_extractor_5_2_bn1_bias = b_features_extractor_5_2_bn1_running_mean = b_features_extractor_5_2_bn1_running_var = None\n",
       "                    getitem_54: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_16: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_19: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_16, p_features_extractor_5_2_conv2_weight, None, [1, 1], [1, 1]);  relu_16 = p_features_extractor_5_2_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_features_extractor_5_2_bn2_weight, p_features_extractor_5_2_bn2_bias, b_features_extractor_5_2_bn2_running_mean, b_features_extractor_5_2_bn2_running_var, 0.1, 1e-05);  conv2d_19 = p_features_extractor_5_2_bn2_weight = p_features_extractor_5_2_bn2_bias = b_features_extractor_5_2_bn2_running_mean = b_features_extractor_5_2_bn2_running_var = None\n",
       "                    getitem_57: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_17: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_57);  getitem_57 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_20: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_17, p_features_extractor_5_2_conv3_weight);  relu_17 = p_features_extractor_5_2_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_20, p_features_extractor_5_2_bn3_weight, p_features_extractor_5_2_bn3_bias, b_features_extractor_5_2_bn3_running_mean, b_features_extractor_5_2_bn3_running_var, 0.1, 1e-05);  conv2d_20 = p_features_extractor_5_2_bn3_weight = p_features_extractor_5_2_bn3_bias = b_features_extractor_5_2_bn3_running_mean = b_features_extractor_5_2_bn3_running_var = None\n",
       "                    getitem_60: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_485: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_60, relu_15);  getitem_60 = relu_15 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_18: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_485);  add_485 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_21: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_18, p_features_extractor_5_3_conv1_weight);  p_features_extractor_5_3_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_21, p_features_extractor_5_3_bn1_weight, p_features_extractor_5_3_bn1_bias, b_features_extractor_5_3_bn1_running_mean, b_features_extractor_5_3_bn1_running_var, 0.1, 1e-05);  conv2d_21 = p_features_extractor_5_3_bn1_weight = p_features_extractor_5_3_bn1_bias = b_features_extractor_5_3_bn1_running_mean = b_features_extractor_5_3_bn1_running_var = None\n",
       "                    getitem_63: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_21[0];  _native_batch_norm_legit_no_training_21 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_19: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_63);  getitem_63 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_22: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_19, p_features_extractor_5_3_conv2_weight, None, [1, 1], [1, 1]);  relu_19 = p_features_extractor_5_3_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_22, p_features_extractor_5_3_bn2_weight, p_features_extractor_5_3_bn2_bias, b_features_extractor_5_3_bn2_running_mean, b_features_extractor_5_3_bn2_running_var, 0.1, 1e-05);  conv2d_22 = p_features_extractor_5_3_bn2_weight = p_features_extractor_5_3_bn2_bias = b_features_extractor_5_3_bn2_running_mean = b_features_extractor_5_3_bn2_running_var = None\n",
       "                    getitem_66: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_20: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_66);  getitem_66 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_23: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_20, p_features_extractor_5_3_conv3_weight);  relu_20 = p_features_extractor_5_3_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_23, p_features_extractor_5_3_bn3_weight, p_features_extractor_5_3_bn3_bias, b_features_extractor_5_3_bn3_running_mean, b_features_extractor_5_3_bn3_running_var, 0.1, 1e-05);  conv2d_23 = p_features_extractor_5_3_bn3_weight = p_features_extractor_5_3_bn3_bias = b_features_extractor_5_3_bn3_running_mean = b_features_extractor_5_3_bn3_running_var = None\n",
       "                    getitem_69: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_23[0];  _native_batch_norm_legit_no_training_23 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_561: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_69, relu_18);  getitem_69 = relu_18 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_21: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_561);  add_561 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_24: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_21, p_features_extractor_5_4_conv1_weight);  p_features_extractor_5_4_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_24, p_features_extractor_5_4_bn1_weight, p_features_extractor_5_4_bn1_bias, b_features_extractor_5_4_bn1_running_mean, b_features_extractor_5_4_bn1_running_var, 0.1, 1e-05);  conv2d_24 = p_features_extractor_5_4_bn1_weight = p_features_extractor_5_4_bn1_bias = b_features_extractor_5_4_bn1_running_mean = b_features_extractor_5_4_bn1_running_var = None\n",
       "                    getitem_72: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_22: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_72);  getitem_72 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_25: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_22, p_features_extractor_5_4_conv2_weight, None, [1, 1], [1, 1]);  relu_22 = p_features_extractor_5_4_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_25, p_features_extractor_5_4_bn2_weight, p_features_extractor_5_4_bn2_bias, b_features_extractor_5_4_bn2_running_mean, b_features_extractor_5_4_bn2_running_var, 0.1, 1e-05);  conv2d_25 = p_features_extractor_5_4_bn2_weight = p_features_extractor_5_4_bn2_bias = b_features_extractor_5_4_bn2_running_mean = b_features_extractor_5_4_bn2_running_var = None\n",
       "                    getitem_75: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_25[0];  _native_batch_norm_legit_no_training_25 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_23: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_75);  getitem_75 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_26: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_23, p_features_extractor_5_4_conv3_weight);  relu_23 = p_features_extractor_5_4_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_26, p_features_extractor_5_4_bn3_weight, p_features_extractor_5_4_bn3_bias, b_features_extractor_5_4_bn3_running_mean, b_features_extractor_5_4_bn3_running_var, 0.1, 1e-05);  conv2d_26 = p_features_extractor_5_4_bn3_weight = p_features_extractor_5_4_bn3_bias = b_features_extractor_5_4_bn3_running_mean = b_features_extractor_5_4_bn3_running_var = None\n",
       "                    getitem_78: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_637: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_78, relu_21);  getitem_78 = relu_21 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_24: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_637);  add_637 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_27: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_24, p_features_extractor_5_5_conv1_weight);  p_features_extractor_5_5_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_27, p_features_extractor_5_5_bn1_weight, p_features_extractor_5_5_bn1_bias, b_features_extractor_5_5_bn1_running_mean, b_features_extractor_5_5_bn1_running_var, 0.1, 1e-05);  conv2d_27 = p_features_extractor_5_5_bn1_weight = p_features_extractor_5_5_bn1_bias = b_features_extractor_5_5_bn1_running_mean = b_features_extractor_5_5_bn1_running_var = None\n",
       "                    getitem_81: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_27[0];  _native_batch_norm_legit_no_training_27 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_25: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_81);  getitem_81 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_28: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_25, p_features_extractor_5_5_conv2_weight, None, [1, 1], [1, 1]);  relu_25 = p_features_extractor_5_5_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_28, p_features_extractor_5_5_bn2_weight, p_features_extractor_5_5_bn2_bias, b_features_extractor_5_5_bn2_running_mean, b_features_extractor_5_5_bn2_running_var, 0.1, 1e-05);  conv2d_28 = p_features_extractor_5_5_bn2_weight = p_features_extractor_5_5_bn2_bias = b_features_extractor_5_5_bn2_running_mean = b_features_extractor_5_5_bn2_running_var = None\n",
       "                    getitem_84: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_26: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_84);  getitem_84 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_29: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_26, p_features_extractor_5_5_conv3_weight);  relu_26 = p_features_extractor_5_5_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_29, p_features_extractor_5_5_bn3_weight, p_features_extractor_5_5_bn3_bias, b_features_extractor_5_5_bn3_running_mean, b_features_extractor_5_5_bn3_running_var, 0.1, 1e-05);  conv2d_29 = p_features_extractor_5_5_bn3_weight = p_features_extractor_5_5_bn3_bias = b_features_extractor_5_5_bn3_running_mean = b_features_extractor_5_5_bn3_running_var = None\n",
       "                    getitem_87: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_29[0];  _native_batch_norm_legit_no_training_29 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_713: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_87, relu_24);  getitem_87 = relu_24 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_27: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_713);  add_713 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_30: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_27, p_features_extractor_5_6_conv1_weight);  p_features_extractor_5_6_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_30, p_features_extractor_5_6_bn1_weight, p_features_extractor_5_6_bn1_bias, b_features_extractor_5_6_bn1_running_mean, b_features_extractor_5_6_bn1_running_var, 0.1, 1e-05);  conv2d_30 = p_features_extractor_5_6_bn1_weight = p_features_extractor_5_6_bn1_bias = b_features_extractor_5_6_bn1_running_mean = b_features_extractor_5_6_bn1_running_var = None\n",
       "                    getitem_90: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_28: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_90);  getitem_90 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_31: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_28, p_features_extractor_5_6_conv2_weight, None, [1, 1], [1, 1]);  relu_28 = p_features_extractor_5_6_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_31, p_features_extractor_5_6_bn2_weight, p_features_extractor_5_6_bn2_bias, b_features_extractor_5_6_bn2_running_mean, b_features_extractor_5_6_bn2_running_var, 0.1, 1e-05);  conv2d_31 = p_features_extractor_5_6_bn2_weight = p_features_extractor_5_6_bn2_bias = b_features_extractor_5_6_bn2_running_mean = b_features_extractor_5_6_bn2_running_var = None\n",
       "                    getitem_93: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_31[0];  _native_batch_norm_legit_no_training_31 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_29: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_93);  getitem_93 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_32: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_29, p_features_extractor_5_6_conv3_weight);  relu_29 = p_features_extractor_5_6_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_32, p_features_extractor_5_6_bn3_weight, p_features_extractor_5_6_bn3_bias, b_features_extractor_5_6_bn3_running_mean, b_features_extractor_5_6_bn3_running_var, 0.1, 1e-05);  conv2d_32 = p_features_extractor_5_6_bn3_weight = p_features_extractor_5_6_bn3_bias = b_features_extractor_5_6_bn3_running_mean = b_features_extractor_5_6_bn3_running_var = None\n",
       "                    getitem_96: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_789: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_96, relu_27);  getitem_96 = relu_27 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_30: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_789);  add_789 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_33: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_30, p_features_extractor_5_7_conv1_weight);  p_features_extractor_5_7_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_33, p_features_extractor_5_7_bn1_weight, p_features_extractor_5_7_bn1_bias, b_features_extractor_5_7_bn1_running_mean, b_features_extractor_5_7_bn1_running_var, 0.1, 1e-05);  conv2d_33 = p_features_extractor_5_7_bn1_weight = p_features_extractor_5_7_bn1_bias = b_features_extractor_5_7_bn1_running_mean = b_features_extractor_5_7_bn1_running_var = None\n",
       "                    getitem_99: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_33[0];  _native_batch_norm_legit_no_training_33 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_31: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_99);  getitem_99 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_34: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.conv2d.default(relu_31, p_features_extractor_5_7_conv2_weight, None, [1, 1], [1, 1]);  relu_31 = p_features_extractor_5_7_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_34, p_features_extractor_5_7_bn2_weight, p_features_extractor_5_7_bn2_bias, b_features_extractor_5_7_bn2_running_mean, b_features_extractor_5_7_bn2_running_var, 0.1, 1e-05);  conv2d_34 = p_features_extractor_5_7_bn2_weight = p_features_extractor_5_7_bn2_bias = b_features_extractor_5_7_bn2_running_mean = b_features_extractor_5_7_bn2_running_var = None\n",
       "                    getitem_102: \"f32[s77, 128, 28, 28]\" = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_32: \"f32[s77, 128, 28, 28]\" = torch.ops.aten.relu.default(getitem_102);  getitem_102 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_35: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.conv2d.default(relu_32, p_features_extractor_5_7_conv3_weight);  relu_32 = p_features_extractor_5_7_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_35, p_features_extractor_5_7_bn3_weight, p_features_extractor_5_7_bn3_bias, b_features_extractor_5_7_bn3_running_mean, b_features_extractor_5_7_bn3_running_var, 0.1, 1e-05);  conv2d_35 = p_features_extractor_5_7_bn3_weight = p_features_extractor_5_7_bn3_bias = b_features_extractor_5_7_bn3_running_mean = b_features_extractor_5_7_bn3_running_var = None\n",
       "                    getitem_105: \"f32[s77, 512, 28, 28]\" = _native_batch_norm_legit_no_training_35[0];  _native_batch_norm_legit_no_training_35 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_865: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_105, relu_30);  getitem_105 = relu_30 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_33: \"f32[s77, 512, 28, 28]\" = torch.ops.aten.relu.default(add_865);  add_865 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_36: \"f32[s77, 256, 28, 28]\" = torch.ops.aten.conv2d.default(relu_33, p_features_extractor_6_0_conv1_weight);  p_features_extractor_6_0_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_36, p_features_extractor_6_0_bn1_weight, p_features_extractor_6_0_bn1_bias, b_features_extractor_6_0_bn1_running_mean, b_features_extractor_6_0_bn1_running_var, 0.1, 1e-05);  conv2d_36 = p_features_extractor_6_0_bn1_weight = p_features_extractor_6_0_bn1_bias = b_features_extractor_6_0_bn1_running_mean = b_features_extractor_6_0_bn1_running_var = None\n",
       "                    getitem_108: \"f32[1, 256, 28, 28]\" = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_34: \"f32[1, 256, 28, 28]\" = torch.ops.aten.relu.default(getitem_108);  getitem_108 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_37: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_34, p_features_extractor_6_0_conv2_weight, None, [2, 2], [1, 1]);  relu_34 = p_features_extractor_6_0_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_37, p_features_extractor_6_0_bn2_weight, p_features_extractor_6_0_bn2_bias, b_features_extractor_6_0_bn2_running_mean, b_features_extractor_6_0_bn2_running_var, 0.1, 1e-05);  conv2d_37 = p_features_extractor_6_0_bn2_weight = p_features_extractor_6_0_bn2_bias = b_features_extractor_6_0_bn2_running_mean = b_features_extractor_6_0_bn2_running_var = None\n",
       "                    getitem_111: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_37[0];  _native_batch_norm_legit_no_training_37 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_35: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_111);  getitem_111 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_38: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_35, p_features_extractor_6_0_conv3_weight);  relu_35 = p_features_extractor_6_0_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_38, p_features_extractor_6_0_bn3_weight, p_features_extractor_6_0_bn3_bias, b_features_extractor_6_0_bn3_running_mean, b_features_extractor_6_0_bn3_running_var, 0.1, 1e-05);  conv2d_38 = p_features_extractor_6_0_bn3_weight = p_features_extractor_6_0_bn3_bias = b_features_extractor_6_0_bn3_running_mean = b_features_extractor_6_0_bn3_running_var = None\n",
       "                    getitem_114: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_39: \"f32[s77, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_33, p_features_extractor_6_0_downsample_0_weight, None, [2, 2]);  relu_33 = p_features_extractor_6_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_39, p_features_extractor_6_0_downsample_1_weight, p_features_extractor_6_0_downsample_1_bias, b_features_extractor_6_0_downsample_1_running_mean, b_features_extractor_6_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_39 = p_features_extractor_6_0_downsample_1_weight = p_features_extractor_6_0_downsample_1_bias = b_features_extractor_6_0_downsample_1_running_mean = b_features_extractor_6_0_downsample_1_running_var = None\n",
       "                    getitem_117: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_891: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_114, getitem_117);  getitem_114 = getitem_117 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_36: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_891);  add_891 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_40: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_36, p_features_extractor_6_1_conv1_weight);  p_features_extractor_6_1_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_40, p_features_extractor_6_1_bn1_weight, p_features_extractor_6_1_bn1_bias, b_features_extractor_6_1_bn1_running_mean, b_features_extractor_6_1_bn1_running_var, 0.1, 1e-05);  conv2d_40 = p_features_extractor_6_1_bn1_weight = p_features_extractor_6_1_bn1_bias = b_features_extractor_6_1_bn1_running_mean = b_features_extractor_6_1_bn1_running_var = None\n",
       "                    getitem_120: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_40[0];  _native_batch_norm_legit_no_training_40 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_37: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_120);  getitem_120 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_41: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_37, p_features_extractor_6_1_conv2_weight, None, [1, 1], [1, 1]);  relu_37 = p_features_extractor_6_1_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_41, p_features_extractor_6_1_bn2_weight, p_features_extractor_6_1_bn2_bias, b_features_extractor_6_1_bn2_running_mean, b_features_extractor_6_1_bn2_running_var, 0.1, 1e-05);  conv2d_41 = p_features_extractor_6_1_bn2_weight = p_features_extractor_6_1_bn2_bias = b_features_extractor_6_1_bn2_running_mean = b_features_extractor_6_1_bn2_running_var = None\n",
       "                    getitem_123: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_38: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_123);  getitem_123 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_42: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_38, p_features_extractor_6_1_conv3_weight);  relu_38 = p_features_extractor_6_1_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_42, p_features_extractor_6_1_bn3_weight, p_features_extractor_6_1_bn3_bias, b_features_extractor_6_1_bn3_running_mean, b_features_extractor_6_1_bn3_running_var, 0.1, 1e-05);  conv2d_42 = p_features_extractor_6_1_bn3_weight = p_features_extractor_6_1_bn3_bias = b_features_extractor_6_1_bn3_running_mean = b_features_extractor_6_1_bn3_running_var = None\n",
       "                    getitem_126: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_42[0];  _native_batch_norm_legit_no_training_42 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_892: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_126, relu_36);  getitem_126 = relu_36 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_39: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_892);  add_892 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_43: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_39, p_features_extractor_6_2_conv1_weight);  p_features_extractor_6_2_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_43, p_features_extractor_6_2_bn1_weight, p_features_extractor_6_2_bn1_bias, b_features_extractor_6_2_bn1_running_mean, b_features_extractor_6_2_bn1_running_var, 0.1, 1e-05);  conv2d_43 = p_features_extractor_6_2_bn1_weight = p_features_extractor_6_2_bn1_bias = b_features_extractor_6_2_bn1_running_mean = b_features_extractor_6_2_bn1_running_var = None\n",
       "                    getitem_129: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_40: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_129);  getitem_129 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_44: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_40, p_features_extractor_6_2_conv2_weight, None, [1, 1], [1, 1]);  relu_40 = p_features_extractor_6_2_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_44 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_44, p_features_extractor_6_2_bn2_weight, p_features_extractor_6_2_bn2_bias, b_features_extractor_6_2_bn2_running_mean, b_features_extractor_6_2_bn2_running_var, 0.1, 1e-05);  conv2d_44 = p_features_extractor_6_2_bn2_weight = p_features_extractor_6_2_bn2_bias = b_features_extractor_6_2_bn2_running_mean = b_features_extractor_6_2_bn2_running_var = None\n",
       "                    getitem_132: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_44[0];  _native_batch_norm_legit_no_training_44 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_41: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_132);  getitem_132 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_45: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_41, p_features_extractor_6_2_conv3_weight);  relu_41 = p_features_extractor_6_2_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_45, p_features_extractor_6_2_bn3_weight, p_features_extractor_6_2_bn3_bias, b_features_extractor_6_2_bn3_running_mean, b_features_extractor_6_2_bn3_running_var, 0.1, 1e-05);  conv2d_45 = p_features_extractor_6_2_bn3_weight = p_features_extractor_6_2_bn3_bias = b_features_extractor_6_2_bn3_running_mean = b_features_extractor_6_2_bn3_running_var = None\n",
       "                    getitem_135: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_45[0];  _native_batch_norm_legit_no_training_45 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_893: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_135, relu_39);  getitem_135 = relu_39 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_42: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_893);  add_893 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_46: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_42, p_features_extractor_6_3_conv1_weight);  p_features_extractor_6_3_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_46 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_46, p_features_extractor_6_3_bn1_weight, p_features_extractor_6_3_bn1_bias, b_features_extractor_6_3_bn1_running_mean, b_features_extractor_6_3_bn1_running_var, 0.1, 1e-05);  conv2d_46 = p_features_extractor_6_3_bn1_weight = p_features_extractor_6_3_bn1_bias = b_features_extractor_6_3_bn1_running_mean = b_features_extractor_6_3_bn1_running_var = None\n",
       "                    getitem_138: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_46[0];  _native_batch_norm_legit_no_training_46 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_43: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_138);  getitem_138 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_47: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_43, p_features_extractor_6_3_conv2_weight, None, [1, 1], [1, 1]);  relu_43 = p_features_extractor_6_3_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_47, p_features_extractor_6_3_bn2_weight, p_features_extractor_6_3_bn2_bias, b_features_extractor_6_3_bn2_running_mean, b_features_extractor_6_3_bn2_running_var, 0.1, 1e-05);  conv2d_47 = p_features_extractor_6_3_bn2_weight = p_features_extractor_6_3_bn2_bias = b_features_extractor_6_3_bn2_running_mean = b_features_extractor_6_3_bn2_running_var = None\n",
       "                    getitem_141: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_47[0];  _native_batch_norm_legit_no_training_47 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_44: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_141);  getitem_141 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_48: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_44, p_features_extractor_6_3_conv3_weight);  relu_44 = p_features_extractor_6_3_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_48 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_48, p_features_extractor_6_3_bn3_weight, p_features_extractor_6_3_bn3_bias, b_features_extractor_6_3_bn3_running_mean, b_features_extractor_6_3_bn3_running_var, 0.1, 1e-05);  conv2d_48 = p_features_extractor_6_3_bn3_weight = p_features_extractor_6_3_bn3_bias = b_features_extractor_6_3_bn3_running_mean = b_features_extractor_6_3_bn3_running_var = None\n",
       "                    getitem_144: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_48[0];  _native_batch_norm_legit_no_training_48 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_894: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_144, relu_42);  getitem_144 = relu_42 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_45: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_894);  add_894 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_49: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_45, p_features_extractor_6_4_conv1_weight);  p_features_extractor_6_4_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_49, p_features_extractor_6_4_bn1_weight, p_features_extractor_6_4_bn1_bias, b_features_extractor_6_4_bn1_running_mean, b_features_extractor_6_4_bn1_running_var, 0.1, 1e-05);  conv2d_49 = p_features_extractor_6_4_bn1_weight = p_features_extractor_6_4_bn1_bias = b_features_extractor_6_4_bn1_running_mean = b_features_extractor_6_4_bn1_running_var = None\n",
       "                    getitem_147: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_49[0];  _native_batch_norm_legit_no_training_49 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_46: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_147);  getitem_147 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_50: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_46, p_features_extractor_6_4_conv2_weight, None, [1, 1], [1, 1]);  relu_46 = p_features_extractor_6_4_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_50 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_50, p_features_extractor_6_4_bn2_weight, p_features_extractor_6_4_bn2_bias, b_features_extractor_6_4_bn2_running_mean, b_features_extractor_6_4_bn2_running_var, 0.1, 1e-05);  conv2d_50 = p_features_extractor_6_4_bn2_weight = p_features_extractor_6_4_bn2_bias = b_features_extractor_6_4_bn2_running_mean = b_features_extractor_6_4_bn2_running_var = None\n",
       "                    getitem_150: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_50[0];  _native_batch_norm_legit_no_training_50 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_47: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_150);  getitem_150 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_51: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_47, p_features_extractor_6_4_conv3_weight);  relu_47 = p_features_extractor_6_4_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_51, p_features_extractor_6_4_bn3_weight, p_features_extractor_6_4_bn3_bias, b_features_extractor_6_4_bn3_running_mean, b_features_extractor_6_4_bn3_running_var, 0.1, 1e-05);  conv2d_51 = p_features_extractor_6_4_bn3_weight = p_features_extractor_6_4_bn3_bias = b_features_extractor_6_4_bn3_running_mean = b_features_extractor_6_4_bn3_running_var = None\n",
       "                    getitem_153: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_51[0];  _native_batch_norm_legit_no_training_51 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_895: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_153, relu_45);  getitem_153 = relu_45 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_48: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_895);  add_895 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_52: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_48, p_features_extractor_6_5_conv1_weight);  p_features_extractor_6_5_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_52 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_52, p_features_extractor_6_5_bn1_weight, p_features_extractor_6_5_bn1_bias, b_features_extractor_6_5_bn1_running_mean, b_features_extractor_6_5_bn1_running_var, 0.1, 1e-05);  conv2d_52 = p_features_extractor_6_5_bn1_weight = p_features_extractor_6_5_bn1_bias = b_features_extractor_6_5_bn1_running_mean = b_features_extractor_6_5_bn1_running_var = None\n",
       "                    getitem_156: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_52[0];  _native_batch_norm_legit_no_training_52 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_49: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_156);  getitem_156 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_53: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_49, p_features_extractor_6_5_conv2_weight, None, [1, 1], [1, 1]);  relu_49 = p_features_extractor_6_5_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_53 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_53, p_features_extractor_6_5_bn2_weight, p_features_extractor_6_5_bn2_bias, b_features_extractor_6_5_bn2_running_mean, b_features_extractor_6_5_bn2_running_var, 0.1, 1e-05);  conv2d_53 = p_features_extractor_6_5_bn2_weight = p_features_extractor_6_5_bn2_bias = b_features_extractor_6_5_bn2_running_mean = b_features_extractor_6_5_bn2_running_var = None\n",
       "                    getitem_159: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_53[0];  _native_batch_norm_legit_no_training_53 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_50: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_159);  getitem_159 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_54: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_50, p_features_extractor_6_5_conv3_weight);  relu_50 = p_features_extractor_6_5_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_54 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_54, p_features_extractor_6_5_bn3_weight, p_features_extractor_6_5_bn3_bias, b_features_extractor_6_5_bn3_running_mean, b_features_extractor_6_5_bn3_running_var, 0.1, 1e-05);  conv2d_54 = p_features_extractor_6_5_bn3_weight = p_features_extractor_6_5_bn3_bias = b_features_extractor_6_5_bn3_running_mean = b_features_extractor_6_5_bn3_running_var = None\n",
       "                    getitem_162: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_54[0];  _native_batch_norm_legit_no_training_54 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_896: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_162, relu_48);  getitem_162 = relu_48 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_51: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_896);  add_896 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_55: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_51, p_features_extractor_6_6_conv1_weight);  p_features_extractor_6_6_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_55 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_55, p_features_extractor_6_6_bn1_weight, p_features_extractor_6_6_bn1_bias, b_features_extractor_6_6_bn1_running_mean, b_features_extractor_6_6_bn1_running_var, 0.1, 1e-05);  conv2d_55 = p_features_extractor_6_6_bn1_weight = p_features_extractor_6_6_bn1_bias = b_features_extractor_6_6_bn1_running_mean = b_features_extractor_6_6_bn1_running_var = None\n",
       "                    getitem_165: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_55[0];  _native_batch_norm_legit_no_training_55 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_52: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_165);  getitem_165 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_56: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_52, p_features_extractor_6_6_conv2_weight, None, [1, 1], [1, 1]);  relu_52 = p_features_extractor_6_6_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_56 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_56, p_features_extractor_6_6_bn2_weight, p_features_extractor_6_6_bn2_bias, b_features_extractor_6_6_bn2_running_mean, b_features_extractor_6_6_bn2_running_var, 0.1, 1e-05);  conv2d_56 = p_features_extractor_6_6_bn2_weight = p_features_extractor_6_6_bn2_bias = b_features_extractor_6_6_bn2_running_mean = b_features_extractor_6_6_bn2_running_var = None\n",
       "                    getitem_168: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_56[0];  _native_batch_norm_legit_no_training_56 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_53: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_168);  getitem_168 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_57: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_53, p_features_extractor_6_6_conv3_weight);  relu_53 = p_features_extractor_6_6_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_57 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_57, p_features_extractor_6_6_bn3_weight, p_features_extractor_6_6_bn3_bias, b_features_extractor_6_6_bn3_running_mean, b_features_extractor_6_6_bn3_running_var, 0.1, 1e-05);  conv2d_57 = p_features_extractor_6_6_bn3_weight = p_features_extractor_6_6_bn3_bias = b_features_extractor_6_6_bn3_running_mean = b_features_extractor_6_6_bn3_running_var = None\n",
       "                    getitem_171: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_57[0];  _native_batch_norm_legit_no_training_57 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_897: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_171, relu_51);  getitem_171 = relu_51 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_54: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_897);  add_897 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_58: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_54, p_features_extractor_6_7_conv1_weight);  p_features_extractor_6_7_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_58 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_58, p_features_extractor_6_7_bn1_weight, p_features_extractor_6_7_bn1_bias, b_features_extractor_6_7_bn1_running_mean, b_features_extractor_6_7_bn1_running_var, 0.1, 1e-05);  conv2d_58 = p_features_extractor_6_7_bn1_weight = p_features_extractor_6_7_bn1_bias = b_features_extractor_6_7_bn1_running_mean = b_features_extractor_6_7_bn1_running_var = None\n",
       "                    getitem_174: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_58[0];  _native_batch_norm_legit_no_training_58 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_55: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_174);  getitem_174 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_59: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_55, p_features_extractor_6_7_conv2_weight, None, [1, 1], [1, 1]);  relu_55 = p_features_extractor_6_7_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_59 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_59, p_features_extractor_6_7_bn2_weight, p_features_extractor_6_7_bn2_bias, b_features_extractor_6_7_bn2_running_mean, b_features_extractor_6_7_bn2_running_var, 0.1, 1e-05);  conv2d_59 = p_features_extractor_6_7_bn2_weight = p_features_extractor_6_7_bn2_bias = b_features_extractor_6_7_bn2_running_mean = b_features_extractor_6_7_bn2_running_var = None\n",
       "                    getitem_177: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_59[0];  _native_batch_norm_legit_no_training_59 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_56: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_177);  getitem_177 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_60: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_56, p_features_extractor_6_7_conv3_weight);  relu_56 = p_features_extractor_6_7_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_60 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_60, p_features_extractor_6_7_bn3_weight, p_features_extractor_6_7_bn3_bias, b_features_extractor_6_7_bn3_running_mean, b_features_extractor_6_7_bn3_running_var, 0.1, 1e-05);  conv2d_60 = p_features_extractor_6_7_bn3_weight = p_features_extractor_6_7_bn3_bias = b_features_extractor_6_7_bn3_running_mean = b_features_extractor_6_7_bn3_running_var = None\n",
       "                    getitem_180: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_60[0];  _native_batch_norm_legit_no_training_60 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_898: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_180, relu_54);  getitem_180 = relu_54 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_57: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_898);  add_898 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_61: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_57, p_features_extractor_6_8_conv1_weight);  p_features_extractor_6_8_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_61 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_61, p_features_extractor_6_8_bn1_weight, p_features_extractor_6_8_bn1_bias, b_features_extractor_6_8_bn1_running_mean, b_features_extractor_6_8_bn1_running_var, 0.1, 1e-05);  conv2d_61 = p_features_extractor_6_8_bn1_weight = p_features_extractor_6_8_bn1_bias = b_features_extractor_6_8_bn1_running_mean = b_features_extractor_6_8_bn1_running_var = None\n",
       "                    getitem_183: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_61[0];  _native_batch_norm_legit_no_training_61 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_58: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_183);  getitem_183 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_62: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_58, p_features_extractor_6_8_conv2_weight, None, [1, 1], [1, 1]);  relu_58 = p_features_extractor_6_8_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_62 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_62, p_features_extractor_6_8_bn2_weight, p_features_extractor_6_8_bn2_bias, b_features_extractor_6_8_bn2_running_mean, b_features_extractor_6_8_bn2_running_var, 0.1, 1e-05);  conv2d_62 = p_features_extractor_6_8_bn2_weight = p_features_extractor_6_8_bn2_bias = b_features_extractor_6_8_bn2_running_mean = b_features_extractor_6_8_bn2_running_var = None\n",
       "                    getitem_186: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_62[0];  _native_batch_norm_legit_no_training_62 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_59: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_186);  getitem_186 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_63: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_59, p_features_extractor_6_8_conv3_weight);  relu_59 = p_features_extractor_6_8_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_63 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_63, p_features_extractor_6_8_bn3_weight, p_features_extractor_6_8_bn3_bias, b_features_extractor_6_8_bn3_running_mean, b_features_extractor_6_8_bn3_running_var, 0.1, 1e-05);  conv2d_63 = p_features_extractor_6_8_bn3_weight = p_features_extractor_6_8_bn3_bias = b_features_extractor_6_8_bn3_running_mean = b_features_extractor_6_8_bn3_running_var = None\n",
       "                    getitem_189: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_63[0];  _native_batch_norm_legit_no_training_63 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_899: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_189, relu_57);  getitem_189 = relu_57 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_60: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_899);  add_899 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_64: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_60, p_features_extractor_6_9_conv1_weight);  p_features_extractor_6_9_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_64 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_64, p_features_extractor_6_9_bn1_weight, p_features_extractor_6_9_bn1_bias, b_features_extractor_6_9_bn1_running_mean, b_features_extractor_6_9_bn1_running_var, 0.1, 1e-05);  conv2d_64 = p_features_extractor_6_9_bn1_weight = p_features_extractor_6_9_bn1_bias = b_features_extractor_6_9_bn1_running_mean = b_features_extractor_6_9_bn1_running_var = None\n",
       "                    getitem_192: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_64[0];  _native_batch_norm_legit_no_training_64 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_61: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_192);  getitem_192 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_65: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_61, p_features_extractor_6_9_conv2_weight, None, [1, 1], [1, 1]);  relu_61 = p_features_extractor_6_9_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_65 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_65, p_features_extractor_6_9_bn2_weight, p_features_extractor_6_9_bn2_bias, b_features_extractor_6_9_bn2_running_mean, b_features_extractor_6_9_bn2_running_var, 0.1, 1e-05);  conv2d_65 = p_features_extractor_6_9_bn2_weight = p_features_extractor_6_9_bn2_bias = b_features_extractor_6_9_bn2_running_mean = b_features_extractor_6_9_bn2_running_var = None\n",
       "                    getitem_195: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_65[0];  _native_batch_norm_legit_no_training_65 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_62: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_195);  getitem_195 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_66: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_62, p_features_extractor_6_9_conv3_weight);  relu_62 = p_features_extractor_6_9_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_66 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_66, p_features_extractor_6_9_bn3_weight, p_features_extractor_6_9_bn3_bias, b_features_extractor_6_9_bn3_running_mean, b_features_extractor_6_9_bn3_running_var, 0.1, 1e-05);  conv2d_66 = p_features_extractor_6_9_bn3_weight = p_features_extractor_6_9_bn3_bias = b_features_extractor_6_9_bn3_running_mean = b_features_extractor_6_9_bn3_running_var = None\n",
       "                    getitem_198: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_66[0];  _native_batch_norm_legit_no_training_66 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_900: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_198, relu_60);  getitem_198 = relu_60 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_63: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_900);  add_900 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_67: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_63, p_features_extractor_6_10_conv1_weight);  p_features_extractor_6_10_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_67 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_67, p_features_extractor_6_10_bn1_weight, p_features_extractor_6_10_bn1_bias, b_features_extractor_6_10_bn1_running_mean, b_features_extractor_6_10_bn1_running_var, 0.1, 1e-05);  conv2d_67 = p_features_extractor_6_10_bn1_weight = p_features_extractor_6_10_bn1_bias = b_features_extractor_6_10_bn1_running_mean = b_features_extractor_6_10_bn1_running_var = None\n",
       "                    getitem_201: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_67[0];  _native_batch_norm_legit_no_training_67 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_64: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_201);  getitem_201 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_68: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_64, p_features_extractor_6_10_conv2_weight, None, [1, 1], [1, 1]);  relu_64 = p_features_extractor_6_10_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_68 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_68, p_features_extractor_6_10_bn2_weight, p_features_extractor_6_10_bn2_bias, b_features_extractor_6_10_bn2_running_mean, b_features_extractor_6_10_bn2_running_var, 0.1, 1e-05);  conv2d_68 = p_features_extractor_6_10_bn2_weight = p_features_extractor_6_10_bn2_bias = b_features_extractor_6_10_bn2_running_mean = b_features_extractor_6_10_bn2_running_var = None\n",
       "                    getitem_204: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_68[0];  _native_batch_norm_legit_no_training_68 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_65: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_204);  getitem_204 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_69: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_65, p_features_extractor_6_10_conv3_weight);  relu_65 = p_features_extractor_6_10_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_69 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_69, p_features_extractor_6_10_bn3_weight, p_features_extractor_6_10_bn3_bias, b_features_extractor_6_10_bn3_running_mean, b_features_extractor_6_10_bn3_running_var, 0.1, 1e-05);  conv2d_69 = p_features_extractor_6_10_bn3_weight = p_features_extractor_6_10_bn3_bias = b_features_extractor_6_10_bn3_running_mean = b_features_extractor_6_10_bn3_running_var = None\n",
       "                    getitem_207: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_69[0];  _native_batch_norm_legit_no_training_69 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_901: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_207, relu_63);  getitem_207 = relu_63 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_66: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_901);  add_901 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_70: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_66, p_features_extractor_6_11_conv1_weight);  p_features_extractor_6_11_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_70 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_70, p_features_extractor_6_11_bn1_weight, p_features_extractor_6_11_bn1_bias, b_features_extractor_6_11_bn1_running_mean, b_features_extractor_6_11_bn1_running_var, 0.1, 1e-05);  conv2d_70 = p_features_extractor_6_11_bn1_weight = p_features_extractor_6_11_bn1_bias = b_features_extractor_6_11_bn1_running_mean = b_features_extractor_6_11_bn1_running_var = None\n",
       "                    getitem_210: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_70[0];  _native_batch_norm_legit_no_training_70 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_67: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_210);  getitem_210 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_71: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_67, p_features_extractor_6_11_conv2_weight, None, [1, 1], [1, 1]);  relu_67 = p_features_extractor_6_11_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_71 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_71, p_features_extractor_6_11_bn2_weight, p_features_extractor_6_11_bn2_bias, b_features_extractor_6_11_bn2_running_mean, b_features_extractor_6_11_bn2_running_var, 0.1, 1e-05);  conv2d_71 = p_features_extractor_6_11_bn2_weight = p_features_extractor_6_11_bn2_bias = b_features_extractor_6_11_bn2_running_mean = b_features_extractor_6_11_bn2_running_var = None\n",
       "                    getitem_213: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_71[0];  _native_batch_norm_legit_no_training_71 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_68: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_213);  getitem_213 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_72: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_68, p_features_extractor_6_11_conv3_weight);  relu_68 = p_features_extractor_6_11_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_72 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_72, p_features_extractor_6_11_bn3_weight, p_features_extractor_6_11_bn3_bias, b_features_extractor_6_11_bn3_running_mean, b_features_extractor_6_11_bn3_running_var, 0.1, 1e-05);  conv2d_72 = p_features_extractor_6_11_bn3_weight = p_features_extractor_6_11_bn3_bias = b_features_extractor_6_11_bn3_running_mean = b_features_extractor_6_11_bn3_running_var = None\n",
       "                    getitem_216: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_72[0];  _native_batch_norm_legit_no_training_72 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_902: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_216, relu_66);  getitem_216 = relu_66 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_69: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_902);  add_902 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_73: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_69, p_features_extractor_6_12_conv1_weight);  p_features_extractor_6_12_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_73 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_73, p_features_extractor_6_12_bn1_weight, p_features_extractor_6_12_bn1_bias, b_features_extractor_6_12_bn1_running_mean, b_features_extractor_6_12_bn1_running_var, 0.1, 1e-05);  conv2d_73 = p_features_extractor_6_12_bn1_weight = p_features_extractor_6_12_bn1_bias = b_features_extractor_6_12_bn1_running_mean = b_features_extractor_6_12_bn1_running_var = None\n",
       "                    getitem_219: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_73[0];  _native_batch_norm_legit_no_training_73 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_70: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_219);  getitem_219 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_74: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_70, p_features_extractor_6_12_conv2_weight, None, [1, 1], [1, 1]);  relu_70 = p_features_extractor_6_12_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_74 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_74, p_features_extractor_6_12_bn2_weight, p_features_extractor_6_12_bn2_bias, b_features_extractor_6_12_bn2_running_mean, b_features_extractor_6_12_bn2_running_var, 0.1, 1e-05);  conv2d_74 = p_features_extractor_6_12_bn2_weight = p_features_extractor_6_12_bn2_bias = b_features_extractor_6_12_bn2_running_mean = b_features_extractor_6_12_bn2_running_var = None\n",
       "                    getitem_222: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_74[0];  _native_batch_norm_legit_no_training_74 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_71: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_222);  getitem_222 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_75: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_71, p_features_extractor_6_12_conv3_weight);  relu_71 = p_features_extractor_6_12_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_75 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_75, p_features_extractor_6_12_bn3_weight, p_features_extractor_6_12_bn3_bias, b_features_extractor_6_12_bn3_running_mean, b_features_extractor_6_12_bn3_running_var, 0.1, 1e-05);  conv2d_75 = p_features_extractor_6_12_bn3_weight = p_features_extractor_6_12_bn3_bias = b_features_extractor_6_12_bn3_running_mean = b_features_extractor_6_12_bn3_running_var = None\n",
       "                    getitem_225: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_75[0];  _native_batch_norm_legit_no_training_75 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_903: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_225, relu_69);  getitem_225 = relu_69 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_72: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_903);  add_903 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_76: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_72, p_features_extractor_6_13_conv1_weight);  p_features_extractor_6_13_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_76 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_76, p_features_extractor_6_13_bn1_weight, p_features_extractor_6_13_bn1_bias, b_features_extractor_6_13_bn1_running_mean, b_features_extractor_6_13_bn1_running_var, 0.1, 1e-05);  conv2d_76 = p_features_extractor_6_13_bn1_weight = p_features_extractor_6_13_bn1_bias = b_features_extractor_6_13_bn1_running_mean = b_features_extractor_6_13_bn1_running_var = None\n",
       "                    getitem_228: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_76[0];  _native_batch_norm_legit_no_training_76 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_73: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_228);  getitem_228 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_77: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_73, p_features_extractor_6_13_conv2_weight, None, [1, 1], [1, 1]);  relu_73 = p_features_extractor_6_13_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_77 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_77, p_features_extractor_6_13_bn2_weight, p_features_extractor_6_13_bn2_bias, b_features_extractor_6_13_bn2_running_mean, b_features_extractor_6_13_bn2_running_var, 0.1, 1e-05);  conv2d_77 = p_features_extractor_6_13_bn2_weight = p_features_extractor_6_13_bn2_bias = b_features_extractor_6_13_bn2_running_mean = b_features_extractor_6_13_bn2_running_var = None\n",
       "                    getitem_231: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_77[0];  _native_batch_norm_legit_no_training_77 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_74: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_231);  getitem_231 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_78: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_74, p_features_extractor_6_13_conv3_weight);  relu_74 = p_features_extractor_6_13_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_78 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_78, p_features_extractor_6_13_bn3_weight, p_features_extractor_6_13_bn3_bias, b_features_extractor_6_13_bn3_running_mean, b_features_extractor_6_13_bn3_running_var, 0.1, 1e-05);  conv2d_78 = p_features_extractor_6_13_bn3_weight = p_features_extractor_6_13_bn3_bias = b_features_extractor_6_13_bn3_running_mean = b_features_extractor_6_13_bn3_running_var = None\n",
       "                    getitem_234: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_78[0];  _native_batch_norm_legit_no_training_78 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_904: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_234, relu_72);  getitem_234 = relu_72 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_75: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_904);  add_904 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_79: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_75, p_features_extractor_6_14_conv1_weight);  p_features_extractor_6_14_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_79 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_79, p_features_extractor_6_14_bn1_weight, p_features_extractor_6_14_bn1_bias, b_features_extractor_6_14_bn1_running_mean, b_features_extractor_6_14_bn1_running_var, 0.1, 1e-05);  conv2d_79 = p_features_extractor_6_14_bn1_weight = p_features_extractor_6_14_bn1_bias = b_features_extractor_6_14_bn1_running_mean = b_features_extractor_6_14_bn1_running_var = None\n",
       "                    getitem_237: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_79[0];  _native_batch_norm_legit_no_training_79 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_76: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_237);  getitem_237 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_80: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_76, p_features_extractor_6_14_conv2_weight, None, [1, 1], [1, 1]);  relu_76 = p_features_extractor_6_14_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_80 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_80, p_features_extractor_6_14_bn2_weight, p_features_extractor_6_14_bn2_bias, b_features_extractor_6_14_bn2_running_mean, b_features_extractor_6_14_bn2_running_var, 0.1, 1e-05);  conv2d_80 = p_features_extractor_6_14_bn2_weight = p_features_extractor_6_14_bn2_bias = b_features_extractor_6_14_bn2_running_mean = b_features_extractor_6_14_bn2_running_var = None\n",
       "                    getitem_240: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_80[0];  _native_batch_norm_legit_no_training_80 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_77: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_240);  getitem_240 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_81: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_77, p_features_extractor_6_14_conv3_weight);  relu_77 = p_features_extractor_6_14_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_81 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_81, p_features_extractor_6_14_bn3_weight, p_features_extractor_6_14_bn3_bias, b_features_extractor_6_14_bn3_running_mean, b_features_extractor_6_14_bn3_running_var, 0.1, 1e-05);  conv2d_81 = p_features_extractor_6_14_bn3_weight = p_features_extractor_6_14_bn3_bias = b_features_extractor_6_14_bn3_running_mean = b_features_extractor_6_14_bn3_running_var = None\n",
       "                    getitem_243: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_81[0];  _native_batch_norm_legit_no_training_81 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_905: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_243, relu_75);  getitem_243 = relu_75 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_78: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_905);  add_905 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_82: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_78, p_features_extractor_6_15_conv1_weight);  p_features_extractor_6_15_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_82 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_82, p_features_extractor_6_15_bn1_weight, p_features_extractor_6_15_bn1_bias, b_features_extractor_6_15_bn1_running_mean, b_features_extractor_6_15_bn1_running_var, 0.1, 1e-05);  conv2d_82 = p_features_extractor_6_15_bn1_weight = p_features_extractor_6_15_bn1_bias = b_features_extractor_6_15_bn1_running_mean = b_features_extractor_6_15_bn1_running_var = None\n",
       "                    getitem_246: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_82[0];  _native_batch_norm_legit_no_training_82 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_79: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_246);  getitem_246 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_83: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_79, p_features_extractor_6_15_conv2_weight, None, [1, 1], [1, 1]);  relu_79 = p_features_extractor_6_15_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_83 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_83, p_features_extractor_6_15_bn2_weight, p_features_extractor_6_15_bn2_bias, b_features_extractor_6_15_bn2_running_mean, b_features_extractor_6_15_bn2_running_var, 0.1, 1e-05);  conv2d_83 = p_features_extractor_6_15_bn2_weight = p_features_extractor_6_15_bn2_bias = b_features_extractor_6_15_bn2_running_mean = b_features_extractor_6_15_bn2_running_var = None\n",
       "                    getitem_249: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_83[0];  _native_batch_norm_legit_no_training_83 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_80: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_249);  getitem_249 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_84: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_80, p_features_extractor_6_15_conv3_weight);  relu_80 = p_features_extractor_6_15_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_84 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_84, p_features_extractor_6_15_bn3_weight, p_features_extractor_6_15_bn3_bias, b_features_extractor_6_15_bn3_running_mean, b_features_extractor_6_15_bn3_running_var, 0.1, 1e-05);  conv2d_84 = p_features_extractor_6_15_bn3_weight = p_features_extractor_6_15_bn3_bias = b_features_extractor_6_15_bn3_running_mean = b_features_extractor_6_15_bn3_running_var = None\n",
       "                    getitem_252: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_84[0];  _native_batch_norm_legit_no_training_84 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_906: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_252, relu_78);  getitem_252 = relu_78 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_81: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_906);  add_906 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_85: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_81, p_features_extractor_6_16_conv1_weight);  p_features_extractor_6_16_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_85 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_85, p_features_extractor_6_16_bn1_weight, p_features_extractor_6_16_bn1_bias, b_features_extractor_6_16_bn1_running_mean, b_features_extractor_6_16_bn1_running_var, 0.1, 1e-05);  conv2d_85 = p_features_extractor_6_16_bn1_weight = p_features_extractor_6_16_bn1_bias = b_features_extractor_6_16_bn1_running_mean = b_features_extractor_6_16_bn1_running_var = None\n",
       "                    getitem_255: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_85[0];  _native_batch_norm_legit_no_training_85 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_82: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_255);  getitem_255 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_86: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_82, p_features_extractor_6_16_conv2_weight, None, [1, 1], [1, 1]);  relu_82 = p_features_extractor_6_16_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_86 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_86, p_features_extractor_6_16_bn2_weight, p_features_extractor_6_16_bn2_bias, b_features_extractor_6_16_bn2_running_mean, b_features_extractor_6_16_bn2_running_var, 0.1, 1e-05);  conv2d_86 = p_features_extractor_6_16_bn2_weight = p_features_extractor_6_16_bn2_bias = b_features_extractor_6_16_bn2_running_mean = b_features_extractor_6_16_bn2_running_var = None\n",
       "                    getitem_258: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_86[0];  _native_batch_norm_legit_no_training_86 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_83: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_258);  getitem_258 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_87: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_83, p_features_extractor_6_16_conv3_weight);  relu_83 = p_features_extractor_6_16_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_87 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_87, p_features_extractor_6_16_bn3_weight, p_features_extractor_6_16_bn3_bias, b_features_extractor_6_16_bn3_running_mean, b_features_extractor_6_16_bn3_running_var, 0.1, 1e-05);  conv2d_87 = p_features_extractor_6_16_bn3_weight = p_features_extractor_6_16_bn3_bias = b_features_extractor_6_16_bn3_running_mean = b_features_extractor_6_16_bn3_running_var = None\n",
       "                    getitem_261: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_87[0];  _native_batch_norm_legit_no_training_87 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_907: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_261, relu_81);  getitem_261 = relu_81 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_84: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_907);  add_907 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_88: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_84, p_features_extractor_6_17_conv1_weight);  p_features_extractor_6_17_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_88 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_88, p_features_extractor_6_17_bn1_weight, p_features_extractor_6_17_bn1_bias, b_features_extractor_6_17_bn1_running_mean, b_features_extractor_6_17_bn1_running_var, 0.1, 1e-05);  conv2d_88 = p_features_extractor_6_17_bn1_weight = p_features_extractor_6_17_bn1_bias = b_features_extractor_6_17_bn1_running_mean = b_features_extractor_6_17_bn1_running_var = None\n",
       "                    getitem_264: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_88[0];  _native_batch_norm_legit_no_training_88 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_85: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_264);  getitem_264 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_89: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_85, p_features_extractor_6_17_conv2_weight, None, [1, 1], [1, 1]);  relu_85 = p_features_extractor_6_17_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_89 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_89, p_features_extractor_6_17_bn2_weight, p_features_extractor_6_17_bn2_bias, b_features_extractor_6_17_bn2_running_mean, b_features_extractor_6_17_bn2_running_var, 0.1, 1e-05);  conv2d_89 = p_features_extractor_6_17_bn2_weight = p_features_extractor_6_17_bn2_bias = b_features_extractor_6_17_bn2_running_mean = b_features_extractor_6_17_bn2_running_var = None\n",
       "                    getitem_267: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_89[0];  _native_batch_norm_legit_no_training_89 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_86: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_267);  getitem_267 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_90: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_86, p_features_extractor_6_17_conv3_weight);  relu_86 = p_features_extractor_6_17_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_90 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_90, p_features_extractor_6_17_bn3_weight, p_features_extractor_6_17_bn3_bias, b_features_extractor_6_17_bn3_running_mean, b_features_extractor_6_17_bn3_running_var, 0.1, 1e-05);  conv2d_90 = p_features_extractor_6_17_bn3_weight = p_features_extractor_6_17_bn3_bias = b_features_extractor_6_17_bn3_running_mean = b_features_extractor_6_17_bn3_running_var = None\n",
       "                    getitem_270: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_90[0];  _native_batch_norm_legit_no_training_90 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_908: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_270, relu_84);  getitem_270 = relu_84 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_87: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_908);  add_908 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_91: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_87, p_features_extractor_6_18_conv1_weight);  p_features_extractor_6_18_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_91 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_91, p_features_extractor_6_18_bn1_weight, p_features_extractor_6_18_bn1_bias, b_features_extractor_6_18_bn1_running_mean, b_features_extractor_6_18_bn1_running_var, 0.1, 1e-05);  conv2d_91 = p_features_extractor_6_18_bn1_weight = p_features_extractor_6_18_bn1_bias = b_features_extractor_6_18_bn1_running_mean = b_features_extractor_6_18_bn1_running_var = None\n",
       "                    getitem_273: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_91[0];  _native_batch_norm_legit_no_training_91 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_88: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_273);  getitem_273 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_92: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_88, p_features_extractor_6_18_conv2_weight, None, [1, 1], [1, 1]);  relu_88 = p_features_extractor_6_18_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_92 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_92, p_features_extractor_6_18_bn2_weight, p_features_extractor_6_18_bn2_bias, b_features_extractor_6_18_bn2_running_mean, b_features_extractor_6_18_bn2_running_var, 0.1, 1e-05);  conv2d_92 = p_features_extractor_6_18_bn2_weight = p_features_extractor_6_18_bn2_bias = b_features_extractor_6_18_bn2_running_mean = b_features_extractor_6_18_bn2_running_var = None\n",
       "                    getitem_276: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_92[0];  _native_batch_norm_legit_no_training_92 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_89: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_276);  getitem_276 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_93: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_89, p_features_extractor_6_18_conv3_weight);  relu_89 = p_features_extractor_6_18_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_93 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_93, p_features_extractor_6_18_bn3_weight, p_features_extractor_6_18_bn3_bias, b_features_extractor_6_18_bn3_running_mean, b_features_extractor_6_18_bn3_running_var, 0.1, 1e-05);  conv2d_93 = p_features_extractor_6_18_bn3_weight = p_features_extractor_6_18_bn3_bias = b_features_extractor_6_18_bn3_running_mean = b_features_extractor_6_18_bn3_running_var = None\n",
       "                    getitem_279: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_93[0];  _native_batch_norm_legit_no_training_93 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_909: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_279, relu_87);  getitem_279 = relu_87 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_90: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_909);  add_909 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_94: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_90, p_features_extractor_6_19_conv1_weight);  p_features_extractor_6_19_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_94 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_94, p_features_extractor_6_19_bn1_weight, p_features_extractor_6_19_bn1_bias, b_features_extractor_6_19_bn1_running_mean, b_features_extractor_6_19_bn1_running_var, 0.1, 1e-05);  conv2d_94 = p_features_extractor_6_19_bn1_weight = p_features_extractor_6_19_bn1_bias = b_features_extractor_6_19_bn1_running_mean = b_features_extractor_6_19_bn1_running_var = None\n",
       "                    getitem_282: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_94[0];  _native_batch_norm_legit_no_training_94 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_91: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_282);  getitem_282 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_95: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_91, p_features_extractor_6_19_conv2_weight, None, [1, 1], [1, 1]);  relu_91 = p_features_extractor_6_19_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_95 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_95, p_features_extractor_6_19_bn2_weight, p_features_extractor_6_19_bn2_bias, b_features_extractor_6_19_bn2_running_mean, b_features_extractor_6_19_bn2_running_var, 0.1, 1e-05);  conv2d_95 = p_features_extractor_6_19_bn2_weight = p_features_extractor_6_19_bn2_bias = b_features_extractor_6_19_bn2_running_mean = b_features_extractor_6_19_bn2_running_var = None\n",
       "                    getitem_285: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_95[0];  _native_batch_norm_legit_no_training_95 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_92: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_285);  getitem_285 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_96: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_92, p_features_extractor_6_19_conv3_weight);  relu_92 = p_features_extractor_6_19_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_96 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_96, p_features_extractor_6_19_bn3_weight, p_features_extractor_6_19_bn3_bias, b_features_extractor_6_19_bn3_running_mean, b_features_extractor_6_19_bn3_running_var, 0.1, 1e-05);  conv2d_96 = p_features_extractor_6_19_bn3_weight = p_features_extractor_6_19_bn3_bias = b_features_extractor_6_19_bn3_running_mean = b_features_extractor_6_19_bn3_running_var = None\n",
       "                    getitem_288: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_96[0];  _native_batch_norm_legit_no_training_96 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_910: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_288, relu_90);  getitem_288 = relu_90 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_93: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_910);  add_910 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_97: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_93, p_features_extractor_6_20_conv1_weight);  p_features_extractor_6_20_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_97 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_97, p_features_extractor_6_20_bn1_weight, p_features_extractor_6_20_bn1_bias, b_features_extractor_6_20_bn1_running_mean, b_features_extractor_6_20_bn1_running_var, 0.1, 1e-05);  conv2d_97 = p_features_extractor_6_20_bn1_weight = p_features_extractor_6_20_bn1_bias = b_features_extractor_6_20_bn1_running_mean = b_features_extractor_6_20_bn1_running_var = None\n",
       "                    getitem_291: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_97[0];  _native_batch_norm_legit_no_training_97 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_94: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_291);  getitem_291 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_98: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_94, p_features_extractor_6_20_conv2_weight, None, [1, 1], [1, 1]);  relu_94 = p_features_extractor_6_20_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_98 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_98, p_features_extractor_6_20_bn2_weight, p_features_extractor_6_20_bn2_bias, b_features_extractor_6_20_bn2_running_mean, b_features_extractor_6_20_bn2_running_var, 0.1, 1e-05);  conv2d_98 = p_features_extractor_6_20_bn2_weight = p_features_extractor_6_20_bn2_bias = b_features_extractor_6_20_bn2_running_mean = b_features_extractor_6_20_bn2_running_var = None\n",
       "                    getitem_294: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_98[0];  _native_batch_norm_legit_no_training_98 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_95: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_294);  getitem_294 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_99: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_95, p_features_extractor_6_20_conv3_weight);  relu_95 = p_features_extractor_6_20_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_99 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_99, p_features_extractor_6_20_bn3_weight, p_features_extractor_6_20_bn3_bias, b_features_extractor_6_20_bn3_running_mean, b_features_extractor_6_20_bn3_running_var, 0.1, 1e-05);  conv2d_99 = p_features_extractor_6_20_bn3_weight = p_features_extractor_6_20_bn3_bias = b_features_extractor_6_20_bn3_running_mean = b_features_extractor_6_20_bn3_running_var = None\n",
       "                    getitem_297: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_99[0];  _native_batch_norm_legit_no_training_99 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_911: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_297, relu_93);  getitem_297 = relu_93 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_96: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_911);  add_911 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_100: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_96, p_features_extractor_6_21_conv1_weight);  p_features_extractor_6_21_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_100 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_100, p_features_extractor_6_21_bn1_weight, p_features_extractor_6_21_bn1_bias, b_features_extractor_6_21_bn1_running_mean, b_features_extractor_6_21_bn1_running_var, 0.1, 1e-05);  conv2d_100 = p_features_extractor_6_21_bn1_weight = p_features_extractor_6_21_bn1_bias = b_features_extractor_6_21_bn1_running_mean = b_features_extractor_6_21_bn1_running_var = None\n",
       "                    getitem_300: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_100[0];  _native_batch_norm_legit_no_training_100 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_97: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_300);  getitem_300 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_101: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_97, p_features_extractor_6_21_conv2_weight, None, [1, 1], [1, 1]);  relu_97 = p_features_extractor_6_21_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_101 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_101, p_features_extractor_6_21_bn2_weight, p_features_extractor_6_21_bn2_bias, b_features_extractor_6_21_bn2_running_mean, b_features_extractor_6_21_bn2_running_var, 0.1, 1e-05);  conv2d_101 = p_features_extractor_6_21_bn2_weight = p_features_extractor_6_21_bn2_bias = b_features_extractor_6_21_bn2_running_mean = b_features_extractor_6_21_bn2_running_var = None\n",
       "                    getitem_303: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_101[0];  _native_batch_norm_legit_no_training_101 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_98: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_303);  getitem_303 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_102: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_98, p_features_extractor_6_21_conv3_weight);  relu_98 = p_features_extractor_6_21_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_102 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_102, p_features_extractor_6_21_bn3_weight, p_features_extractor_6_21_bn3_bias, b_features_extractor_6_21_bn3_running_mean, b_features_extractor_6_21_bn3_running_var, 0.1, 1e-05);  conv2d_102 = p_features_extractor_6_21_bn3_weight = p_features_extractor_6_21_bn3_bias = b_features_extractor_6_21_bn3_running_mean = b_features_extractor_6_21_bn3_running_var = None\n",
       "                    getitem_306: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_102[0];  _native_batch_norm_legit_no_training_102 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_912: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_306, relu_96);  getitem_306 = relu_96 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_99: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_912);  add_912 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_103: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_99, p_features_extractor_6_22_conv1_weight);  p_features_extractor_6_22_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_103 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_103, p_features_extractor_6_22_bn1_weight, p_features_extractor_6_22_bn1_bias, b_features_extractor_6_22_bn1_running_mean, b_features_extractor_6_22_bn1_running_var, 0.1, 1e-05);  conv2d_103 = p_features_extractor_6_22_bn1_weight = p_features_extractor_6_22_bn1_bias = b_features_extractor_6_22_bn1_running_mean = b_features_extractor_6_22_bn1_running_var = None\n",
       "                    getitem_309: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_103[0];  _native_batch_norm_legit_no_training_103 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_100: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_309);  getitem_309 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_104: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_100, p_features_extractor_6_22_conv2_weight, None, [1, 1], [1, 1]);  relu_100 = p_features_extractor_6_22_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_104 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_104, p_features_extractor_6_22_bn2_weight, p_features_extractor_6_22_bn2_bias, b_features_extractor_6_22_bn2_running_mean, b_features_extractor_6_22_bn2_running_var, 0.1, 1e-05);  conv2d_104 = p_features_extractor_6_22_bn2_weight = p_features_extractor_6_22_bn2_bias = b_features_extractor_6_22_bn2_running_mean = b_features_extractor_6_22_bn2_running_var = None\n",
       "                    getitem_312: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_104[0];  _native_batch_norm_legit_no_training_104 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_101: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_312);  getitem_312 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_105: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_101, p_features_extractor_6_22_conv3_weight);  relu_101 = p_features_extractor_6_22_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_105 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_105, p_features_extractor_6_22_bn3_weight, p_features_extractor_6_22_bn3_bias, b_features_extractor_6_22_bn3_running_mean, b_features_extractor_6_22_bn3_running_var, 0.1, 1e-05);  conv2d_105 = p_features_extractor_6_22_bn3_weight = p_features_extractor_6_22_bn3_bias = b_features_extractor_6_22_bn3_running_mean = b_features_extractor_6_22_bn3_running_var = None\n",
       "                    getitem_315: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_105[0];  _native_batch_norm_legit_no_training_105 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_913: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_315, relu_99);  getitem_315 = relu_99 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_102: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_913);  add_913 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_106: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_102, p_features_extractor_6_23_conv1_weight);  p_features_extractor_6_23_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_106 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_106, p_features_extractor_6_23_bn1_weight, p_features_extractor_6_23_bn1_bias, b_features_extractor_6_23_bn1_running_mean, b_features_extractor_6_23_bn1_running_var, 0.1, 1e-05);  conv2d_106 = p_features_extractor_6_23_bn1_weight = p_features_extractor_6_23_bn1_bias = b_features_extractor_6_23_bn1_running_mean = b_features_extractor_6_23_bn1_running_var = None\n",
       "                    getitem_318: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_106[0];  _native_batch_norm_legit_no_training_106 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_103: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_318);  getitem_318 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_107: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_103, p_features_extractor_6_23_conv2_weight, None, [1, 1], [1, 1]);  relu_103 = p_features_extractor_6_23_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_107 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_107, p_features_extractor_6_23_bn2_weight, p_features_extractor_6_23_bn2_bias, b_features_extractor_6_23_bn2_running_mean, b_features_extractor_6_23_bn2_running_var, 0.1, 1e-05);  conv2d_107 = p_features_extractor_6_23_bn2_weight = p_features_extractor_6_23_bn2_bias = b_features_extractor_6_23_bn2_running_mean = b_features_extractor_6_23_bn2_running_var = None\n",
       "                    getitem_321: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_107[0];  _native_batch_norm_legit_no_training_107 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_104: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_321);  getitem_321 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_108: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_104, p_features_extractor_6_23_conv3_weight);  relu_104 = p_features_extractor_6_23_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_108 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_108, p_features_extractor_6_23_bn3_weight, p_features_extractor_6_23_bn3_bias, b_features_extractor_6_23_bn3_running_mean, b_features_extractor_6_23_bn3_running_var, 0.1, 1e-05);  conv2d_108 = p_features_extractor_6_23_bn3_weight = p_features_extractor_6_23_bn3_bias = b_features_extractor_6_23_bn3_running_mean = b_features_extractor_6_23_bn3_running_var = None\n",
       "                    getitem_324: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_108[0];  _native_batch_norm_legit_no_training_108 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_914: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_324, relu_102);  getitem_324 = relu_102 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_105: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_914);  add_914 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_109: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_105, p_features_extractor_6_24_conv1_weight);  p_features_extractor_6_24_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_109 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_109, p_features_extractor_6_24_bn1_weight, p_features_extractor_6_24_bn1_bias, b_features_extractor_6_24_bn1_running_mean, b_features_extractor_6_24_bn1_running_var, 0.1, 1e-05);  conv2d_109 = p_features_extractor_6_24_bn1_weight = p_features_extractor_6_24_bn1_bias = b_features_extractor_6_24_bn1_running_mean = b_features_extractor_6_24_bn1_running_var = None\n",
       "                    getitem_327: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_109[0];  _native_batch_norm_legit_no_training_109 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_106: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_327);  getitem_327 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_110: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_106, p_features_extractor_6_24_conv2_weight, None, [1, 1], [1, 1]);  relu_106 = p_features_extractor_6_24_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_110 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_110, p_features_extractor_6_24_bn2_weight, p_features_extractor_6_24_bn2_bias, b_features_extractor_6_24_bn2_running_mean, b_features_extractor_6_24_bn2_running_var, 0.1, 1e-05);  conv2d_110 = p_features_extractor_6_24_bn2_weight = p_features_extractor_6_24_bn2_bias = b_features_extractor_6_24_bn2_running_mean = b_features_extractor_6_24_bn2_running_var = None\n",
       "                    getitem_330: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_110[0];  _native_batch_norm_legit_no_training_110 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_107: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_330);  getitem_330 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_111: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_107, p_features_extractor_6_24_conv3_weight);  relu_107 = p_features_extractor_6_24_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_111 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_111, p_features_extractor_6_24_bn3_weight, p_features_extractor_6_24_bn3_bias, b_features_extractor_6_24_bn3_running_mean, b_features_extractor_6_24_bn3_running_var, 0.1, 1e-05);  conv2d_111 = p_features_extractor_6_24_bn3_weight = p_features_extractor_6_24_bn3_bias = b_features_extractor_6_24_bn3_running_mean = b_features_extractor_6_24_bn3_running_var = None\n",
       "                    getitem_333: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_111[0];  _native_batch_norm_legit_no_training_111 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_915: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_333, relu_105);  getitem_333 = relu_105 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_108: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_915);  add_915 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_112: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_108, p_features_extractor_6_25_conv1_weight);  p_features_extractor_6_25_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_112 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_112, p_features_extractor_6_25_bn1_weight, p_features_extractor_6_25_bn1_bias, b_features_extractor_6_25_bn1_running_mean, b_features_extractor_6_25_bn1_running_var, 0.1, 1e-05);  conv2d_112 = p_features_extractor_6_25_bn1_weight = p_features_extractor_6_25_bn1_bias = b_features_extractor_6_25_bn1_running_mean = b_features_extractor_6_25_bn1_running_var = None\n",
       "                    getitem_336: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_112[0];  _native_batch_norm_legit_no_training_112 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_109: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_336);  getitem_336 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_113: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_109, p_features_extractor_6_25_conv2_weight, None, [1, 1], [1, 1]);  relu_109 = p_features_extractor_6_25_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_113 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_113, p_features_extractor_6_25_bn2_weight, p_features_extractor_6_25_bn2_bias, b_features_extractor_6_25_bn2_running_mean, b_features_extractor_6_25_bn2_running_var, 0.1, 1e-05);  conv2d_113 = p_features_extractor_6_25_bn2_weight = p_features_extractor_6_25_bn2_bias = b_features_extractor_6_25_bn2_running_mean = b_features_extractor_6_25_bn2_running_var = None\n",
       "                    getitem_339: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_113[0];  _native_batch_norm_legit_no_training_113 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_110: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_339);  getitem_339 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_114: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_110, p_features_extractor_6_25_conv3_weight);  relu_110 = p_features_extractor_6_25_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_114 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_114, p_features_extractor_6_25_bn3_weight, p_features_extractor_6_25_bn3_bias, b_features_extractor_6_25_bn3_running_mean, b_features_extractor_6_25_bn3_running_var, 0.1, 1e-05);  conv2d_114 = p_features_extractor_6_25_bn3_weight = p_features_extractor_6_25_bn3_bias = b_features_extractor_6_25_bn3_running_mean = b_features_extractor_6_25_bn3_running_var = None\n",
       "                    getitem_342: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_114[0];  _native_batch_norm_legit_no_training_114 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_916: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_342, relu_108);  getitem_342 = relu_108 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_111: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_916);  add_916 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_115: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_111, p_features_extractor_6_26_conv1_weight);  p_features_extractor_6_26_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_115 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_115, p_features_extractor_6_26_bn1_weight, p_features_extractor_6_26_bn1_bias, b_features_extractor_6_26_bn1_running_mean, b_features_extractor_6_26_bn1_running_var, 0.1, 1e-05);  conv2d_115 = p_features_extractor_6_26_bn1_weight = p_features_extractor_6_26_bn1_bias = b_features_extractor_6_26_bn1_running_mean = b_features_extractor_6_26_bn1_running_var = None\n",
       "                    getitem_345: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_115[0];  _native_batch_norm_legit_no_training_115 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_112: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_345);  getitem_345 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_116: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_112, p_features_extractor_6_26_conv2_weight, None, [1, 1], [1, 1]);  relu_112 = p_features_extractor_6_26_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_116 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_116, p_features_extractor_6_26_bn2_weight, p_features_extractor_6_26_bn2_bias, b_features_extractor_6_26_bn2_running_mean, b_features_extractor_6_26_bn2_running_var, 0.1, 1e-05);  conv2d_116 = p_features_extractor_6_26_bn2_weight = p_features_extractor_6_26_bn2_bias = b_features_extractor_6_26_bn2_running_mean = b_features_extractor_6_26_bn2_running_var = None\n",
       "                    getitem_348: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_116[0];  _native_batch_norm_legit_no_training_116 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_113: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_348);  getitem_348 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_117: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_113, p_features_extractor_6_26_conv3_weight);  relu_113 = p_features_extractor_6_26_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_117 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_117, p_features_extractor_6_26_bn3_weight, p_features_extractor_6_26_bn3_bias, b_features_extractor_6_26_bn3_running_mean, b_features_extractor_6_26_bn3_running_var, 0.1, 1e-05);  conv2d_117 = p_features_extractor_6_26_bn3_weight = p_features_extractor_6_26_bn3_bias = b_features_extractor_6_26_bn3_running_mean = b_features_extractor_6_26_bn3_running_var = None\n",
       "                    getitem_351: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_117[0];  _native_batch_norm_legit_no_training_117 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_917: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_351, relu_111);  getitem_351 = relu_111 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_114: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_917);  add_917 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_118: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_114, p_features_extractor_6_27_conv1_weight);  p_features_extractor_6_27_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_118 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_118, p_features_extractor_6_27_bn1_weight, p_features_extractor_6_27_bn1_bias, b_features_extractor_6_27_bn1_running_mean, b_features_extractor_6_27_bn1_running_var, 0.1, 1e-05);  conv2d_118 = p_features_extractor_6_27_bn1_weight = p_features_extractor_6_27_bn1_bias = b_features_extractor_6_27_bn1_running_mean = b_features_extractor_6_27_bn1_running_var = None\n",
       "                    getitem_354: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_118[0];  _native_batch_norm_legit_no_training_118 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_115: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_354);  getitem_354 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_119: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_115, p_features_extractor_6_27_conv2_weight, None, [1, 1], [1, 1]);  relu_115 = p_features_extractor_6_27_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_119 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_119, p_features_extractor_6_27_bn2_weight, p_features_extractor_6_27_bn2_bias, b_features_extractor_6_27_bn2_running_mean, b_features_extractor_6_27_bn2_running_var, 0.1, 1e-05);  conv2d_119 = p_features_extractor_6_27_bn2_weight = p_features_extractor_6_27_bn2_bias = b_features_extractor_6_27_bn2_running_mean = b_features_extractor_6_27_bn2_running_var = None\n",
       "                    getitem_357: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_119[0];  _native_batch_norm_legit_no_training_119 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_116: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_357);  getitem_357 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_120: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_116, p_features_extractor_6_27_conv3_weight);  relu_116 = p_features_extractor_6_27_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_120 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_120, p_features_extractor_6_27_bn3_weight, p_features_extractor_6_27_bn3_bias, b_features_extractor_6_27_bn3_running_mean, b_features_extractor_6_27_bn3_running_var, 0.1, 1e-05);  conv2d_120 = p_features_extractor_6_27_bn3_weight = p_features_extractor_6_27_bn3_bias = b_features_extractor_6_27_bn3_running_mean = b_features_extractor_6_27_bn3_running_var = None\n",
       "                    getitem_360: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_120[0];  _native_batch_norm_legit_no_training_120 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_918: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_360, relu_114);  getitem_360 = relu_114 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_117: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_918);  add_918 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_121: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_117, p_features_extractor_6_28_conv1_weight);  p_features_extractor_6_28_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_121 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_121, p_features_extractor_6_28_bn1_weight, p_features_extractor_6_28_bn1_bias, b_features_extractor_6_28_bn1_running_mean, b_features_extractor_6_28_bn1_running_var, 0.1, 1e-05);  conv2d_121 = p_features_extractor_6_28_bn1_weight = p_features_extractor_6_28_bn1_bias = b_features_extractor_6_28_bn1_running_mean = b_features_extractor_6_28_bn1_running_var = None\n",
       "                    getitem_363: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_121[0];  _native_batch_norm_legit_no_training_121 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_118: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_363);  getitem_363 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_122: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_118, p_features_extractor_6_28_conv2_weight, None, [1, 1], [1, 1]);  relu_118 = p_features_extractor_6_28_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_122 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_122, p_features_extractor_6_28_bn2_weight, p_features_extractor_6_28_bn2_bias, b_features_extractor_6_28_bn2_running_mean, b_features_extractor_6_28_bn2_running_var, 0.1, 1e-05);  conv2d_122 = p_features_extractor_6_28_bn2_weight = p_features_extractor_6_28_bn2_bias = b_features_extractor_6_28_bn2_running_mean = b_features_extractor_6_28_bn2_running_var = None\n",
       "                    getitem_366: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_122[0];  _native_batch_norm_legit_no_training_122 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_119: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_366);  getitem_366 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_123: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_119, p_features_extractor_6_28_conv3_weight);  relu_119 = p_features_extractor_6_28_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_123 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_123, p_features_extractor_6_28_bn3_weight, p_features_extractor_6_28_bn3_bias, b_features_extractor_6_28_bn3_running_mean, b_features_extractor_6_28_bn3_running_var, 0.1, 1e-05);  conv2d_123 = p_features_extractor_6_28_bn3_weight = p_features_extractor_6_28_bn3_bias = b_features_extractor_6_28_bn3_running_mean = b_features_extractor_6_28_bn3_running_var = None\n",
       "                    getitem_369: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_123[0];  _native_batch_norm_legit_no_training_123 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_919: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_369, relu_117);  getitem_369 = relu_117 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_120: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_919);  add_919 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_124: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_120, p_features_extractor_6_29_conv1_weight);  p_features_extractor_6_29_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_124 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_124, p_features_extractor_6_29_bn1_weight, p_features_extractor_6_29_bn1_bias, b_features_extractor_6_29_bn1_running_mean, b_features_extractor_6_29_bn1_running_var, 0.1, 1e-05);  conv2d_124 = p_features_extractor_6_29_bn1_weight = p_features_extractor_6_29_bn1_bias = b_features_extractor_6_29_bn1_running_mean = b_features_extractor_6_29_bn1_running_var = None\n",
       "                    getitem_372: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_124[0];  _native_batch_norm_legit_no_training_124 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_121: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_372);  getitem_372 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_125: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_121, p_features_extractor_6_29_conv2_weight, None, [1, 1], [1, 1]);  relu_121 = p_features_extractor_6_29_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_125 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_125, p_features_extractor_6_29_bn2_weight, p_features_extractor_6_29_bn2_bias, b_features_extractor_6_29_bn2_running_mean, b_features_extractor_6_29_bn2_running_var, 0.1, 1e-05);  conv2d_125 = p_features_extractor_6_29_bn2_weight = p_features_extractor_6_29_bn2_bias = b_features_extractor_6_29_bn2_running_mean = b_features_extractor_6_29_bn2_running_var = None\n",
       "                    getitem_375: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_125[0];  _native_batch_norm_legit_no_training_125 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_122: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_375);  getitem_375 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_126: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_122, p_features_extractor_6_29_conv3_weight);  relu_122 = p_features_extractor_6_29_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_126 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_126, p_features_extractor_6_29_bn3_weight, p_features_extractor_6_29_bn3_bias, b_features_extractor_6_29_bn3_running_mean, b_features_extractor_6_29_bn3_running_var, 0.1, 1e-05);  conv2d_126 = p_features_extractor_6_29_bn3_weight = p_features_extractor_6_29_bn3_bias = b_features_extractor_6_29_bn3_running_mean = b_features_extractor_6_29_bn3_running_var = None\n",
       "                    getitem_378: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_126[0];  _native_batch_norm_legit_no_training_126 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_920: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_378, relu_120);  getitem_378 = relu_120 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_123: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_920);  add_920 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_127: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_123, p_features_extractor_6_30_conv1_weight);  p_features_extractor_6_30_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_127 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_127, p_features_extractor_6_30_bn1_weight, p_features_extractor_6_30_bn1_bias, b_features_extractor_6_30_bn1_running_mean, b_features_extractor_6_30_bn1_running_var, 0.1, 1e-05);  conv2d_127 = p_features_extractor_6_30_bn1_weight = p_features_extractor_6_30_bn1_bias = b_features_extractor_6_30_bn1_running_mean = b_features_extractor_6_30_bn1_running_var = None\n",
       "                    getitem_381: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_127[0];  _native_batch_norm_legit_no_training_127 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_124: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_381);  getitem_381 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_128: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_124, p_features_extractor_6_30_conv2_weight, None, [1, 1], [1, 1]);  relu_124 = p_features_extractor_6_30_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_128 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_128, p_features_extractor_6_30_bn2_weight, p_features_extractor_6_30_bn2_bias, b_features_extractor_6_30_bn2_running_mean, b_features_extractor_6_30_bn2_running_var, 0.1, 1e-05);  conv2d_128 = p_features_extractor_6_30_bn2_weight = p_features_extractor_6_30_bn2_bias = b_features_extractor_6_30_bn2_running_mean = b_features_extractor_6_30_bn2_running_var = None\n",
       "                    getitem_384: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_128[0];  _native_batch_norm_legit_no_training_128 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_125: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_384);  getitem_384 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_129: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_125, p_features_extractor_6_30_conv3_weight);  relu_125 = p_features_extractor_6_30_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_129 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_129, p_features_extractor_6_30_bn3_weight, p_features_extractor_6_30_bn3_bias, b_features_extractor_6_30_bn3_running_mean, b_features_extractor_6_30_bn3_running_var, 0.1, 1e-05);  conv2d_129 = p_features_extractor_6_30_bn3_weight = p_features_extractor_6_30_bn3_bias = b_features_extractor_6_30_bn3_running_mean = b_features_extractor_6_30_bn3_running_var = None\n",
       "                    getitem_387: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_129[0];  _native_batch_norm_legit_no_training_129 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_921: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_387, relu_123);  getitem_387 = relu_123 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_126: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_921);  add_921 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_130: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_126, p_features_extractor_6_31_conv1_weight);  p_features_extractor_6_31_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_130 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_130, p_features_extractor_6_31_bn1_weight, p_features_extractor_6_31_bn1_bias, b_features_extractor_6_31_bn1_running_mean, b_features_extractor_6_31_bn1_running_var, 0.1, 1e-05);  conv2d_130 = p_features_extractor_6_31_bn1_weight = p_features_extractor_6_31_bn1_bias = b_features_extractor_6_31_bn1_running_mean = b_features_extractor_6_31_bn1_running_var = None\n",
       "                    getitem_390: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_130[0];  _native_batch_norm_legit_no_training_130 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_127: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_390);  getitem_390 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_131: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_127, p_features_extractor_6_31_conv2_weight, None, [1, 1], [1, 1]);  relu_127 = p_features_extractor_6_31_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_131 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_131, p_features_extractor_6_31_bn2_weight, p_features_extractor_6_31_bn2_bias, b_features_extractor_6_31_bn2_running_mean, b_features_extractor_6_31_bn2_running_var, 0.1, 1e-05);  conv2d_131 = p_features_extractor_6_31_bn2_weight = p_features_extractor_6_31_bn2_bias = b_features_extractor_6_31_bn2_running_mean = b_features_extractor_6_31_bn2_running_var = None\n",
       "                    getitem_393: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_131[0];  _native_batch_norm_legit_no_training_131 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_128: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_393);  getitem_393 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_132: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_128, p_features_extractor_6_31_conv3_weight);  relu_128 = p_features_extractor_6_31_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_132 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_132, p_features_extractor_6_31_bn3_weight, p_features_extractor_6_31_bn3_bias, b_features_extractor_6_31_bn3_running_mean, b_features_extractor_6_31_bn3_running_var, 0.1, 1e-05);  conv2d_132 = p_features_extractor_6_31_bn3_weight = p_features_extractor_6_31_bn3_bias = b_features_extractor_6_31_bn3_running_mean = b_features_extractor_6_31_bn3_running_var = None\n",
       "                    getitem_396: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_132[0];  _native_batch_norm_legit_no_training_132 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_922: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_396, relu_126);  getitem_396 = relu_126 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_129: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_922);  add_922 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_133: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_129, p_features_extractor_6_32_conv1_weight);  p_features_extractor_6_32_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_133 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_133, p_features_extractor_6_32_bn1_weight, p_features_extractor_6_32_bn1_bias, b_features_extractor_6_32_bn1_running_mean, b_features_extractor_6_32_bn1_running_var, 0.1, 1e-05);  conv2d_133 = p_features_extractor_6_32_bn1_weight = p_features_extractor_6_32_bn1_bias = b_features_extractor_6_32_bn1_running_mean = b_features_extractor_6_32_bn1_running_var = None\n",
       "                    getitem_399: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_133[0];  _native_batch_norm_legit_no_training_133 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_130: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_399);  getitem_399 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_134: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_130, p_features_extractor_6_32_conv2_weight, None, [1, 1], [1, 1]);  relu_130 = p_features_extractor_6_32_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_134 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_134, p_features_extractor_6_32_bn2_weight, p_features_extractor_6_32_bn2_bias, b_features_extractor_6_32_bn2_running_mean, b_features_extractor_6_32_bn2_running_var, 0.1, 1e-05);  conv2d_134 = p_features_extractor_6_32_bn2_weight = p_features_extractor_6_32_bn2_bias = b_features_extractor_6_32_bn2_running_mean = b_features_extractor_6_32_bn2_running_var = None\n",
       "                    getitem_402: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_134[0];  _native_batch_norm_legit_no_training_134 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_131: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_402);  getitem_402 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_135: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_131, p_features_extractor_6_32_conv3_weight);  relu_131 = p_features_extractor_6_32_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_135 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_135, p_features_extractor_6_32_bn3_weight, p_features_extractor_6_32_bn3_bias, b_features_extractor_6_32_bn3_running_mean, b_features_extractor_6_32_bn3_running_var, 0.1, 1e-05);  conv2d_135 = p_features_extractor_6_32_bn3_weight = p_features_extractor_6_32_bn3_bias = b_features_extractor_6_32_bn3_running_mean = b_features_extractor_6_32_bn3_running_var = None\n",
       "                    getitem_405: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_135[0];  _native_batch_norm_legit_no_training_135 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_923: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_405, relu_129);  getitem_405 = relu_129 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_132: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_923);  add_923 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_136: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_132, p_features_extractor_6_33_conv1_weight);  p_features_extractor_6_33_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_136 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_136, p_features_extractor_6_33_bn1_weight, p_features_extractor_6_33_bn1_bias, b_features_extractor_6_33_bn1_running_mean, b_features_extractor_6_33_bn1_running_var, 0.1, 1e-05);  conv2d_136 = p_features_extractor_6_33_bn1_weight = p_features_extractor_6_33_bn1_bias = b_features_extractor_6_33_bn1_running_mean = b_features_extractor_6_33_bn1_running_var = None\n",
       "                    getitem_408: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_136[0];  _native_batch_norm_legit_no_training_136 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_133: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_408);  getitem_408 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_137: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_133, p_features_extractor_6_33_conv2_weight, None, [1, 1], [1, 1]);  relu_133 = p_features_extractor_6_33_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_137 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_137, p_features_extractor_6_33_bn2_weight, p_features_extractor_6_33_bn2_bias, b_features_extractor_6_33_bn2_running_mean, b_features_extractor_6_33_bn2_running_var, 0.1, 1e-05);  conv2d_137 = p_features_extractor_6_33_bn2_weight = p_features_extractor_6_33_bn2_bias = b_features_extractor_6_33_bn2_running_mean = b_features_extractor_6_33_bn2_running_var = None\n",
       "                    getitem_411: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_137[0];  _native_batch_norm_legit_no_training_137 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_134: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_411);  getitem_411 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_138: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_134, p_features_extractor_6_33_conv3_weight);  relu_134 = p_features_extractor_6_33_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_138 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_138, p_features_extractor_6_33_bn3_weight, p_features_extractor_6_33_bn3_bias, b_features_extractor_6_33_bn3_running_mean, b_features_extractor_6_33_bn3_running_var, 0.1, 1e-05);  conv2d_138 = p_features_extractor_6_33_bn3_weight = p_features_extractor_6_33_bn3_bias = b_features_extractor_6_33_bn3_running_mean = b_features_extractor_6_33_bn3_running_var = None\n",
       "                    getitem_414: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_138[0];  _native_batch_norm_legit_no_training_138 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_924: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_414, relu_132);  getitem_414 = relu_132 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_135: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_924);  add_924 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_139: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_135, p_features_extractor_6_34_conv1_weight);  p_features_extractor_6_34_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_139 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_139, p_features_extractor_6_34_bn1_weight, p_features_extractor_6_34_bn1_bias, b_features_extractor_6_34_bn1_running_mean, b_features_extractor_6_34_bn1_running_var, 0.1, 1e-05);  conv2d_139 = p_features_extractor_6_34_bn1_weight = p_features_extractor_6_34_bn1_bias = b_features_extractor_6_34_bn1_running_mean = b_features_extractor_6_34_bn1_running_var = None\n",
       "                    getitem_417: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_139[0];  _native_batch_norm_legit_no_training_139 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_136: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_417);  getitem_417 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_140: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_136, p_features_extractor_6_34_conv2_weight, None, [1, 1], [1, 1]);  relu_136 = p_features_extractor_6_34_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_140 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_140, p_features_extractor_6_34_bn2_weight, p_features_extractor_6_34_bn2_bias, b_features_extractor_6_34_bn2_running_mean, b_features_extractor_6_34_bn2_running_var, 0.1, 1e-05);  conv2d_140 = p_features_extractor_6_34_bn2_weight = p_features_extractor_6_34_bn2_bias = b_features_extractor_6_34_bn2_running_mean = b_features_extractor_6_34_bn2_running_var = None\n",
       "                    getitem_420: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_140[0];  _native_batch_norm_legit_no_training_140 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_137: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_420);  getitem_420 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_141: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_137, p_features_extractor_6_34_conv3_weight);  relu_137 = p_features_extractor_6_34_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_141 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_141, p_features_extractor_6_34_bn3_weight, p_features_extractor_6_34_bn3_bias, b_features_extractor_6_34_bn3_running_mean, b_features_extractor_6_34_bn3_running_var, 0.1, 1e-05);  conv2d_141 = p_features_extractor_6_34_bn3_weight = p_features_extractor_6_34_bn3_bias = b_features_extractor_6_34_bn3_running_mean = b_features_extractor_6_34_bn3_running_var = None\n",
       "                    getitem_423: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_141[0];  _native_batch_norm_legit_no_training_141 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_925: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_423, relu_135);  getitem_423 = relu_135 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_138: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_925);  add_925 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_142: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_138, p_features_extractor_6_35_conv1_weight);  p_features_extractor_6_35_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_142 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_142, p_features_extractor_6_35_bn1_weight, p_features_extractor_6_35_bn1_bias, b_features_extractor_6_35_bn1_running_mean, b_features_extractor_6_35_bn1_running_var, 0.1, 1e-05);  conv2d_142 = p_features_extractor_6_35_bn1_weight = p_features_extractor_6_35_bn1_bias = b_features_extractor_6_35_bn1_running_mean = b_features_extractor_6_35_bn1_running_var = None\n",
       "                    getitem_426: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_142[0];  _native_batch_norm_legit_no_training_142 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_139: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_426);  getitem_426 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_143: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(relu_139, p_features_extractor_6_35_conv2_weight, None, [1, 1], [1, 1]);  relu_139 = p_features_extractor_6_35_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_143 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_143, p_features_extractor_6_35_bn2_weight, p_features_extractor_6_35_bn2_bias, b_features_extractor_6_35_bn2_running_mean, b_features_extractor_6_35_bn2_running_var, 0.1, 1e-05);  conv2d_143 = p_features_extractor_6_35_bn2_weight = p_features_extractor_6_35_bn2_bias = b_features_extractor_6_35_bn2_running_mean = b_features_extractor_6_35_bn2_running_var = None\n",
       "                    getitem_429: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_143[0];  _native_batch_norm_legit_no_training_143 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_140: \"f32[1, 256, 14, 14]\" = torch.ops.aten.relu.default(getitem_429);  getitem_429 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_144: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.conv2d.default(relu_140, p_features_extractor_6_35_conv3_weight);  relu_140 = p_features_extractor_6_35_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_144 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_144, p_features_extractor_6_35_bn3_weight, p_features_extractor_6_35_bn3_bias, b_features_extractor_6_35_bn3_running_mean, b_features_extractor_6_35_bn3_running_var, 0.1, 1e-05);  conv2d_144 = p_features_extractor_6_35_bn3_weight = p_features_extractor_6_35_bn3_bias = b_features_extractor_6_35_bn3_running_mean = b_features_extractor_6_35_bn3_running_var = None\n",
       "                    getitem_432: \"f32[1, 1024, 14, 14]\" = _native_batch_norm_legit_no_training_144[0];  _native_batch_norm_legit_no_training_144 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_926: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_432, relu_138);  getitem_432 = relu_138 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_141: \"f32[1, 1024, 14, 14]\" = torch.ops.aten.relu.default(add_926);  add_926 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_145: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(relu_141, p_features_extractor_7_0_conv1_weight);  p_features_extractor_7_0_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_145 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_145, p_features_extractor_7_0_bn1_weight, p_features_extractor_7_0_bn1_bias, b_features_extractor_7_0_bn1_running_mean, b_features_extractor_7_0_bn1_running_var, 0.1, 1e-05);  conv2d_145 = p_features_extractor_7_0_bn1_weight = p_features_extractor_7_0_bn1_bias = b_features_extractor_7_0_bn1_running_mean = b_features_extractor_7_0_bn1_running_var = None\n",
       "                    getitem_435: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_145[0];  _native_batch_norm_legit_no_training_145 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_142: \"f32[1, 512, 14, 14]\" = torch.ops.aten.relu.default(getitem_435);  getitem_435 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_146: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_142, p_features_extractor_7_0_conv2_weight, None, [2, 2], [1, 1]);  relu_142 = p_features_extractor_7_0_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_146 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_146, p_features_extractor_7_0_bn2_weight, p_features_extractor_7_0_bn2_bias, b_features_extractor_7_0_bn2_running_mean, b_features_extractor_7_0_bn2_running_var, 0.1, 1e-05);  conv2d_146 = p_features_extractor_7_0_bn2_weight = p_features_extractor_7_0_bn2_bias = b_features_extractor_7_0_bn2_running_mean = b_features_extractor_7_0_bn2_running_var = None\n",
       "                    getitem_438: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_146[0];  _native_batch_norm_legit_no_training_146 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_143: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_438);  getitem_438 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_147: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_143, p_features_extractor_7_0_conv3_weight);  relu_143 = p_features_extractor_7_0_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_147 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_147, p_features_extractor_7_0_bn3_weight, p_features_extractor_7_0_bn3_bias, b_features_extractor_7_0_bn3_running_mean, b_features_extractor_7_0_bn3_running_var, 0.1, 1e-05);  conv2d_147 = p_features_extractor_7_0_bn3_weight = p_features_extractor_7_0_bn3_bias = b_features_extractor_7_0_bn3_running_mean = b_features_extractor_7_0_bn3_running_var = None\n",
       "                    getitem_441: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_147[0];  _native_batch_norm_legit_no_training_147 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_148: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_141, p_features_extractor_7_0_downsample_0_weight, None, [2, 2]);  relu_141 = p_features_extractor_7_0_downsample_0_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_148 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_148, p_features_extractor_7_0_downsample_1_weight, p_features_extractor_7_0_downsample_1_bias, b_features_extractor_7_0_downsample_1_running_mean, b_features_extractor_7_0_downsample_1_running_var, 0.1, 1e-05);  conv2d_148 = p_features_extractor_7_0_downsample_1_weight = p_features_extractor_7_0_downsample_1_bias = b_features_extractor_7_0_downsample_1_running_mean = b_features_extractor_7_0_downsample_1_running_var = None\n",
       "                    getitem_444: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_148[0];  _native_batch_norm_legit_no_training_148 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_927: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_441, getitem_444);  getitem_441 = getitem_444 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_144: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.relu.default(add_927);  add_927 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_149: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_144, p_features_extractor_7_1_conv1_weight);  p_features_extractor_7_1_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_149 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_149, p_features_extractor_7_1_bn1_weight, p_features_extractor_7_1_bn1_bias, b_features_extractor_7_1_bn1_running_mean, b_features_extractor_7_1_bn1_running_var, 0.1, 1e-05);  conv2d_149 = p_features_extractor_7_1_bn1_weight = p_features_extractor_7_1_bn1_bias = b_features_extractor_7_1_bn1_running_mean = b_features_extractor_7_1_bn1_running_var = None\n",
       "                    getitem_447: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_149[0];  _native_batch_norm_legit_no_training_149 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_145: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_447);  getitem_447 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_150: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_145, p_features_extractor_7_1_conv2_weight, None, [1, 1], [1, 1]);  relu_145 = p_features_extractor_7_1_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_150 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_150, p_features_extractor_7_1_bn2_weight, p_features_extractor_7_1_bn2_bias, b_features_extractor_7_1_bn2_running_mean, b_features_extractor_7_1_bn2_running_var, 0.1, 1e-05);  conv2d_150 = p_features_extractor_7_1_bn2_weight = p_features_extractor_7_1_bn2_bias = b_features_extractor_7_1_bn2_running_mean = b_features_extractor_7_1_bn2_running_var = None\n",
       "                    getitem_450: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_150[0];  _native_batch_norm_legit_no_training_150 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_146: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_450);  getitem_450 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_151: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_146, p_features_extractor_7_1_conv3_weight);  relu_146 = p_features_extractor_7_1_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_151 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_151, p_features_extractor_7_1_bn3_weight, p_features_extractor_7_1_bn3_bias, b_features_extractor_7_1_bn3_running_mean, b_features_extractor_7_1_bn3_running_var, 0.1, 1e-05);  conv2d_151 = p_features_extractor_7_1_bn3_weight = p_features_extractor_7_1_bn3_bias = b_features_extractor_7_1_bn3_running_mean = b_features_extractor_7_1_bn3_running_var = None\n",
       "                    getitem_453: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_151[0];  _native_batch_norm_legit_no_training_151 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_928: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_453, relu_144);  getitem_453 = relu_144 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_147: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.relu.default(add_928);  add_928 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_152: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_147, p_features_extractor_7_2_conv1_weight);  p_features_extractor_7_2_conv1_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_152 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_152, p_features_extractor_7_2_bn1_weight, p_features_extractor_7_2_bn1_bias, b_features_extractor_7_2_bn1_running_mean, b_features_extractor_7_2_bn1_running_var, 0.1, 1e-05);  conv2d_152 = p_features_extractor_7_2_bn1_weight = p_features_extractor_7_2_bn1_bias = b_features_extractor_7_2_bn1_running_mean = b_features_extractor_7_2_bn1_running_var = None\n",
       "                    getitem_456: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_152[0];  _native_batch_norm_legit_no_training_152 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_148: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_456);  getitem_456 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_153: \"f32[1, 512, 7, 7]\" = torch.ops.aten.conv2d.default(relu_148, p_features_extractor_7_2_conv2_weight, None, [1, 1], [1, 1]);  relu_148 = p_features_extractor_7_2_conv2_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_153 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_153, p_features_extractor_7_2_bn2_weight, p_features_extractor_7_2_bn2_bias, b_features_extractor_7_2_bn2_running_mean, b_features_extractor_7_2_bn2_running_var, 0.1, 1e-05);  conv2d_153 = p_features_extractor_7_2_bn2_weight = p_features_extractor_7_2_bn2_bias = b_features_extractor_7_2_bn2_running_mean = b_features_extractor_7_2_bn2_running_var = None\n",
       "                    getitem_459: \"f32[1, 512, 7, 7]\" = _native_batch_norm_legit_no_training_153[0];  _native_batch_norm_legit_no_training_153 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_149: \"f32[1, 512, 7, 7]\" = torch.ops.aten.relu.default(getitem_459);  getitem_459 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_154: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.conv2d.default(relu_149, p_features_extractor_7_2_conv3_weight);  relu_149 = p_features_extractor_7_2_conv3_weight = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_154 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_154, p_features_extractor_7_2_bn3_weight, p_features_extractor_7_2_bn3_bias, b_features_extractor_7_2_bn3_running_mean, b_features_extractor_7_2_bn3_running_var, 0.1, 1e-05);  conv2d_154 = p_features_extractor_7_2_bn3_weight = p_features_extractor_7_2_bn3_bias = b_features_extractor_7_2_bn3_running_mean = b_features_extractor_7_2_bn3_running_var = None\n",
       "                    getitem_462: \"f32[1, 2048, 7, 7]\" = _native_batch_norm_legit_no_training_154[0];  _native_batch_norm_legit_no_training_154 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torchvision\\models\\resnet.py:160 in forward, code: out += identity\n",
       "                    add_929: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_462, relu_147);  getitem_462 = relu_147 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:144 in forward, code: return F.relu(input, inplace=self.inplace)\n",
       "                    relu_150: \"f32[1, 2048, 7, 7]\" = torch.ops.aten.relu.default(add_929);  add_929 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean: \"f32[1, 2048, 1, 1]\" = torch.ops.aten.mean.dim(relu_150, [-1, -2], True);  relu_150 = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\AppData\\Local\\Temp\\ipykernel_21636\\374571119.py:47 in forward, code: x = torch.flatten(x, 1) # Flatten the (batch_size, 2048, 1, 1) to (batch_size, 2048)\n",
       "                    view: \"f32[1, 2048]\" = torch.ops.aten.view.default(mean, [1, 2048]);  mean = None\n",
       "            \n",
       "                     # File: C:\\Users\\sahas11\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 131]\" = torch.ops.aten.linear.default(view, p_output_layer_weight, p_output_layer_bias);  view = p_output_layer_weight = p_output_layer_bias = None\n",
       "                    return (linear,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_base_model_conv1_weight: PARAMETER target='base_model.conv1.weight'\n",
       "            p_base_model_bn1_weight: PARAMETER target='base_model.bn1.weight'\n",
       "            p_base_model_bn1_bias: PARAMETER target='base_model.bn1.bias'\n",
       "            p_base_model_layer1_0_conv1_weight: PARAMETER target='base_model.layer1.0.conv1.weight'\n",
       "            p_base_model_layer1_0_bn1_weight: PARAMETER target='base_model.layer1.0.bn1.weight'\n",
       "            p_base_model_layer1_0_bn1_bias: PARAMETER target='base_model.layer1.0.bn1.bias'\n",
       "            p_base_model_layer1_0_conv2_weight: PARAMETER target='base_model.layer1.0.conv2.weight'\n",
       "            p_base_model_layer1_0_bn2_weight: PARAMETER target='base_model.layer1.0.bn2.weight'\n",
       "            p_base_model_layer1_0_bn2_bias: PARAMETER target='base_model.layer1.0.bn2.bias'\n",
       "            p_base_model_layer1_0_conv3_weight: PARAMETER target='base_model.layer1.0.conv3.weight'\n",
       "            p_base_model_layer1_0_bn3_weight: PARAMETER target='base_model.layer1.0.bn3.weight'\n",
       "            p_base_model_layer1_0_bn3_bias: PARAMETER target='base_model.layer1.0.bn3.bias'\n",
       "            p_base_model_layer1_0_downsample_0_weight: PARAMETER target='base_model.layer1.0.downsample.0.weight'\n",
       "            p_base_model_layer1_0_downsample_1_weight: PARAMETER target='base_model.layer1.0.downsample.1.weight'\n",
       "            p_base_model_layer1_0_downsample_1_bias: PARAMETER target='base_model.layer1.0.downsample.1.bias'\n",
       "            p_base_model_layer1_1_conv1_weight: PARAMETER target='base_model.layer1.1.conv1.weight'\n",
       "            p_base_model_layer1_1_bn1_weight: PARAMETER target='base_model.layer1.1.bn1.weight'\n",
       "            p_base_model_layer1_1_bn1_bias: PARAMETER target='base_model.layer1.1.bn1.bias'\n",
       "            p_base_model_layer1_1_conv2_weight: PARAMETER target='base_model.layer1.1.conv2.weight'\n",
       "            p_base_model_layer1_1_bn2_weight: PARAMETER target='base_model.layer1.1.bn2.weight'\n",
       "            p_base_model_layer1_1_bn2_bias: PARAMETER target='base_model.layer1.1.bn2.bias'\n",
       "            p_base_model_layer1_1_conv3_weight: PARAMETER target='base_model.layer1.1.conv3.weight'\n",
       "            p_base_model_layer1_1_bn3_weight: PARAMETER target='base_model.layer1.1.bn3.weight'\n",
       "            p_base_model_layer1_1_bn3_bias: PARAMETER target='base_model.layer1.1.bn3.bias'\n",
       "            p_base_model_layer1_2_conv1_weight: PARAMETER target='base_model.layer1.2.conv1.weight'\n",
       "            p_base_model_layer1_2_bn1_weight: PARAMETER target='base_model.layer1.2.bn1.weight'\n",
       "            p_base_model_layer1_2_bn1_bias: PARAMETER target='base_model.layer1.2.bn1.bias'\n",
       "            p_base_model_layer1_2_conv2_weight: PARAMETER target='base_model.layer1.2.conv2.weight'\n",
       "            p_base_model_layer1_2_bn2_weight: PARAMETER target='base_model.layer1.2.bn2.weight'\n",
       "            p_base_model_layer1_2_bn2_bias: PARAMETER target='base_model.layer1.2.bn2.bias'\n",
       "            p_base_model_layer1_2_conv3_weight: PARAMETER target='base_model.layer1.2.conv3.weight'\n",
       "            p_base_model_layer1_2_bn3_weight: PARAMETER target='base_model.layer1.2.bn3.weight'\n",
       "            p_base_model_layer1_2_bn3_bias: PARAMETER target='base_model.layer1.2.bn3.bias'\n",
       "            p_base_model_layer2_0_conv1_weight: PARAMETER target='base_model.layer2.0.conv1.weight'\n",
       "            p_base_model_layer2_0_bn1_weight: PARAMETER target='base_model.layer2.0.bn1.weight'\n",
       "            p_base_model_layer2_0_bn1_bias: PARAMETER target='base_model.layer2.0.bn1.bias'\n",
       "            p_base_model_layer2_0_conv2_weight: PARAMETER target='base_model.layer2.0.conv2.weight'\n",
       "            p_base_model_layer2_0_bn2_weight: PARAMETER target='base_model.layer2.0.bn2.weight'\n",
       "            p_base_model_layer2_0_bn2_bias: PARAMETER target='base_model.layer2.0.bn2.bias'\n",
       "            p_base_model_layer2_0_conv3_weight: PARAMETER target='base_model.layer2.0.conv3.weight'\n",
       "            p_base_model_layer2_0_bn3_weight: PARAMETER target='base_model.layer2.0.bn3.weight'\n",
       "            p_base_model_layer2_0_bn3_bias: PARAMETER target='base_model.layer2.0.bn3.bias'\n",
       "            p_base_model_layer2_0_downsample_0_weight: PARAMETER target='base_model.layer2.0.downsample.0.weight'\n",
       "            p_base_model_layer2_0_downsample_1_weight: PARAMETER target='base_model.layer2.0.downsample.1.weight'\n",
       "            p_base_model_layer2_0_downsample_1_bias: PARAMETER target='base_model.layer2.0.downsample.1.bias'\n",
       "            p_base_model_layer2_1_conv1_weight: PARAMETER target='base_model.layer2.1.conv1.weight'\n",
       "            p_base_model_layer2_1_bn1_weight: PARAMETER target='base_model.layer2.1.bn1.weight'\n",
       "            p_base_model_layer2_1_bn1_bias: PARAMETER target='base_model.layer2.1.bn1.bias'\n",
       "            p_base_model_layer2_1_conv2_weight: PARAMETER target='base_model.layer2.1.conv2.weight'\n",
       "            p_base_model_layer2_1_bn2_weight: PARAMETER target='base_model.layer2.1.bn2.weight'\n",
       "            p_base_model_layer2_1_bn2_bias: PARAMETER target='base_model.layer2.1.bn2.bias'\n",
       "            p_base_model_layer2_1_conv3_weight: PARAMETER target='base_model.layer2.1.conv3.weight'\n",
       "            p_base_model_layer2_1_bn3_weight: PARAMETER target='base_model.layer2.1.bn3.weight'\n",
       "            p_base_model_layer2_1_bn3_bias: PARAMETER target='base_model.layer2.1.bn3.bias'\n",
       "            p_base_model_layer2_2_conv1_weight: PARAMETER target='base_model.layer2.2.conv1.weight'\n",
       "            p_base_model_layer2_2_bn1_weight: PARAMETER target='base_model.layer2.2.bn1.weight'\n",
       "            p_base_model_layer2_2_bn1_bias: PARAMETER target='base_model.layer2.2.bn1.bias'\n",
       "            p_base_model_layer2_2_conv2_weight: PARAMETER target='base_model.layer2.2.conv2.weight'\n",
       "            p_base_model_layer2_2_bn2_weight: PARAMETER target='base_model.layer2.2.bn2.weight'\n",
       "            p_base_model_layer2_2_bn2_bias: PARAMETER target='base_model.layer2.2.bn2.bias'\n",
       "            p_base_model_layer2_2_conv3_weight: PARAMETER target='base_model.layer2.2.conv3.weight'\n",
       "            p_base_model_layer2_2_bn3_weight: PARAMETER target='base_model.layer2.2.bn3.weight'\n",
       "            p_base_model_layer2_2_bn3_bias: PARAMETER target='base_model.layer2.2.bn3.bias'\n",
       "            p_base_model_layer2_3_conv1_weight: PARAMETER target='base_model.layer2.3.conv1.weight'\n",
       "            p_base_model_layer2_3_bn1_weight: PARAMETER target='base_model.layer2.3.bn1.weight'\n",
       "            p_base_model_layer2_3_bn1_bias: PARAMETER target='base_model.layer2.3.bn1.bias'\n",
       "            p_base_model_layer2_3_conv2_weight: PARAMETER target='base_model.layer2.3.conv2.weight'\n",
       "            p_base_model_layer2_3_bn2_weight: PARAMETER target='base_model.layer2.3.bn2.weight'\n",
       "            p_base_model_layer2_3_bn2_bias: PARAMETER target='base_model.layer2.3.bn2.bias'\n",
       "            p_base_model_layer2_3_conv3_weight: PARAMETER target='base_model.layer2.3.conv3.weight'\n",
       "            p_base_model_layer2_3_bn3_weight: PARAMETER target='base_model.layer2.3.bn3.weight'\n",
       "            p_base_model_layer2_3_bn3_bias: PARAMETER target='base_model.layer2.3.bn3.bias'\n",
       "            p_base_model_layer2_4_conv1_weight: PARAMETER target='base_model.layer2.4.conv1.weight'\n",
       "            p_base_model_layer2_4_bn1_weight: PARAMETER target='base_model.layer2.4.bn1.weight'\n",
       "            p_base_model_layer2_4_bn1_bias: PARAMETER target='base_model.layer2.4.bn1.bias'\n",
       "            p_base_model_layer2_4_conv2_weight: PARAMETER target='base_model.layer2.4.conv2.weight'\n",
       "            p_base_model_layer2_4_bn2_weight: PARAMETER target='base_model.layer2.4.bn2.weight'\n",
       "            p_base_model_layer2_4_bn2_bias: PARAMETER target='base_model.layer2.4.bn2.bias'\n",
       "            p_base_model_layer2_4_conv3_weight: PARAMETER target='base_model.layer2.4.conv3.weight'\n",
       "            p_base_model_layer2_4_bn3_weight: PARAMETER target='base_model.layer2.4.bn3.weight'\n",
       "            p_base_model_layer2_4_bn3_bias: PARAMETER target='base_model.layer2.4.bn3.bias'\n",
       "            p_base_model_layer2_5_conv1_weight: PARAMETER target='base_model.layer2.5.conv1.weight'\n",
       "            p_base_model_layer2_5_bn1_weight: PARAMETER target='base_model.layer2.5.bn1.weight'\n",
       "            p_base_model_layer2_5_bn1_bias: PARAMETER target='base_model.layer2.5.bn1.bias'\n",
       "            p_base_model_layer2_5_conv2_weight: PARAMETER target='base_model.layer2.5.conv2.weight'\n",
       "            p_base_model_layer2_5_bn2_weight: PARAMETER target='base_model.layer2.5.bn2.weight'\n",
       "            p_base_model_layer2_5_bn2_bias: PARAMETER target='base_model.layer2.5.bn2.bias'\n",
       "            p_base_model_layer2_5_conv3_weight: PARAMETER target='base_model.layer2.5.conv3.weight'\n",
       "            p_base_model_layer2_5_bn3_weight: PARAMETER target='base_model.layer2.5.bn3.weight'\n",
       "            p_base_model_layer2_5_bn3_bias: PARAMETER target='base_model.layer2.5.bn3.bias'\n",
       "            p_base_model_layer2_6_conv1_weight: PARAMETER target='base_model.layer2.6.conv1.weight'\n",
       "            p_base_model_layer2_6_bn1_weight: PARAMETER target='base_model.layer2.6.bn1.weight'\n",
       "            p_base_model_layer2_6_bn1_bias: PARAMETER target='base_model.layer2.6.bn1.bias'\n",
       "            p_base_model_layer2_6_conv2_weight: PARAMETER target='base_model.layer2.6.conv2.weight'\n",
       "            p_base_model_layer2_6_bn2_weight: PARAMETER target='base_model.layer2.6.bn2.weight'\n",
       "            p_base_model_layer2_6_bn2_bias: PARAMETER target='base_model.layer2.6.bn2.bias'\n",
       "            p_base_model_layer2_6_conv3_weight: PARAMETER target='base_model.layer2.6.conv3.weight'\n",
       "            p_base_model_layer2_6_bn3_weight: PARAMETER target='base_model.layer2.6.bn3.weight'\n",
       "            p_base_model_layer2_6_bn3_bias: PARAMETER target='base_model.layer2.6.bn3.bias'\n",
       "            p_base_model_layer2_7_conv1_weight: PARAMETER target='base_model.layer2.7.conv1.weight'\n",
       "            p_base_model_layer2_7_bn1_weight: PARAMETER target='base_model.layer2.7.bn1.weight'\n",
       "            p_base_model_layer2_7_bn1_bias: PARAMETER target='base_model.layer2.7.bn1.bias'\n",
       "            p_base_model_layer2_7_conv2_weight: PARAMETER target='base_model.layer2.7.conv2.weight'\n",
       "            p_base_model_layer2_7_bn2_weight: PARAMETER target='base_model.layer2.7.bn2.weight'\n",
       "            p_base_model_layer2_7_bn2_bias: PARAMETER target='base_model.layer2.7.bn2.bias'\n",
       "            p_base_model_layer2_7_conv3_weight: PARAMETER target='base_model.layer2.7.conv3.weight'\n",
       "            p_base_model_layer2_7_bn3_weight: PARAMETER target='base_model.layer2.7.bn3.weight'\n",
       "            p_base_model_layer2_7_bn3_bias: PARAMETER target='base_model.layer2.7.bn3.bias'\n",
       "            p_base_model_layer3_0_conv1_weight: PARAMETER target='base_model.layer3.0.conv1.weight'\n",
       "            p_base_model_layer3_0_bn1_weight: PARAMETER target='base_model.layer3.0.bn1.weight'\n",
       "            p_base_model_layer3_0_bn1_bias: PARAMETER target='base_model.layer3.0.bn1.bias'\n",
       "            p_base_model_layer3_0_conv2_weight: PARAMETER target='base_model.layer3.0.conv2.weight'\n",
       "            p_base_model_layer3_0_bn2_weight: PARAMETER target='base_model.layer3.0.bn2.weight'\n",
       "            p_base_model_layer3_0_bn2_bias: PARAMETER target='base_model.layer3.0.bn2.bias'\n",
       "            p_base_model_layer3_0_conv3_weight: PARAMETER target='base_model.layer3.0.conv3.weight'\n",
       "            p_base_model_layer3_0_bn3_weight: PARAMETER target='base_model.layer3.0.bn3.weight'\n",
       "            p_base_model_layer3_0_bn3_bias: PARAMETER target='base_model.layer3.0.bn3.bias'\n",
       "            p_base_model_layer3_0_downsample_0_weight: PARAMETER target='base_model.layer3.0.downsample.0.weight'\n",
       "            p_base_model_layer3_0_downsample_1_weight: PARAMETER target='base_model.layer3.0.downsample.1.weight'\n",
       "            p_base_model_layer3_0_downsample_1_bias: PARAMETER target='base_model.layer3.0.downsample.1.bias'\n",
       "            p_base_model_layer3_1_conv1_weight: PARAMETER target='base_model.layer3.1.conv1.weight'\n",
       "            p_base_model_layer3_1_bn1_weight: PARAMETER target='base_model.layer3.1.bn1.weight'\n",
       "            p_base_model_layer3_1_bn1_bias: PARAMETER target='base_model.layer3.1.bn1.bias'\n",
       "            p_base_model_layer3_1_conv2_weight: PARAMETER target='base_model.layer3.1.conv2.weight'\n",
       "            p_base_model_layer3_1_bn2_weight: PARAMETER target='base_model.layer3.1.bn2.weight'\n",
       "            p_base_model_layer3_1_bn2_bias: PARAMETER target='base_model.layer3.1.bn2.bias'\n",
       "            p_base_model_layer3_1_conv3_weight: PARAMETER target='base_model.layer3.1.conv3.weight'\n",
       "            p_base_model_layer3_1_bn3_weight: PARAMETER target='base_model.layer3.1.bn3.weight'\n",
       "            p_base_model_layer3_1_bn3_bias: PARAMETER target='base_model.layer3.1.bn3.bias'\n",
       "            p_base_model_layer3_2_conv1_weight: PARAMETER target='base_model.layer3.2.conv1.weight'\n",
       "            p_base_model_layer3_2_bn1_weight: PARAMETER target='base_model.layer3.2.bn1.weight'\n",
       "            p_base_model_layer3_2_bn1_bias: PARAMETER target='base_model.layer3.2.bn1.bias'\n",
       "            p_base_model_layer3_2_conv2_weight: PARAMETER target='base_model.layer3.2.conv2.weight'\n",
       "            p_base_model_layer3_2_bn2_weight: PARAMETER target='base_model.layer3.2.bn2.weight'\n",
       "            p_base_model_layer3_2_bn2_bias: PARAMETER target='base_model.layer3.2.bn2.bias'\n",
       "            p_base_model_layer3_2_conv3_weight: PARAMETER target='base_model.layer3.2.conv3.weight'\n",
       "            p_base_model_layer3_2_bn3_weight: PARAMETER target='base_model.layer3.2.bn3.weight'\n",
       "            p_base_model_layer3_2_bn3_bias: PARAMETER target='base_model.layer3.2.bn3.bias'\n",
       "            p_base_model_layer3_3_conv1_weight: PARAMETER target='base_model.layer3.3.conv1.weight'\n",
       "            p_base_model_layer3_3_bn1_weight: PARAMETER target='base_model.layer3.3.bn1.weight'\n",
       "            p_base_model_layer3_3_bn1_bias: PARAMETER target='base_model.layer3.3.bn1.bias'\n",
       "            p_base_model_layer3_3_conv2_weight: PARAMETER target='base_model.layer3.3.conv2.weight'\n",
       "            p_base_model_layer3_3_bn2_weight: PARAMETER target='base_model.layer3.3.bn2.weight'\n",
       "            p_base_model_layer3_3_bn2_bias: PARAMETER target='base_model.layer3.3.bn2.bias'\n",
       "            p_base_model_layer3_3_conv3_weight: PARAMETER target='base_model.layer3.3.conv3.weight'\n",
       "            p_base_model_layer3_3_bn3_weight: PARAMETER target='base_model.layer3.3.bn3.weight'\n",
       "            p_base_model_layer3_3_bn3_bias: PARAMETER target='base_model.layer3.3.bn3.bias'\n",
       "            p_base_model_layer3_4_conv1_weight: PARAMETER target='base_model.layer3.4.conv1.weight'\n",
       "            p_base_model_layer3_4_bn1_weight: PARAMETER target='base_model.layer3.4.bn1.weight'\n",
       "            p_base_model_layer3_4_bn1_bias: PARAMETER target='base_model.layer3.4.bn1.bias'\n",
       "            p_base_model_layer3_4_conv2_weight: PARAMETER target='base_model.layer3.4.conv2.weight'\n",
       "            p_base_model_layer3_4_bn2_weight: PARAMETER target='base_model.layer3.4.bn2.weight'\n",
       "            p_base_model_layer3_4_bn2_bias: PARAMETER target='base_model.layer3.4.bn2.bias'\n",
       "            p_base_model_layer3_4_conv3_weight: PARAMETER target='base_model.layer3.4.conv3.weight'\n",
       "            p_base_model_layer3_4_bn3_weight: PARAMETER target='base_model.layer3.4.bn3.weight'\n",
       "            p_base_model_layer3_4_bn3_bias: PARAMETER target='base_model.layer3.4.bn3.bias'\n",
       "            p_base_model_layer3_5_conv1_weight: PARAMETER target='base_model.layer3.5.conv1.weight'\n",
       "            p_base_model_layer3_5_bn1_weight: PARAMETER target='base_model.layer3.5.bn1.weight'\n",
       "            p_base_model_layer3_5_bn1_bias: PARAMETER target='base_model.layer3.5.bn1.bias'\n",
       "            p_base_model_layer3_5_conv2_weight: PARAMETER target='base_model.layer3.5.conv2.weight'\n",
       "            p_base_model_layer3_5_bn2_weight: PARAMETER target='base_model.layer3.5.bn2.weight'\n",
       "            p_base_model_layer3_5_bn2_bias: PARAMETER target='base_model.layer3.5.bn2.bias'\n",
       "            p_base_model_layer3_5_conv3_weight: PARAMETER target='base_model.layer3.5.conv3.weight'\n",
       "            p_base_model_layer3_5_bn3_weight: PARAMETER target='base_model.layer3.5.bn3.weight'\n",
       "            p_base_model_layer3_5_bn3_bias: PARAMETER target='base_model.layer3.5.bn3.bias'\n",
       "            p_base_model_layer3_6_conv1_weight: PARAMETER target='base_model.layer3.6.conv1.weight'\n",
       "            p_base_model_layer3_6_bn1_weight: PARAMETER target='base_model.layer3.6.bn1.weight'\n",
       "            p_base_model_layer3_6_bn1_bias: PARAMETER target='base_model.layer3.6.bn1.bias'\n",
       "            p_base_model_layer3_6_conv2_weight: PARAMETER target='base_model.layer3.6.conv2.weight'\n",
       "            p_base_model_layer3_6_bn2_weight: PARAMETER target='base_model.layer3.6.bn2.weight'\n",
       "            p_base_model_layer3_6_bn2_bias: PARAMETER target='base_model.layer3.6.bn2.bias'\n",
       "            p_base_model_layer3_6_conv3_weight: PARAMETER target='base_model.layer3.6.conv3.weight'\n",
       "            p_base_model_layer3_6_bn3_weight: PARAMETER target='base_model.layer3.6.bn3.weight'\n",
       "            p_base_model_layer3_6_bn3_bias: PARAMETER target='base_model.layer3.6.bn3.bias'\n",
       "            p_base_model_layer3_7_conv1_weight: PARAMETER target='base_model.layer3.7.conv1.weight'\n",
       "            p_base_model_layer3_7_bn1_weight: PARAMETER target='base_model.layer3.7.bn1.weight'\n",
       "            p_base_model_layer3_7_bn1_bias: PARAMETER target='base_model.layer3.7.bn1.bias'\n",
       "            p_base_model_layer3_7_conv2_weight: PARAMETER target='base_model.layer3.7.conv2.weight'\n",
       "            p_base_model_layer3_7_bn2_weight: PARAMETER target='base_model.layer3.7.bn2.weight'\n",
       "            p_base_model_layer3_7_bn2_bias: PARAMETER target='base_model.layer3.7.bn2.bias'\n",
       "            p_base_model_layer3_7_conv3_weight: PARAMETER target='base_model.layer3.7.conv3.weight'\n",
       "            p_base_model_layer3_7_bn3_weight: PARAMETER target='base_model.layer3.7.bn3.weight'\n",
       "            p_base_model_layer3_7_bn3_bias: PARAMETER target='base_model.layer3.7.bn3.bias'\n",
       "            p_base_model_layer3_8_conv1_weight: PARAMETER target='base_model.layer3.8.conv1.weight'\n",
       "            p_base_model_layer3_8_bn1_weight: PARAMETER target='base_model.layer3.8.bn1.weight'\n",
       "            p_base_model_layer3_8_bn1_bias: PARAMETER target='base_model.layer3.8.bn1.bias'\n",
       "            p_base_model_layer3_8_conv2_weight: PARAMETER target='base_model.layer3.8.conv2.weight'\n",
       "            p_base_model_layer3_8_bn2_weight: PARAMETER target='base_model.layer3.8.bn2.weight'\n",
       "            p_base_model_layer3_8_bn2_bias: PARAMETER target='base_model.layer3.8.bn2.bias'\n",
       "            p_base_model_layer3_8_conv3_weight: PARAMETER target='base_model.layer3.8.conv3.weight'\n",
       "            p_base_model_layer3_8_bn3_weight: PARAMETER target='base_model.layer3.8.bn3.weight'\n",
       "            p_base_model_layer3_8_bn3_bias: PARAMETER target='base_model.layer3.8.bn3.bias'\n",
       "            p_base_model_layer3_9_conv1_weight: PARAMETER target='base_model.layer3.9.conv1.weight'\n",
       "            p_base_model_layer3_9_bn1_weight: PARAMETER target='base_model.layer3.9.bn1.weight'\n",
       "            p_base_model_layer3_9_bn1_bias: PARAMETER target='base_model.layer3.9.bn1.bias'\n",
       "            p_base_model_layer3_9_conv2_weight: PARAMETER target='base_model.layer3.9.conv2.weight'\n",
       "            p_base_model_layer3_9_bn2_weight: PARAMETER target='base_model.layer3.9.bn2.weight'\n",
       "            p_base_model_layer3_9_bn2_bias: PARAMETER target='base_model.layer3.9.bn2.bias'\n",
       "            p_base_model_layer3_9_conv3_weight: PARAMETER target='base_model.layer3.9.conv3.weight'\n",
       "            p_base_model_layer3_9_bn3_weight: PARAMETER target='base_model.layer3.9.bn3.weight'\n",
       "            p_base_model_layer3_9_bn3_bias: PARAMETER target='base_model.layer3.9.bn3.bias'\n",
       "            p_base_model_layer3_10_conv1_weight: PARAMETER target='base_model.layer3.10.conv1.weight'\n",
       "            p_base_model_layer3_10_bn1_weight: PARAMETER target='base_model.layer3.10.bn1.weight'\n",
       "            p_base_model_layer3_10_bn1_bias: PARAMETER target='base_model.layer3.10.bn1.bias'\n",
       "            p_base_model_layer3_10_conv2_weight: PARAMETER target='base_model.layer3.10.conv2.weight'\n",
       "            p_base_model_layer3_10_bn2_weight: PARAMETER target='base_model.layer3.10.bn2.weight'\n",
       "            p_base_model_layer3_10_bn2_bias: PARAMETER target='base_model.layer3.10.bn2.bias'\n",
       "            p_base_model_layer3_10_conv3_weight: PARAMETER target='base_model.layer3.10.conv3.weight'\n",
       "            p_base_model_layer3_10_bn3_weight: PARAMETER target='base_model.layer3.10.bn3.weight'\n",
       "            p_base_model_layer3_10_bn3_bias: PARAMETER target='base_model.layer3.10.bn3.bias'\n",
       "            p_base_model_layer3_11_conv1_weight: PARAMETER target='base_model.layer3.11.conv1.weight'\n",
       "            p_base_model_layer3_11_bn1_weight: PARAMETER target='base_model.layer3.11.bn1.weight'\n",
       "            p_base_model_layer3_11_bn1_bias: PARAMETER target='base_model.layer3.11.bn1.bias'\n",
       "            p_base_model_layer3_11_conv2_weight: PARAMETER target='base_model.layer3.11.conv2.weight'\n",
       "            p_base_model_layer3_11_bn2_weight: PARAMETER target='base_model.layer3.11.bn2.weight'\n",
       "            p_base_model_layer3_11_bn2_bias: PARAMETER target='base_model.layer3.11.bn2.bias'\n",
       "            p_base_model_layer3_11_conv3_weight: PARAMETER target='base_model.layer3.11.conv3.weight'\n",
       "            p_base_model_layer3_11_bn3_weight: PARAMETER target='base_model.layer3.11.bn3.weight'\n",
       "            p_base_model_layer3_11_bn3_bias: PARAMETER target='base_model.layer3.11.bn3.bias'\n",
       "            p_base_model_layer3_12_conv1_weight: PARAMETER target='base_model.layer3.12.conv1.weight'\n",
       "            p_base_model_layer3_12_bn1_weight: PARAMETER target='base_model.layer3.12.bn1.weight'\n",
       "            p_base_model_layer3_12_bn1_bias: PARAMETER target='base_model.layer3.12.bn1.bias'\n",
       "            p_base_model_layer3_12_conv2_weight: PARAMETER target='base_model.layer3.12.conv2.weight'\n",
       "            p_base_model_layer3_12_bn2_weight: PARAMETER target='base_model.layer3.12.bn2.weight'\n",
       "            p_base_model_layer3_12_bn2_bias: PARAMETER target='base_model.layer3.12.bn2.bias'\n",
       "            p_base_model_layer3_12_conv3_weight: PARAMETER target='base_model.layer3.12.conv3.weight'\n",
       "            p_base_model_layer3_12_bn3_weight: PARAMETER target='base_model.layer3.12.bn3.weight'\n",
       "            p_base_model_layer3_12_bn3_bias: PARAMETER target='base_model.layer3.12.bn3.bias'\n",
       "            p_base_model_layer3_13_conv1_weight: PARAMETER target='base_model.layer3.13.conv1.weight'\n",
       "            p_base_model_layer3_13_bn1_weight: PARAMETER target='base_model.layer3.13.bn1.weight'\n",
       "            p_base_model_layer3_13_bn1_bias: PARAMETER target='base_model.layer3.13.bn1.bias'\n",
       "            p_base_model_layer3_13_conv2_weight: PARAMETER target='base_model.layer3.13.conv2.weight'\n",
       "            p_base_model_layer3_13_bn2_weight: PARAMETER target='base_model.layer3.13.bn2.weight'\n",
       "            p_base_model_layer3_13_bn2_bias: PARAMETER target='base_model.layer3.13.bn2.bias'\n",
       "            p_base_model_layer3_13_conv3_weight: PARAMETER target='base_model.layer3.13.conv3.weight'\n",
       "            p_base_model_layer3_13_bn3_weight: PARAMETER target='base_model.layer3.13.bn3.weight'\n",
       "            p_base_model_layer3_13_bn3_bias: PARAMETER target='base_model.layer3.13.bn3.bias'\n",
       "            p_base_model_layer3_14_conv1_weight: PARAMETER target='base_model.layer3.14.conv1.weight'\n",
       "            p_base_model_layer3_14_bn1_weight: PARAMETER target='base_model.layer3.14.bn1.weight'\n",
       "            p_base_model_layer3_14_bn1_bias: PARAMETER target='base_model.layer3.14.bn1.bias'\n",
       "            p_base_model_layer3_14_conv2_weight: PARAMETER target='base_model.layer3.14.conv2.weight'\n",
       "            p_base_model_layer3_14_bn2_weight: PARAMETER target='base_model.layer3.14.bn2.weight'\n",
       "            p_base_model_layer3_14_bn2_bias: PARAMETER target='base_model.layer3.14.bn2.bias'\n",
       "            p_base_model_layer3_14_conv3_weight: PARAMETER target='base_model.layer3.14.conv3.weight'\n",
       "            p_base_model_layer3_14_bn3_weight: PARAMETER target='base_model.layer3.14.bn3.weight'\n",
       "            p_base_model_layer3_14_bn3_bias: PARAMETER target='base_model.layer3.14.bn3.bias'\n",
       "            p_base_model_layer3_15_conv1_weight: PARAMETER target='base_model.layer3.15.conv1.weight'\n",
       "            p_base_model_layer3_15_bn1_weight: PARAMETER target='base_model.layer3.15.bn1.weight'\n",
       "            p_base_model_layer3_15_bn1_bias: PARAMETER target='base_model.layer3.15.bn1.bias'\n",
       "            p_base_model_layer3_15_conv2_weight: PARAMETER target='base_model.layer3.15.conv2.weight'\n",
       "            p_base_model_layer3_15_bn2_weight: PARAMETER target='base_model.layer3.15.bn2.weight'\n",
       "            p_base_model_layer3_15_bn2_bias: PARAMETER target='base_model.layer3.15.bn2.bias'\n",
       "            p_base_model_layer3_15_conv3_weight: PARAMETER target='base_model.layer3.15.conv3.weight'\n",
       "            p_base_model_layer3_15_bn3_weight: PARAMETER target='base_model.layer3.15.bn3.weight'\n",
       "            p_base_model_layer3_15_bn3_bias: PARAMETER target='base_model.layer3.15.bn3.bias'\n",
       "            p_base_model_layer3_16_conv1_weight: PARAMETER target='base_model.layer3.16.conv1.weight'\n",
       "            p_base_model_layer3_16_bn1_weight: PARAMETER target='base_model.layer3.16.bn1.weight'\n",
       "            p_base_model_layer3_16_bn1_bias: PARAMETER target='base_model.layer3.16.bn1.bias'\n",
       "            p_base_model_layer3_16_conv2_weight: PARAMETER target='base_model.layer3.16.conv2.weight'\n",
       "            p_base_model_layer3_16_bn2_weight: PARAMETER target='base_model.layer3.16.bn2.weight'\n",
       "            p_base_model_layer3_16_bn2_bias: PARAMETER target='base_model.layer3.16.bn2.bias'\n",
       "            p_base_model_layer3_16_conv3_weight: PARAMETER target='base_model.layer3.16.conv3.weight'\n",
       "            p_base_model_layer3_16_bn3_weight: PARAMETER target='base_model.layer3.16.bn3.weight'\n",
       "            p_base_model_layer3_16_bn3_bias: PARAMETER target='base_model.layer3.16.bn3.bias'\n",
       "            p_base_model_layer3_17_conv1_weight: PARAMETER target='base_model.layer3.17.conv1.weight'\n",
       "            p_base_model_layer3_17_bn1_weight: PARAMETER target='base_model.layer3.17.bn1.weight'\n",
       "            p_base_model_layer3_17_bn1_bias: PARAMETER target='base_model.layer3.17.bn1.bias'\n",
       "            p_base_model_layer3_17_conv2_weight: PARAMETER target='base_model.layer3.17.conv2.weight'\n",
       "            p_base_model_layer3_17_bn2_weight: PARAMETER target='base_model.layer3.17.bn2.weight'\n",
       "            p_base_model_layer3_17_bn2_bias: PARAMETER target='base_model.layer3.17.bn2.bias'\n",
       "            p_base_model_layer3_17_conv3_weight: PARAMETER target='base_model.layer3.17.conv3.weight'\n",
       "            p_base_model_layer3_17_bn3_weight: PARAMETER target='base_model.layer3.17.bn3.weight'\n",
       "            p_base_model_layer3_17_bn3_bias: PARAMETER target='base_model.layer3.17.bn3.bias'\n",
       "            p_base_model_layer3_18_conv1_weight: PARAMETER target='base_model.layer3.18.conv1.weight'\n",
       "            p_base_model_layer3_18_bn1_weight: PARAMETER target='base_model.layer3.18.bn1.weight'\n",
       "            p_base_model_layer3_18_bn1_bias: PARAMETER target='base_model.layer3.18.bn1.bias'\n",
       "            p_base_model_layer3_18_conv2_weight: PARAMETER target='base_model.layer3.18.conv2.weight'\n",
       "            p_base_model_layer3_18_bn2_weight: PARAMETER target='base_model.layer3.18.bn2.weight'\n",
       "            p_base_model_layer3_18_bn2_bias: PARAMETER target='base_model.layer3.18.bn2.bias'\n",
       "            p_base_model_layer3_18_conv3_weight: PARAMETER target='base_model.layer3.18.conv3.weight'\n",
       "            p_base_model_layer3_18_bn3_weight: PARAMETER target='base_model.layer3.18.bn3.weight'\n",
       "            p_base_model_layer3_18_bn3_bias: PARAMETER target='base_model.layer3.18.bn3.bias'\n",
       "            p_base_model_layer3_19_conv1_weight: PARAMETER target='base_model.layer3.19.conv1.weight'\n",
       "            p_base_model_layer3_19_bn1_weight: PARAMETER target='base_model.layer3.19.bn1.weight'\n",
       "            p_base_model_layer3_19_bn1_bias: PARAMETER target='base_model.layer3.19.bn1.bias'\n",
       "            p_base_model_layer3_19_conv2_weight: PARAMETER target='base_model.layer3.19.conv2.weight'\n",
       "            p_base_model_layer3_19_bn2_weight: PARAMETER target='base_model.layer3.19.bn2.weight'\n",
       "            p_base_model_layer3_19_bn2_bias: PARAMETER target='base_model.layer3.19.bn2.bias'\n",
       "            p_base_model_layer3_19_conv3_weight: PARAMETER target='base_model.layer3.19.conv3.weight'\n",
       "            p_base_model_layer3_19_bn3_weight: PARAMETER target='base_model.layer3.19.bn3.weight'\n",
       "            p_base_model_layer3_19_bn3_bias: PARAMETER target='base_model.layer3.19.bn3.bias'\n",
       "            p_base_model_layer3_20_conv1_weight: PARAMETER target='base_model.layer3.20.conv1.weight'\n",
       "            p_base_model_layer3_20_bn1_weight: PARAMETER target='base_model.layer3.20.bn1.weight'\n",
       "            p_base_model_layer3_20_bn1_bias: PARAMETER target='base_model.layer3.20.bn1.bias'\n",
       "            p_base_model_layer3_20_conv2_weight: PARAMETER target='base_model.layer3.20.conv2.weight'\n",
       "            p_base_model_layer3_20_bn2_weight: PARAMETER target='base_model.layer3.20.bn2.weight'\n",
       "            p_base_model_layer3_20_bn2_bias: PARAMETER target='base_model.layer3.20.bn2.bias'\n",
       "            p_base_model_layer3_20_conv3_weight: PARAMETER target='base_model.layer3.20.conv3.weight'\n",
       "            p_base_model_layer3_20_bn3_weight: PARAMETER target='base_model.layer3.20.bn3.weight'\n",
       "            p_base_model_layer3_20_bn3_bias: PARAMETER target='base_model.layer3.20.bn3.bias'\n",
       "            p_base_model_layer3_21_conv1_weight: PARAMETER target='base_model.layer3.21.conv1.weight'\n",
       "            p_base_model_layer3_21_bn1_weight: PARAMETER target='base_model.layer3.21.bn1.weight'\n",
       "            p_base_model_layer3_21_bn1_bias: PARAMETER target='base_model.layer3.21.bn1.bias'\n",
       "            p_base_model_layer3_21_conv2_weight: PARAMETER target='base_model.layer3.21.conv2.weight'\n",
       "            p_base_model_layer3_21_bn2_weight: PARAMETER target='base_model.layer3.21.bn2.weight'\n",
       "            p_base_model_layer3_21_bn2_bias: PARAMETER target='base_model.layer3.21.bn2.bias'\n",
       "            p_base_model_layer3_21_conv3_weight: PARAMETER target='base_model.layer3.21.conv3.weight'\n",
       "            p_base_model_layer3_21_bn3_weight: PARAMETER target='base_model.layer3.21.bn3.weight'\n",
       "            p_base_model_layer3_21_bn3_bias: PARAMETER target='base_model.layer3.21.bn3.bias'\n",
       "            p_base_model_layer3_22_conv1_weight: PARAMETER target='base_model.layer3.22.conv1.weight'\n",
       "            p_base_model_layer3_22_bn1_weight: PARAMETER target='base_model.layer3.22.bn1.weight'\n",
       "            p_base_model_layer3_22_bn1_bias: PARAMETER target='base_model.layer3.22.bn1.bias'\n",
       "            p_base_model_layer3_22_conv2_weight: PARAMETER target='base_model.layer3.22.conv2.weight'\n",
       "            p_base_model_layer3_22_bn2_weight: PARAMETER target='base_model.layer3.22.bn2.weight'\n",
       "            p_base_model_layer3_22_bn2_bias: PARAMETER target='base_model.layer3.22.bn2.bias'\n",
       "            p_base_model_layer3_22_conv3_weight: PARAMETER target='base_model.layer3.22.conv3.weight'\n",
       "            p_base_model_layer3_22_bn3_weight: PARAMETER target='base_model.layer3.22.bn3.weight'\n",
       "            p_base_model_layer3_22_bn3_bias: PARAMETER target='base_model.layer3.22.bn3.bias'\n",
       "            p_base_model_layer3_23_conv1_weight: PARAMETER target='base_model.layer3.23.conv1.weight'\n",
       "            p_base_model_layer3_23_bn1_weight: PARAMETER target='base_model.layer3.23.bn1.weight'\n",
       "            p_base_model_layer3_23_bn1_bias: PARAMETER target='base_model.layer3.23.bn1.bias'\n",
       "            p_base_model_layer3_23_conv2_weight: PARAMETER target='base_model.layer3.23.conv2.weight'\n",
       "            p_base_model_layer3_23_bn2_weight: PARAMETER target='base_model.layer3.23.bn2.weight'\n",
       "            p_base_model_layer3_23_bn2_bias: PARAMETER target='base_model.layer3.23.bn2.bias'\n",
       "            p_base_model_layer3_23_conv3_weight: PARAMETER target='base_model.layer3.23.conv3.weight'\n",
       "            p_base_model_layer3_23_bn3_weight: PARAMETER target='base_model.layer3.23.bn3.weight'\n",
       "            p_base_model_layer3_23_bn3_bias: PARAMETER target='base_model.layer3.23.bn3.bias'\n",
       "            p_base_model_layer3_24_conv1_weight: PARAMETER target='base_model.layer3.24.conv1.weight'\n",
       "            p_base_model_layer3_24_bn1_weight: PARAMETER target='base_model.layer3.24.bn1.weight'\n",
       "            p_base_model_layer3_24_bn1_bias: PARAMETER target='base_model.layer3.24.bn1.bias'\n",
       "            p_base_model_layer3_24_conv2_weight: PARAMETER target='base_model.layer3.24.conv2.weight'\n",
       "            p_base_model_layer3_24_bn2_weight: PARAMETER target='base_model.layer3.24.bn2.weight'\n",
       "            p_base_model_layer3_24_bn2_bias: PARAMETER target='base_model.layer3.24.bn2.bias'\n",
       "            p_base_model_layer3_24_conv3_weight: PARAMETER target='base_model.layer3.24.conv3.weight'\n",
       "            p_base_model_layer3_24_bn3_weight: PARAMETER target='base_model.layer3.24.bn3.weight'\n",
       "            p_base_model_layer3_24_bn3_bias: PARAMETER target='base_model.layer3.24.bn3.bias'\n",
       "            p_base_model_layer3_25_conv1_weight: PARAMETER target='base_model.layer3.25.conv1.weight'\n",
       "            p_base_model_layer3_25_bn1_weight: PARAMETER target='base_model.layer3.25.bn1.weight'\n",
       "            p_base_model_layer3_25_bn1_bias: PARAMETER target='base_model.layer3.25.bn1.bias'\n",
       "            p_base_model_layer3_25_conv2_weight: PARAMETER target='base_model.layer3.25.conv2.weight'\n",
       "            p_base_model_layer3_25_bn2_weight: PARAMETER target='base_model.layer3.25.bn2.weight'\n",
       "            p_base_model_layer3_25_bn2_bias: PARAMETER target='base_model.layer3.25.bn2.bias'\n",
       "            p_base_model_layer3_25_conv3_weight: PARAMETER target='base_model.layer3.25.conv3.weight'\n",
       "            p_base_model_layer3_25_bn3_weight: PARAMETER target='base_model.layer3.25.bn3.weight'\n",
       "            p_base_model_layer3_25_bn3_bias: PARAMETER target='base_model.layer3.25.bn3.bias'\n",
       "            p_base_model_layer3_26_conv1_weight: PARAMETER target='base_model.layer3.26.conv1.weight'\n",
       "            p_base_model_layer3_26_bn1_weight: PARAMETER target='base_model.layer3.26.bn1.weight'\n",
       "            p_base_model_layer3_26_bn1_bias: PARAMETER target='base_model.layer3.26.bn1.bias'\n",
       "            p_base_model_layer3_26_conv2_weight: PARAMETER target='base_model.layer3.26.conv2.weight'\n",
       "            p_base_model_layer3_26_bn2_weight: PARAMETER target='base_model.layer3.26.bn2.weight'\n",
       "            p_base_model_layer3_26_bn2_bias: PARAMETER target='base_model.layer3.26.bn2.bias'\n",
       "            p_base_model_layer3_26_conv3_weight: PARAMETER target='base_model.layer3.26.conv3.weight'\n",
       "            p_base_model_layer3_26_bn3_weight: PARAMETER target='base_model.layer3.26.bn3.weight'\n",
       "            p_base_model_layer3_26_bn3_bias: PARAMETER target='base_model.layer3.26.bn3.bias'\n",
       "            p_base_model_layer3_27_conv1_weight: PARAMETER target='base_model.layer3.27.conv1.weight'\n",
       "            p_base_model_layer3_27_bn1_weight: PARAMETER target='base_model.layer3.27.bn1.weight'\n",
       "            p_base_model_layer3_27_bn1_bias: PARAMETER target='base_model.layer3.27.bn1.bias'\n",
       "            p_base_model_layer3_27_conv2_weight: PARAMETER target='base_model.layer3.27.conv2.weight'\n",
       "            p_base_model_layer3_27_bn2_weight: PARAMETER target='base_model.layer3.27.bn2.weight'\n",
       "            p_base_model_layer3_27_bn2_bias: PARAMETER target='base_model.layer3.27.bn2.bias'\n",
       "            p_base_model_layer3_27_conv3_weight: PARAMETER target='base_model.layer3.27.conv3.weight'\n",
       "            p_base_model_layer3_27_bn3_weight: PARAMETER target='base_model.layer3.27.bn3.weight'\n",
       "            p_base_model_layer3_27_bn3_bias: PARAMETER target='base_model.layer3.27.bn3.bias'\n",
       "            p_base_model_layer3_28_conv1_weight: PARAMETER target='base_model.layer3.28.conv1.weight'\n",
       "            p_base_model_layer3_28_bn1_weight: PARAMETER target='base_model.layer3.28.bn1.weight'\n",
       "            p_base_model_layer3_28_bn1_bias: PARAMETER target='base_model.layer3.28.bn1.bias'\n",
       "            p_base_model_layer3_28_conv2_weight: PARAMETER target='base_model.layer3.28.conv2.weight'\n",
       "            p_base_model_layer3_28_bn2_weight: PARAMETER target='base_model.layer3.28.bn2.weight'\n",
       "            p_base_model_layer3_28_bn2_bias: PARAMETER target='base_model.layer3.28.bn2.bias'\n",
       "            p_base_model_layer3_28_conv3_weight: PARAMETER target='base_model.layer3.28.conv3.weight'\n",
       "            p_base_model_layer3_28_bn3_weight: PARAMETER target='base_model.layer3.28.bn3.weight'\n",
       "            p_base_model_layer3_28_bn3_bias: PARAMETER target='base_model.layer3.28.bn3.bias'\n",
       "            p_base_model_layer3_29_conv1_weight: PARAMETER target='base_model.layer3.29.conv1.weight'\n",
       "            p_base_model_layer3_29_bn1_weight: PARAMETER target='base_model.layer3.29.bn1.weight'\n",
       "            p_base_model_layer3_29_bn1_bias: PARAMETER target='base_model.layer3.29.bn1.bias'\n",
       "            p_base_model_layer3_29_conv2_weight: PARAMETER target='base_model.layer3.29.conv2.weight'\n",
       "            p_base_model_layer3_29_bn2_weight: PARAMETER target='base_model.layer3.29.bn2.weight'\n",
       "            p_base_model_layer3_29_bn2_bias: PARAMETER target='base_model.layer3.29.bn2.bias'\n",
       "            p_base_model_layer3_29_conv3_weight: PARAMETER target='base_model.layer3.29.conv3.weight'\n",
       "            p_base_model_layer3_29_bn3_weight: PARAMETER target='base_model.layer3.29.bn3.weight'\n",
       "            p_base_model_layer3_29_bn3_bias: PARAMETER target='base_model.layer3.29.bn3.bias'\n",
       "            p_base_model_layer3_30_conv1_weight: PARAMETER target='base_model.layer3.30.conv1.weight'\n",
       "            p_base_model_layer3_30_bn1_weight: PARAMETER target='base_model.layer3.30.bn1.weight'\n",
       "            p_base_model_layer3_30_bn1_bias: PARAMETER target='base_model.layer3.30.bn1.bias'\n",
       "            p_base_model_layer3_30_conv2_weight: PARAMETER target='base_model.layer3.30.conv2.weight'\n",
       "            p_base_model_layer3_30_bn2_weight: PARAMETER target='base_model.layer3.30.bn2.weight'\n",
       "            p_base_model_layer3_30_bn2_bias: PARAMETER target='base_model.layer3.30.bn2.bias'\n",
       "            p_base_model_layer3_30_conv3_weight: PARAMETER target='base_model.layer3.30.conv3.weight'\n",
       "            p_base_model_layer3_30_bn3_weight: PARAMETER target='base_model.layer3.30.bn3.weight'\n",
       "            p_base_model_layer3_30_bn3_bias: PARAMETER target='base_model.layer3.30.bn3.bias'\n",
       "            p_base_model_layer3_31_conv1_weight: PARAMETER target='base_model.layer3.31.conv1.weight'\n",
       "            p_base_model_layer3_31_bn1_weight: PARAMETER target='base_model.layer3.31.bn1.weight'\n",
       "            p_base_model_layer3_31_bn1_bias: PARAMETER target='base_model.layer3.31.bn1.bias'\n",
       "            p_base_model_layer3_31_conv2_weight: PARAMETER target='base_model.layer3.31.conv2.weight'\n",
       "            p_base_model_layer3_31_bn2_weight: PARAMETER target='base_model.layer3.31.bn2.weight'\n",
       "            p_base_model_layer3_31_bn2_bias: PARAMETER target='base_model.layer3.31.bn2.bias'\n",
       "            p_base_model_layer3_31_conv3_weight: PARAMETER target='base_model.layer3.31.conv3.weight'\n",
       "            p_base_model_layer3_31_bn3_weight: PARAMETER target='base_model.layer3.31.bn3.weight'\n",
       "            p_base_model_layer3_31_bn3_bias: PARAMETER target='base_model.layer3.31.bn3.bias'\n",
       "            p_base_model_layer3_32_conv1_weight: PARAMETER target='base_model.layer3.32.conv1.weight'\n",
       "            p_base_model_layer3_32_bn1_weight: PARAMETER target='base_model.layer3.32.bn1.weight'\n",
       "            p_base_model_layer3_32_bn1_bias: PARAMETER target='base_model.layer3.32.bn1.bias'\n",
       "            p_base_model_layer3_32_conv2_weight: PARAMETER target='base_model.layer3.32.conv2.weight'\n",
       "            p_base_model_layer3_32_bn2_weight: PARAMETER target='base_model.layer3.32.bn2.weight'\n",
       "            p_base_model_layer3_32_bn2_bias: PARAMETER target='base_model.layer3.32.bn2.bias'\n",
       "            p_base_model_layer3_32_conv3_weight: PARAMETER target='base_model.layer3.32.conv3.weight'\n",
       "            p_base_model_layer3_32_bn3_weight: PARAMETER target='base_model.layer3.32.bn3.weight'\n",
       "            p_base_model_layer3_32_bn3_bias: PARAMETER target='base_model.layer3.32.bn3.bias'\n",
       "            p_base_model_layer3_33_conv1_weight: PARAMETER target='base_model.layer3.33.conv1.weight'\n",
       "            p_base_model_layer3_33_bn1_weight: PARAMETER target='base_model.layer3.33.bn1.weight'\n",
       "            p_base_model_layer3_33_bn1_bias: PARAMETER target='base_model.layer3.33.bn1.bias'\n",
       "            p_base_model_layer3_33_conv2_weight: PARAMETER target='base_model.layer3.33.conv2.weight'\n",
       "            p_base_model_layer3_33_bn2_weight: PARAMETER target='base_model.layer3.33.bn2.weight'\n",
       "            p_base_model_layer3_33_bn2_bias: PARAMETER target='base_model.layer3.33.bn2.bias'\n",
       "            p_base_model_layer3_33_conv3_weight: PARAMETER target='base_model.layer3.33.conv3.weight'\n",
       "            p_base_model_layer3_33_bn3_weight: PARAMETER target='base_model.layer3.33.bn3.weight'\n",
       "            p_base_model_layer3_33_bn3_bias: PARAMETER target='base_model.layer3.33.bn3.bias'\n",
       "            p_base_model_layer3_34_conv1_weight: PARAMETER target='base_model.layer3.34.conv1.weight'\n",
       "            p_base_model_layer3_34_bn1_weight: PARAMETER target='base_model.layer3.34.bn1.weight'\n",
       "            p_base_model_layer3_34_bn1_bias: PARAMETER target='base_model.layer3.34.bn1.bias'\n",
       "            p_base_model_layer3_34_conv2_weight: PARAMETER target='base_model.layer3.34.conv2.weight'\n",
       "            p_base_model_layer3_34_bn2_weight: PARAMETER target='base_model.layer3.34.bn2.weight'\n",
       "            p_base_model_layer3_34_bn2_bias: PARAMETER target='base_model.layer3.34.bn2.bias'\n",
       "            p_base_model_layer3_34_conv3_weight: PARAMETER target='base_model.layer3.34.conv3.weight'\n",
       "            p_base_model_layer3_34_bn3_weight: PARAMETER target='base_model.layer3.34.bn3.weight'\n",
       "            p_base_model_layer3_34_bn3_bias: PARAMETER target='base_model.layer3.34.bn3.bias'\n",
       "            p_base_model_layer3_35_conv1_weight: PARAMETER target='base_model.layer3.35.conv1.weight'\n",
       "            p_base_model_layer3_35_bn1_weight: PARAMETER target='base_model.layer3.35.bn1.weight'\n",
       "            p_base_model_layer3_35_bn1_bias: PARAMETER target='base_model.layer3.35.bn1.bias'\n",
       "            p_base_model_layer3_35_conv2_weight: PARAMETER target='base_model.layer3.35.conv2.weight'\n",
       "            p_base_model_layer3_35_bn2_weight: PARAMETER target='base_model.layer3.35.bn2.weight'\n",
       "            p_base_model_layer3_35_bn2_bias: PARAMETER target='base_model.layer3.35.bn2.bias'\n",
       "            p_base_model_layer3_35_conv3_weight: PARAMETER target='base_model.layer3.35.conv3.weight'\n",
       "            p_base_model_layer3_35_bn3_weight: PARAMETER target='base_model.layer3.35.bn3.weight'\n",
       "            p_base_model_layer3_35_bn3_bias: PARAMETER target='base_model.layer3.35.bn3.bias'\n",
       "            p_base_model_layer4_0_conv1_weight: PARAMETER target='base_model.layer4.0.conv1.weight'\n",
       "            p_base_model_layer4_0_bn1_weight: PARAMETER target='base_model.layer4.0.bn1.weight'\n",
       "            p_base_model_layer4_0_bn1_bias: PARAMETER target='base_model.layer4.0.bn1.bias'\n",
       "            p_base_model_layer4_0_conv2_weight: PARAMETER target='base_model.layer4.0.conv2.weight'\n",
       "            p_base_model_layer4_0_bn2_weight: PARAMETER target='base_model.layer4.0.bn2.weight'\n",
       "            p_base_model_layer4_0_bn2_bias: PARAMETER target='base_model.layer4.0.bn2.bias'\n",
       "            p_base_model_layer4_0_conv3_weight: PARAMETER target='base_model.layer4.0.conv3.weight'\n",
       "            p_base_model_layer4_0_bn3_weight: PARAMETER target='base_model.layer4.0.bn3.weight'\n",
       "            p_base_model_layer4_0_bn3_bias: PARAMETER target='base_model.layer4.0.bn3.bias'\n",
       "            p_base_model_layer4_0_downsample_0_weight: PARAMETER target='base_model.layer4.0.downsample.0.weight'\n",
       "            p_base_model_layer4_0_downsample_1_weight: PARAMETER target='base_model.layer4.0.downsample.1.weight'\n",
       "            p_base_model_layer4_0_downsample_1_bias: PARAMETER target='base_model.layer4.0.downsample.1.bias'\n",
       "            p_base_model_layer4_1_conv1_weight: PARAMETER target='base_model.layer4.1.conv1.weight'\n",
       "            p_base_model_layer4_1_bn1_weight: PARAMETER target='base_model.layer4.1.bn1.weight'\n",
       "            p_base_model_layer4_1_bn1_bias: PARAMETER target='base_model.layer4.1.bn1.bias'\n",
       "            p_base_model_layer4_1_conv2_weight: PARAMETER target='base_model.layer4.1.conv2.weight'\n",
       "            p_base_model_layer4_1_bn2_weight: PARAMETER target='base_model.layer4.1.bn2.weight'\n",
       "            p_base_model_layer4_1_bn2_bias: PARAMETER target='base_model.layer4.1.bn2.bias'\n",
       "            p_base_model_layer4_1_conv3_weight: PARAMETER target='base_model.layer4.1.conv3.weight'\n",
       "            p_base_model_layer4_1_bn3_weight: PARAMETER target='base_model.layer4.1.bn3.weight'\n",
       "            p_base_model_layer4_1_bn3_bias: PARAMETER target='base_model.layer4.1.bn3.bias'\n",
       "            p_base_model_layer4_2_conv1_weight: PARAMETER target='base_model.layer4.2.conv1.weight'\n",
       "            p_base_model_layer4_2_bn1_weight: PARAMETER target='base_model.layer4.2.bn1.weight'\n",
       "            p_base_model_layer4_2_bn1_bias: PARAMETER target='base_model.layer4.2.bn1.bias'\n",
       "            p_base_model_layer4_2_conv2_weight: PARAMETER target='base_model.layer4.2.conv2.weight'\n",
       "            p_base_model_layer4_2_bn2_weight: PARAMETER target='base_model.layer4.2.bn2.weight'\n",
       "            p_base_model_layer4_2_bn2_bias: PARAMETER target='base_model.layer4.2.bn2.bias'\n",
       "            p_base_model_layer4_2_conv3_weight: PARAMETER target='base_model.layer4.2.conv3.weight'\n",
       "            p_base_model_layer4_2_bn3_weight: PARAMETER target='base_model.layer4.2.bn3.weight'\n",
       "            p_base_model_layer4_2_bn3_bias: PARAMETER target='base_model.layer4.2.bn3.bias'\n",
       "            p_base_model_fc_weight: PARAMETER target='base_model.fc.weight'\n",
       "            p_base_model_fc_bias: PARAMETER target='base_model.fc.bias'\n",
       "            p_features_extractor_0_weight: PARAMETER target='features_extractor.0.weight'\n",
       "            p_features_extractor_1_weight: PARAMETER target='features_extractor.1.weight'\n",
       "            p_features_extractor_1_bias: PARAMETER target='features_extractor.1.bias'\n",
       "            p_features_extractor_4_0_conv1_weight: PARAMETER target='features_extractor.4.0.conv1.weight'\n",
       "            p_features_extractor_4_0_bn1_weight: PARAMETER target='features_extractor.4.0.bn1.weight'\n",
       "            p_features_extractor_4_0_bn1_bias: PARAMETER target='features_extractor.4.0.bn1.bias'\n",
       "            p_features_extractor_4_0_conv2_weight: PARAMETER target='features_extractor.4.0.conv2.weight'\n",
       "            p_features_extractor_4_0_bn2_weight: PARAMETER target='features_extractor.4.0.bn2.weight'\n",
       "            p_features_extractor_4_0_bn2_bias: PARAMETER target='features_extractor.4.0.bn2.bias'\n",
       "            p_features_extractor_4_0_conv3_weight: PARAMETER target='features_extractor.4.0.conv3.weight'\n",
       "            p_features_extractor_4_0_bn3_weight: PARAMETER target='features_extractor.4.0.bn3.weight'\n",
       "            p_features_extractor_4_0_bn3_bias: PARAMETER target='features_extractor.4.0.bn3.bias'\n",
       "            p_features_extractor_4_0_downsample_0_weight: PARAMETER target='features_extractor.4.0.downsample.0.weight'\n",
       "            p_features_extractor_4_0_downsample_1_weight: PARAMETER target='features_extractor.4.0.downsample.1.weight'\n",
       "            p_features_extractor_4_0_downsample_1_bias: PARAMETER target='features_extractor.4.0.downsample.1.bias'\n",
       "            p_features_extractor_4_1_conv1_weight: PARAMETER target='features_extractor.4.1.conv1.weight'\n",
       "            p_features_extractor_4_1_bn1_weight: PARAMETER target='features_extractor.4.1.bn1.weight'\n",
       "            p_features_extractor_4_1_bn1_bias: PARAMETER target='features_extractor.4.1.bn1.bias'\n",
       "            p_features_extractor_4_1_conv2_weight: PARAMETER target='features_extractor.4.1.conv2.weight'\n",
       "            p_features_extractor_4_1_bn2_weight: PARAMETER target='features_extractor.4.1.bn2.weight'\n",
       "            p_features_extractor_4_1_bn2_bias: PARAMETER target='features_extractor.4.1.bn2.bias'\n",
       "            p_features_extractor_4_1_conv3_weight: PARAMETER target='features_extractor.4.1.conv3.weight'\n",
       "            p_features_extractor_4_1_bn3_weight: PARAMETER target='features_extractor.4.1.bn3.weight'\n",
       "            p_features_extractor_4_1_bn3_bias: PARAMETER target='features_extractor.4.1.bn3.bias'\n",
       "            p_features_extractor_4_2_conv1_weight: PARAMETER target='features_extractor.4.2.conv1.weight'\n",
       "            p_features_extractor_4_2_bn1_weight: PARAMETER target='features_extractor.4.2.bn1.weight'\n",
       "            p_features_extractor_4_2_bn1_bias: PARAMETER target='features_extractor.4.2.bn1.bias'\n",
       "            p_features_extractor_4_2_conv2_weight: PARAMETER target='features_extractor.4.2.conv2.weight'\n",
       "            p_features_extractor_4_2_bn2_weight: PARAMETER target='features_extractor.4.2.bn2.weight'\n",
       "            p_features_extractor_4_2_bn2_bias: PARAMETER target='features_extractor.4.2.bn2.bias'\n",
       "            p_features_extractor_4_2_conv3_weight: PARAMETER target='features_extractor.4.2.conv3.weight'\n",
       "            p_features_extractor_4_2_bn3_weight: PARAMETER target='features_extractor.4.2.bn3.weight'\n",
       "            p_features_extractor_4_2_bn3_bias: PARAMETER target='features_extractor.4.2.bn3.bias'\n",
       "            p_features_extractor_5_0_conv1_weight: PARAMETER target='features_extractor.5.0.conv1.weight'\n",
       "            p_features_extractor_5_0_bn1_weight: PARAMETER target='features_extractor.5.0.bn1.weight'\n",
       "            p_features_extractor_5_0_bn1_bias: PARAMETER target='features_extractor.5.0.bn1.bias'\n",
       "            p_features_extractor_5_0_conv2_weight: PARAMETER target='features_extractor.5.0.conv2.weight'\n",
       "            p_features_extractor_5_0_bn2_weight: PARAMETER target='features_extractor.5.0.bn2.weight'\n",
       "            p_features_extractor_5_0_bn2_bias: PARAMETER target='features_extractor.5.0.bn2.bias'\n",
       "            p_features_extractor_5_0_conv3_weight: PARAMETER target='features_extractor.5.0.conv3.weight'\n",
       "            p_features_extractor_5_0_bn3_weight: PARAMETER target='features_extractor.5.0.bn3.weight'\n",
       "            p_features_extractor_5_0_bn3_bias: PARAMETER target='features_extractor.5.0.bn3.bias'\n",
       "            p_features_extractor_5_0_downsample_0_weight: PARAMETER target='features_extractor.5.0.downsample.0.weight'\n",
       "            p_features_extractor_5_0_downsample_1_weight: PARAMETER target='features_extractor.5.0.downsample.1.weight'\n",
       "            p_features_extractor_5_0_downsample_1_bias: PARAMETER target='features_extractor.5.0.downsample.1.bias'\n",
       "            p_features_extractor_5_1_conv1_weight: PARAMETER target='features_extractor.5.1.conv1.weight'\n",
       "            p_features_extractor_5_1_bn1_weight: PARAMETER target='features_extractor.5.1.bn1.weight'\n",
       "            p_features_extractor_5_1_bn1_bias: PARAMETER target='features_extractor.5.1.bn1.bias'\n",
       "            p_features_extractor_5_1_conv2_weight: PARAMETER target='features_extractor.5.1.conv2.weight'\n",
       "            p_features_extractor_5_1_bn2_weight: PARAMETER target='features_extractor.5.1.bn2.weight'\n",
       "            p_features_extractor_5_1_bn2_bias: PARAMETER target='features_extractor.5.1.bn2.bias'\n",
       "            p_features_extractor_5_1_conv3_weight: PARAMETER target='features_extractor.5.1.conv3.weight'\n",
       "            p_features_extractor_5_1_bn3_weight: PARAMETER target='features_extractor.5.1.bn3.weight'\n",
       "            p_features_extractor_5_1_bn3_bias: PARAMETER target='features_extractor.5.1.bn3.bias'\n",
       "            p_features_extractor_5_2_conv1_weight: PARAMETER target='features_extractor.5.2.conv1.weight'\n",
       "            p_features_extractor_5_2_bn1_weight: PARAMETER target='features_extractor.5.2.bn1.weight'\n",
       "            p_features_extractor_5_2_bn1_bias: PARAMETER target='features_extractor.5.2.bn1.bias'\n",
       "            p_features_extractor_5_2_conv2_weight: PARAMETER target='features_extractor.5.2.conv2.weight'\n",
       "            p_features_extractor_5_2_bn2_weight: PARAMETER target='features_extractor.5.2.bn2.weight'\n",
       "            p_features_extractor_5_2_bn2_bias: PARAMETER target='features_extractor.5.2.bn2.bias'\n",
       "            p_features_extractor_5_2_conv3_weight: PARAMETER target='features_extractor.5.2.conv3.weight'\n",
       "            p_features_extractor_5_2_bn3_weight: PARAMETER target='features_extractor.5.2.bn3.weight'\n",
       "            p_features_extractor_5_2_bn3_bias: PARAMETER target='features_extractor.5.2.bn3.bias'\n",
       "            p_features_extractor_5_3_conv1_weight: PARAMETER target='features_extractor.5.3.conv1.weight'\n",
       "            p_features_extractor_5_3_bn1_weight: PARAMETER target='features_extractor.5.3.bn1.weight'\n",
       "            p_features_extractor_5_3_bn1_bias: PARAMETER target='features_extractor.5.3.bn1.bias'\n",
       "            p_features_extractor_5_3_conv2_weight: PARAMETER target='features_extractor.5.3.conv2.weight'\n",
       "            p_features_extractor_5_3_bn2_weight: PARAMETER target='features_extractor.5.3.bn2.weight'\n",
       "            p_features_extractor_5_3_bn2_bias: PARAMETER target='features_extractor.5.3.bn2.bias'\n",
       "            p_features_extractor_5_3_conv3_weight: PARAMETER target='features_extractor.5.3.conv3.weight'\n",
       "            p_features_extractor_5_3_bn3_weight: PARAMETER target='features_extractor.5.3.bn3.weight'\n",
       "            p_features_extractor_5_3_bn3_bias: PARAMETER target='features_extractor.5.3.bn3.bias'\n",
       "            p_features_extractor_5_4_conv1_weight: PARAMETER target='features_extractor.5.4.conv1.weight'\n",
       "            p_features_extractor_5_4_bn1_weight: PARAMETER target='features_extractor.5.4.bn1.weight'\n",
       "            p_features_extractor_5_4_bn1_bias: PARAMETER target='features_extractor.5.4.bn1.bias'\n",
       "            p_features_extractor_5_4_conv2_weight: PARAMETER target='features_extractor.5.4.conv2.weight'\n",
       "            p_features_extractor_5_4_bn2_weight: PARAMETER target='features_extractor.5.4.bn2.weight'\n",
       "            p_features_extractor_5_4_bn2_bias: PARAMETER target='features_extractor.5.4.bn2.bias'\n",
       "            p_features_extractor_5_4_conv3_weight: PARAMETER target='features_extractor.5.4.conv3.weight'\n",
       "            p_features_extractor_5_4_bn3_weight: PARAMETER target='features_extractor.5.4.bn3.weight'\n",
       "            p_features_extractor_5_4_bn3_bias: PARAMETER target='features_extractor.5.4.bn3.bias'\n",
       "            p_features_extractor_5_5_conv1_weight: PARAMETER target='features_extractor.5.5.conv1.weight'\n",
       "            p_features_extractor_5_5_bn1_weight: PARAMETER target='features_extractor.5.5.bn1.weight'\n",
       "            p_features_extractor_5_5_bn1_bias: PARAMETER target='features_extractor.5.5.bn1.bias'\n",
       "            p_features_extractor_5_5_conv2_weight: PARAMETER target='features_extractor.5.5.conv2.weight'\n",
       "            p_features_extractor_5_5_bn2_weight: PARAMETER target='features_extractor.5.5.bn2.weight'\n",
       "            p_features_extractor_5_5_bn2_bias: PARAMETER target='features_extractor.5.5.bn2.bias'\n",
       "            p_features_extractor_5_5_conv3_weight: PARAMETER target='features_extractor.5.5.conv3.weight'\n",
       "            p_features_extractor_5_5_bn3_weight: PARAMETER target='features_extractor.5.5.bn3.weight'\n",
       "            p_features_extractor_5_5_bn3_bias: PARAMETER target='features_extractor.5.5.bn3.bias'\n",
       "            p_features_extractor_5_6_conv1_weight: PARAMETER target='features_extractor.5.6.conv1.weight'\n",
       "            p_features_extractor_5_6_bn1_weight: PARAMETER target='features_extractor.5.6.bn1.weight'\n",
       "            p_features_extractor_5_6_bn1_bias: PARAMETER target='features_extractor.5.6.bn1.bias'\n",
       "            p_features_extractor_5_6_conv2_weight: PARAMETER target='features_extractor.5.6.conv2.weight'\n",
       "            p_features_extractor_5_6_bn2_weight: PARAMETER target='features_extractor.5.6.bn2.weight'\n",
       "            p_features_extractor_5_6_bn2_bias: PARAMETER target='features_extractor.5.6.bn2.bias'\n",
       "            p_features_extractor_5_6_conv3_weight: PARAMETER target='features_extractor.5.6.conv3.weight'\n",
       "            p_features_extractor_5_6_bn3_weight: PARAMETER target='features_extractor.5.6.bn3.weight'\n",
       "            p_features_extractor_5_6_bn3_bias: PARAMETER target='features_extractor.5.6.bn3.bias'\n",
       "            p_features_extractor_5_7_conv1_weight: PARAMETER target='features_extractor.5.7.conv1.weight'\n",
       "            p_features_extractor_5_7_bn1_weight: PARAMETER target='features_extractor.5.7.bn1.weight'\n",
       "            p_features_extractor_5_7_bn1_bias: PARAMETER target='features_extractor.5.7.bn1.bias'\n",
       "            p_features_extractor_5_7_conv2_weight: PARAMETER target='features_extractor.5.7.conv2.weight'\n",
       "            p_features_extractor_5_7_bn2_weight: PARAMETER target='features_extractor.5.7.bn2.weight'\n",
       "            p_features_extractor_5_7_bn2_bias: PARAMETER target='features_extractor.5.7.bn2.bias'\n",
       "            p_features_extractor_5_7_conv3_weight: PARAMETER target='features_extractor.5.7.conv3.weight'\n",
       "            p_features_extractor_5_7_bn3_weight: PARAMETER target='features_extractor.5.7.bn3.weight'\n",
       "            p_features_extractor_5_7_bn3_bias: PARAMETER target='features_extractor.5.7.bn3.bias'\n",
       "            p_features_extractor_6_0_conv1_weight: PARAMETER target='features_extractor.6.0.conv1.weight'\n",
       "            p_features_extractor_6_0_bn1_weight: PARAMETER target='features_extractor.6.0.bn1.weight'\n",
       "            p_features_extractor_6_0_bn1_bias: PARAMETER target='features_extractor.6.0.bn1.bias'\n",
       "            p_features_extractor_6_0_conv2_weight: PARAMETER target='features_extractor.6.0.conv2.weight'\n",
       "            p_features_extractor_6_0_bn2_weight: PARAMETER target='features_extractor.6.0.bn2.weight'\n",
       "            p_features_extractor_6_0_bn2_bias: PARAMETER target='features_extractor.6.0.bn2.bias'\n",
       "            p_features_extractor_6_0_conv3_weight: PARAMETER target='features_extractor.6.0.conv3.weight'\n",
       "            p_features_extractor_6_0_bn3_weight: PARAMETER target='features_extractor.6.0.bn3.weight'\n",
       "            p_features_extractor_6_0_bn3_bias: PARAMETER target='features_extractor.6.0.bn3.bias'\n",
       "            p_features_extractor_6_0_downsample_0_weight: PARAMETER target='features_extractor.6.0.downsample.0.weight'\n",
       "            p_features_extractor_6_0_downsample_1_weight: PARAMETER target='features_extractor.6.0.downsample.1.weight'\n",
       "            p_features_extractor_6_0_downsample_1_bias: PARAMETER target='features_extractor.6.0.downsample.1.bias'\n",
       "            p_features_extractor_6_1_conv1_weight: PARAMETER target='features_extractor.6.1.conv1.weight'\n",
       "            p_features_extractor_6_1_bn1_weight: PARAMETER target='features_extractor.6.1.bn1.weight'\n",
       "            p_features_extractor_6_1_bn1_bias: PARAMETER target='features_extractor.6.1.bn1.bias'\n",
       "            p_features_extractor_6_1_conv2_weight: PARAMETER target='features_extractor.6.1.conv2.weight'\n",
       "            p_features_extractor_6_1_bn2_weight: PARAMETER target='features_extractor.6.1.bn2.weight'\n",
       "            p_features_extractor_6_1_bn2_bias: PARAMETER target='features_extractor.6.1.bn2.bias'\n",
       "            p_features_extractor_6_1_conv3_weight: PARAMETER target='features_extractor.6.1.conv3.weight'\n",
       "            p_features_extractor_6_1_bn3_weight: PARAMETER target='features_extractor.6.1.bn3.weight'\n",
       "            p_features_extractor_6_1_bn3_bias: PARAMETER target='features_extractor.6.1.bn3.bias'\n",
       "            p_features_extractor_6_2_conv1_weight: PARAMETER target='features_extractor.6.2.conv1.weight'\n",
       "            p_features_extractor_6_2_bn1_weight: PARAMETER target='features_extractor.6.2.bn1.weight'\n",
       "            p_features_extractor_6_2_bn1_bias: PARAMETER target='features_extractor.6.2.bn1.bias'\n",
       "            p_features_extractor_6_2_conv2_weight: PARAMETER target='features_extractor.6.2.conv2.weight'\n",
       "            p_features_extractor_6_2_bn2_weight: PARAMETER target='features_extractor.6.2.bn2.weight'\n",
       "            p_features_extractor_6_2_bn2_bias: PARAMETER target='features_extractor.6.2.bn2.bias'\n",
       "            p_features_extractor_6_2_conv3_weight: PARAMETER target='features_extractor.6.2.conv3.weight'\n",
       "            p_features_extractor_6_2_bn3_weight: PARAMETER target='features_extractor.6.2.bn3.weight'\n",
       "            p_features_extractor_6_2_bn3_bias: PARAMETER target='features_extractor.6.2.bn3.bias'\n",
       "            p_features_extractor_6_3_conv1_weight: PARAMETER target='features_extractor.6.3.conv1.weight'\n",
       "            p_features_extractor_6_3_bn1_weight: PARAMETER target='features_extractor.6.3.bn1.weight'\n",
       "            p_features_extractor_6_3_bn1_bias: PARAMETER target='features_extractor.6.3.bn1.bias'\n",
       "            p_features_extractor_6_3_conv2_weight: PARAMETER target='features_extractor.6.3.conv2.weight'\n",
       "            p_features_extractor_6_3_bn2_weight: PARAMETER target='features_extractor.6.3.bn2.weight'\n",
       "            p_features_extractor_6_3_bn2_bias: PARAMETER target='features_extractor.6.3.bn2.bias'\n",
       "            p_features_extractor_6_3_conv3_weight: PARAMETER target='features_extractor.6.3.conv3.weight'\n",
       "            p_features_extractor_6_3_bn3_weight: PARAMETER target='features_extractor.6.3.bn3.weight'\n",
       "            p_features_extractor_6_3_bn3_bias: PARAMETER target='features_extractor.6.3.bn3.bias'\n",
       "            p_features_extractor_6_4_conv1_weight: PARAMETER target='features_extractor.6.4.conv1.weight'\n",
       "            p_features_extractor_6_4_bn1_weight: PARAMETER target='features_extractor.6.4.bn1.weight'\n",
       "            p_features_extractor_6_4_bn1_bias: PARAMETER target='features_extractor.6.4.bn1.bias'\n",
       "            p_features_extractor_6_4_conv2_weight: PARAMETER target='features_extractor.6.4.conv2.weight'\n",
       "            p_features_extractor_6_4_bn2_weight: PARAMETER target='features_extractor.6.4.bn2.weight'\n",
       "            p_features_extractor_6_4_bn2_bias: PARAMETER target='features_extractor.6.4.bn2.bias'\n",
       "            p_features_extractor_6_4_conv3_weight: PARAMETER target='features_extractor.6.4.conv3.weight'\n",
       "            p_features_extractor_6_4_bn3_weight: PARAMETER target='features_extractor.6.4.bn3.weight'\n",
       "            p_features_extractor_6_4_bn3_bias: PARAMETER target='features_extractor.6.4.bn3.bias'\n",
       "            p_features_extractor_6_5_conv1_weight: PARAMETER target='features_extractor.6.5.conv1.weight'\n",
       "            p_features_extractor_6_5_bn1_weight: PARAMETER target='features_extractor.6.5.bn1.weight'\n",
       "            p_features_extractor_6_5_bn1_bias: PARAMETER target='features_extractor.6.5.bn1.bias'\n",
       "            p_features_extractor_6_5_conv2_weight: PARAMETER target='features_extractor.6.5.conv2.weight'\n",
       "            p_features_extractor_6_5_bn2_weight: PARAMETER target='features_extractor.6.5.bn2.weight'\n",
       "            p_features_extractor_6_5_bn2_bias: PARAMETER target='features_extractor.6.5.bn2.bias'\n",
       "            p_features_extractor_6_5_conv3_weight: PARAMETER target='features_extractor.6.5.conv3.weight'\n",
       "            p_features_extractor_6_5_bn3_weight: PARAMETER target='features_extractor.6.5.bn3.weight'\n",
       "            p_features_extractor_6_5_bn3_bias: PARAMETER target='features_extractor.6.5.bn3.bias'\n",
       "            p_features_extractor_6_6_conv1_weight: PARAMETER target='features_extractor.6.6.conv1.weight'\n",
       "            p_features_extractor_6_6_bn1_weight: PARAMETER target='features_extractor.6.6.bn1.weight'\n",
       "            p_features_extractor_6_6_bn1_bias: PARAMETER target='features_extractor.6.6.bn1.bias'\n",
       "            p_features_extractor_6_6_conv2_weight: PARAMETER target='features_extractor.6.6.conv2.weight'\n",
       "            p_features_extractor_6_6_bn2_weight: PARAMETER target='features_extractor.6.6.bn2.weight'\n",
       "            p_features_extractor_6_6_bn2_bias: PARAMETER target='features_extractor.6.6.bn2.bias'\n",
       "            p_features_extractor_6_6_conv3_weight: PARAMETER target='features_extractor.6.6.conv3.weight'\n",
       "            p_features_extractor_6_6_bn3_weight: PARAMETER target='features_extractor.6.6.bn3.weight'\n",
       "            p_features_extractor_6_6_bn3_bias: PARAMETER target='features_extractor.6.6.bn3.bias'\n",
       "            p_features_extractor_6_7_conv1_weight: PARAMETER target='features_extractor.6.7.conv1.weight'\n",
       "            p_features_extractor_6_7_bn1_weight: PARAMETER target='features_extractor.6.7.bn1.weight'\n",
       "            p_features_extractor_6_7_bn1_bias: PARAMETER target='features_extractor.6.7.bn1.bias'\n",
       "            p_features_extractor_6_7_conv2_weight: PARAMETER target='features_extractor.6.7.conv2.weight'\n",
       "            p_features_extractor_6_7_bn2_weight: PARAMETER target='features_extractor.6.7.bn2.weight'\n",
       "            p_features_extractor_6_7_bn2_bias: PARAMETER target='features_extractor.6.7.bn2.bias'\n",
       "            p_features_extractor_6_7_conv3_weight: PARAMETER target='features_extractor.6.7.conv3.weight'\n",
       "            p_features_extractor_6_7_bn3_weight: PARAMETER target='features_extractor.6.7.bn3.weight'\n",
       "            p_features_extractor_6_7_bn3_bias: PARAMETER target='features_extractor.6.7.bn3.bias'\n",
       "            p_features_extractor_6_8_conv1_weight: PARAMETER target='features_extractor.6.8.conv1.weight'\n",
       "            p_features_extractor_6_8_bn1_weight: PARAMETER target='features_extractor.6.8.bn1.weight'\n",
       "            p_features_extractor_6_8_bn1_bias: PARAMETER target='features_extractor.6.8.bn1.bias'\n",
       "            p_features_extractor_6_8_conv2_weight: PARAMETER target='features_extractor.6.8.conv2.weight'\n",
       "            p_features_extractor_6_8_bn2_weight: PARAMETER target='features_extractor.6.8.bn2.weight'\n",
       "            p_features_extractor_6_8_bn2_bias: PARAMETER target='features_extractor.6.8.bn2.bias'\n",
       "            p_features_extractor_6_8_conv3_weight: PARAMETER target='features_extractor.6.8.conv3.weight'\n",
       "            p_features_extractor_6_8_bn3_weight: PARAMETER target='features_extractor.6.8.bn3.weight'\n",
       "            p_features_extractor_6_8_bn3_bias: PARAMETER target='features_extractor.6.8.bn3.bias'\n",
       "            p_features_extractor_6_9_conv1_weight: PARAMETER target='features_extractor.6.9.conv1.weight'\n",
       "            p_features_extractor_6_9_bn1_weight: PARAMETER target='features_extractor.6.9.bn1.weight'\n",
       "            p_features_extractor_6_9_bn1_bias: PARAMETER target='features_extractor.6.9.bn1.bias'\n",
       "            p_features_extractor_6_9_conv2_weight: PARAMETER target='features_extractor.6.9.conv2.weight'\n",
       "            p_features_extractor_6_9_bn2_weight: PARAMETER target='features_extractor.6.9.bn2.weight'\n",
       "            p_features_extractor_6_9_bn2_bias: PARAMETER target='features_extractor.6.9.bn2.bias'\n",
       "            p_features_extractor_6_9_conv3_weight: PARAMETER target='features_extractor.6.9.conv3.weight'\n",
       "            p_features_extractor_6_9_bn3_weight: PARAMETER target='features_extractor.6.9.bn3.weight'\n",
       "            p_features_extractor_6_9_bn3_bias: PARAMETER target='features_extractor.6.9.bn3.bias'\n",
       "            p_features_extractor_6_10_conv1_weight: PARAMETER target='features_extractor.6.10.conv1.weight'\n",
       "            p_features_extractor_6_10_bn1_weight: PARAMETER target='features_extractor.6.10.bn1.weight'\n",
       "            p_features_extractor_6_10_bn1_bias: PARAMETER target='features_extractor.6.10.bn1.bias'\n",
       "            p_features_extractor_6_10_conv2_weight: PARAMETER target='features_extractor.6.10.conv2.weight'\n",
       "            p_features_extractor_6_10_bn2_weight: PARAMETER target='features_extractor.6.10.bn2.weight'\n",
       "            p_features_extractor_6_10_bn2_bias: PARAMETER target='features_extractor.6.10.bn2.bias'\n",
       "            p_features_extractor_6_10_conv3_weight: PARAMETER target='features_extractor.6.10.conv3.weight'\n",
       "            p_features_extractor_6_10_bn3_weight: PARAMETER target='features_extractor.6.10.bn3.weight'\n",
       "            p_features_extractor_6_10_bn3_bias: PARAMETER target='features_extractor.6.10.bn3.bias'\n",
       "            p_features_extractor_6_11_conv1_weight: PARAMETER target='features_extractor.6.11.conv1.weight'\n",
       "            p_features_extractor_6_11_bn1_weight: PARAMETER target='features_extractor.6.11.bn1.weight'\n",
       "            p_features_extractor_6_11_bn1_bias: PARAMETER target='features_extractor.6.11.bn1.bias'\n",
       "            p_features_extractor_6_11_conv2_weight: PARAMETER target='features_extractor.6.11.conv2.weight'\n",
       "            p_features_extractor_6_11_bn2_weight: PARAMETER target='features_extractor.6.11.bn2.weight'\n",
       "            p_features_extractor_6_11_bn2_bias: PARAMETER target='features_extractor.6.11.bn2.bias'\n",
       "            p_features_extractor_6_11_conv3_weight: PARAMETER target='features_extractor.6.11.conv3.weight'\n",
       "            p_features_extractor_6_11_bn3_weight: PARAMETER target='features_extractor.6.11.bn3.weight'\n",
       "            p_features_extractor_6_11_bn3_bias: PARAMETER target='features_extractor.6.11.bn3.bias'\n",
       "            p_features_extractor_6_12_conv1_weight: PARAMETER target='features_extractor.6.12.conv1.weight'\n",
       "            p_features_extractor_6_12_bn1_weight: PARAMETER target='features_extractor.6.12.bn1.weight'\n",
       "            p_features_extractor_6_12_bn1_bias: PARAMETER target='features_extractor.6.12.bn1.bias'\n",
       "            p_features_extractor_6_12_conv2_weight: PARAMETER target='features_extractor.6.12.conv2.weight'\n",
       "            p_features_extractor_6_12_bn2_weight: PARAMETER target='features_extractor.6.12.bn2.weight'\n",
       "            p_features_extractor_6_12_bn2_bias: PARAMETER target='features_extractor.6.12.bn2.bias'\n",
       "            p_features_extractor_6_12_conv3_weight: PARAMETER target='features_extractor.6.12.conv3.weight'\n",
       "            p_features_extractor_6_12_bn3_weight: PARAMETER target='features_extractor.6.12.bn3.weight'\n",
       "            p_features_extractor_6_12_bn3_bias: PARAMETER target='features_extractor.6.12.bn3.bias'\n",
       "            p_features_extractor_6_13_conv1_weight: PARAMETER target='features_extractor.6.13.conv1.weight'\n",
       "            p_features_extractor_6_13_bn1_weight: PARAMETER target='features_extractor.6.13.bn1.weight'\n",
       "            p_features_extractor_6_13_bn1_bias: PARAMETER target='features_extractor.6.13.bn1.bias'\n",
       "            p_features_extractor_6_13_conv2_weight: PARAMETER target='features_extractor.6.13.conv2.weight'\n",
       "            p_features_extractor_6_13_bn2_weight: PARAMETER target='features_extractor.6.13.bn2.weight'\n",
       "            p_features_extractor_6_13_bn2_bias: PARAMETER target='features_extractor.6.13.bn2.bias'\n",
       "            p_features_extractor_6_13_conv3_weight: PARAMETER target='features_extractor.6.13.conv3.weight'\n",
       "            p_features_extractor_6_13_bn3_weight: PARAMETER target='features_extractor.6.13.bn3.weight'\n",
       "            p_features_extractor_6_13_bn3_bias: PARAMETER target='features_extractor.6.13.bn3.bias'\n",
       "            p_features_extractor_6_14_conv1_weight: PARAMETER target='features_extractor.6.14.conv1.weight'\n",
       "            p_features_extractor_6_14_bn1_weight: PARAMETER target='features_extractor.6.14.bn1.weight'\n",
       "            p_features_extractor_6_14_bn1_bias: PARAMETER target='features_extractor.6.14.bn1.bias'\n",
       "            p_features_extractor_6_14_conv2_weight: PARAMETER target='features_extractor.6.14.conv2.weight'\n",
       "            p_features_extractor_6_14_bn2_weight: PARAMETER target='features_extractor.6.14.bn2.weight'\n",
       "            p_features_extractor_6_14_bn2_bias: PARAMETER target='features_extractor.6.14.bn2.bias'\n",
       "            p_features_extractor_6_14_conv3_weight: PARAMETER target='features_extractor.6.14.conv3.weight'\n",
       "            p_features_extractor_6_14_bn3_weight: PARAMETER target='features_extractor.6.14.bn3.weight'\n",
       "            p_features_extractor_6_14_bn3_bias: PARAMETER target='features_extractor.6.14.bn3.bias'\n",
       "            p_features_extractor_6_15_conv1_weight: PARAMETER target='features_extractor.6.15.conv1.weight'\n",
       "            p_features_extractor_6_15_bn1_weight: PARAMETER target='features_extractor.6.15.bn1.weight'\n",
       "            p_features_extractor_6_15_bn1_bias: PARAMETER target='features_extractor.6.15.bn1.bias'\n",
       "            p_features_extractor_6_15_conv2_weight: PARAMETER target='features_extractor.6.15.conv2.weight'\n",
       "            p_features_extractor_6_15_bn2_weight: PARAMETER target='features_extractor.6.15.bn2.weight'\n",
       "            p_features_extractor_6_15_bn2_bias: PARAMETER target='features_extractor.6.15.bn2.bias'\n",
       "            p_features_extractor_6_15_conv3_weight: PARAMETER target='features_extractor.6.15.conv3.weight'\n",
       "            p_features_extractor_6_15_bn3_weight: PARAMETER target='features_extractor.6.15.bn3.weight'\n",
       "            p_features_extractor_6_15_bn3_bias: PARAMETER target='features_extractor.6.15.bn3.bias'\n",
       "            p_features_extractor_6_16_conv1_weight: PARAMETER target='features_extractor.6.16.conv1.weight'\n",
       "            p_features_extractor_6_16_bn1_weight: PARAMETER target='features_extractor.6.16.bn1.weight'\n",
       "            p_features_extractor_6_16_bn1_bias: PARAMETER target='features_extractor.6.16.bn1.bias'\n",
       "            p_features_extractor_6_16_conv2_weight: PARAMETER target='features_extractor.6.16.conv2.weight'\n",
       "            p_features_extractor_6_16_bn2_weight: PARAMETER target='features_extractor.6.16.bn2.weight'\n",
       "            p_features_extractor_6_16_bn2_bias: PARAMETER target='features_extractor.6.16.bn2.bias'\n",
       "            p_features_extractor_6_16_conv3_weight: PARAMETER target='features_extractor.6.16.conv3.weight'\n",
       "            p_features_extractor_6_16_bn3_weight: PARAMETER target='features_extractor.6.16.bn3.weight'\n",
       "            p_features_extractor_6_16_bn3_bias: PARAMETER target='features_extractor.6.16.bn3.bias'\n",
       "            p_features_extractor_6_17_conv1_weight: PARAMETER target='features_extractor.6.17.conv1.weight'\n",
       "            p_features_extractor_6_17_bn1_weight: PARAMETER target='features_extractor.6.17.bn1.weight'\n",
       "            p_features_extractor_6_17_bn1_bias: PARAMETER target='features_extractor.6.17.bn1.bias'\n",
       "            p_features_extractor_6_17_conv2_weight: PARAMETER target='features_extractor.6.17.conv2.weight'\n",
       "            p_features_extractor_6_17_bn2_weight: PARAMETER target='features_extractor.6.17.bn2.weight'\n",
       "            p_features_extractor_6_17_bn2_bias: PARAMETER target='features_extractor.6.17.bn2.bias'\n",
       "            p_features_extractor_6_17_conv3_weight: PARAMETER target='features_extractor.6.17.conv3.weight'\n",
       "            p_features_extractor_6_17_bn3_weight: PARAMETER target='features_extractor.6.17.bn3.weight'\n",
       "            p_features_extractor_6_17_bn3_bias: PARAMETER target='features_extractor.6.17.bn3.bias'\n",
       "            p_features_extractor_6_18_conv1_weight: PARAMETER target='features_extractor.6.18.conv1.weight'\n",
       "            p_features_extractor_6_18_bn1_weight: PARAMETER target='features_extractor.6.18.bn1.weight'\n",
       "            p_features_extractor_6_18_bn1_bias: PARAMETER target='features_extractor.6.18.bn1.bias'\n",
       "            p_features_extractor_6_18_conv2_weight: PARAMETER target='features_extractor.6.18.conv2.weight'\n",
       "            p_features_extractor_6_18_bn2_weight: PARAMETER target='features_extractor.6.18.bn2.weight'\n",
       "            p_features_extractor_6_18_bn2_bias: PARAMETER target='features_extractor.6.18.bn2.bias'\n",
       "            p_features_extractor_6_18_conv3_weight: PARAMETER target='features_extractor.6.18.conv3.weight'\n",
       "            p_features_extractor_6_18_bn3_weight: PARAMETER target='features_extractor.6.18.bn3.weight'\n",
       "            p_features_extractor_6_18_bn3_bias: PARAMETER target='features_extractor.6.18.bn3.bias'\n",
       "            p_features_extractor_6_19_conv1_weight: PARAMETER target='features_extractor.6.19.conv1.weight'\n",
       "            p_features_extractor_6_19_bn1_weight: PARAMETER target='features_extractor.6.19.bn1.weight'\n",
       "            p_features_extractor_6_19_bn1_bias: PARAMETER target='features_extractor.6.19.bn1.bias'\n",
       "            p_features_extractor_6_19_conv2_weight: PARAMETER target='features_extractor.6.19.conv2.weight'\n",
       "            p_features_extractor_6_19_bn2_weight: PARAMETER target='features_extractor.6.19.bn2.weight'\n",
       "            p_features_extractor_6_19_bn2_bias: PARAMETER target='features_extractor.6.19.bn2.bias'\n",
       "            p_features_extractor_6_19_conv3_weight: PARAMETER target='features_extractor.6.19.conv3.weight'\n",
       "            p_features_extractor_6_19_bn3_weight: PARAMETER target='features_extractor.6.19.bn3.weight'\n",
       "            p_features_extractor_6_19_bn3_bias: PARAMETER target='features_extractor.6.19.bn3.bias'\n",
       "            p_features_extractor_6_20_conv1_weight: PARAMETER target='features_extractor.6.20.conv1.weight'\n",
       "            p_features_extractor_6_20_bn1_weight: PARAMETER target='features_extractor.6.20.bn1.weight'\n",
       "            p_features_extractor_6_20_bn1_bias: PARAMETER target='features_extractor.6.20.bn1.bias'\n",
       "            p_features_extractor_6_20_conv2_weight: PARAMETER target='features_extractor.6.20.conv2.weight'\n",
       "            p_features_extractor_6_20_bn2_weight: PARAMETER target='features_extractor.6.20.bn2.weight'\n",
       "            p_features_extractor_6_20_bn2_bias: PARAMETER target='features_extractor.6.20.bn2.bias'\n",
       "            p_features_extractor_6_20_conv3_weight: PARAMETER target='features_extractor.6.20.conv3.weight'\n",
       "            p_features_extractor_6_20_bn3_weight: PARAMETER target='features_extractor.6.20.bn3.weight'\n",
       "            p_features_extractor_6_20_bn3_bias: PARAMETER target='features_extractor.6.20.bn3.bias'\n",
       "            p_features_extractor_6_21_conv1_weight: PARAMETER target='features_extractor.6.21.conv1.weight'\n",
       "            p_features_extractor_6_21_bn1_weight: PARAMETER target='features_extractor.6.21.bn1.weight'\n",
       "            p_features_extractor_6_21_bn1_bias: PARAMETER target='features_extractor.6.21.bn1.bias'\n",
       "            p_features_extractor_6_21_conv2_weight: PARAMETER target='features_extractor.6.21.conv2.weight'\n",
       "            p_features_extractor_6_21_bn2_weight: PARAMETER target='features_extractor.6.21.bn2.weight'\n",
       "            p_features_extractor_6_21_bn2_bias: PARAMETER target='features_extractor.6.21.bn2.bias'\n",
       "            p_features_extractor_6_21_conv3_weight: PARAMETER target='features_extractor.6.21.conv3.weight'\n",
       "            p_features_extractor_6_21_bn3_weight: PARAMETER target='features_extractor.6.21.bn3.weight'\n",
       "            p_features_extractor_6_21_bn3_bias: PARAMETER target='features_extractor.6.21.bn3.bias'\n",
       "            p_features_extractor_6_22_conv1_weight: PARAMETER target='features_extractor.6.22.conv1.weight'\n",
       "            p_features_extractor_6_22_bn1_weight: PARAMETER target='features_extractor.6.22.bn1.weight'\n",
       "            p_features_extractor_6_22_bn1_bias: PARAMETER target='features_extractor.6.22.bn1.bias'\n",
       "            p_features_extractor_6_22_conv2_weight: PARAMETER target='features_extractor.6.22.conv2.weight'\n",
       "            p_features_extractor_6_22_bn2_weight: PARAMETER target='features_extractor.6.22.bn2.weight'\n",
       "            p_features_extractor_6_22_bn2_bias: PARAMETER target='features_extractor.6.22.bn2.bias'\n",
       "            p_features_extractor_6_22_conv3_weight: PARAMETER target='features_extractor.6.22.conv3.weight'\n",
       "            p_features_extractor_6_22_bn3_weight: PARAMETER target='features_extractor.6.22.bn3.weight'\n",
       "            p_features_extractor_6_22_bn3_bias: PARAMETER target='features_extractor.6.22.bn3.bias'\n",
       "            p_features_extractor_6_23_conv1_weight: PARAMETER target='features_extractor.6.23.conv1.weight'\n",
       "            p_features_extractor_6_23_bn1_weight: PARAMETER target='features_extractor.6.23.bn1.weight'\n",
       "            p_features_extractor_6_23_bn1_bias: PARAMETER target='features_extractor.6.23.bn1.bias'\n",
       "            p_features_extractor_6_23_conv2_weight: PARAMETER target='features_extractor.6.23.conv2.weight'\n",
       "            p_features_extractor_6_23_bn2_weight: PARAMETER target='features_extractor.6.23.bn2.weight'\n",
       "            p_features_extractor_6_23_bn2_bias: PARAMETER target='features_extractor.6.23.bn2.bias'\n",
       "            p_features_extractor_6_23_conv3_weight: PARAMETER target='features_extractor.6.23.conv3.weight'\n",
       "            p_features_extractor_6_23_bn3_weight: PARAMETER target='features_extractor.6.23.bn3.weight'\n",
       "            p_features_extractor_6_23_bn3_bias: PARAMETER target='features_extractor.6.23.bn3.bias'\n",
       "            p_features_extractor_6_24_conv1_weight: PARAMETER target='features_extractor.6.24.conv1.weight'\n",
       "            p_features_extractor_6_24_bn1_weight: PARAMETER target='features_extractor.6.24.bn1.weight'\n",
       "            p_features_extractor_6_24_bn1_bias: PARAMETER target='features_extractor.6.24.bn1.bias'\n",
       "            p_features_extractor_6_24_conv2_weight: PARAMETER target='features_extractor.6.24.conv2.weight'\n",
       "            p_features_extractor_6_24_bn2_weight: PARAMETER target='features_extractor.6.24.bn2.weight'\n",
       "            p_features_extractor_6_24_bn2_bias: PARAMETER target='features_extractor.6.24.bn2.bias'\n",
       "            p_features_extractor_6_24_conv3_weight: PARAMETER target='features_extractor.6.24.conv3.weight'\n",
       "            p_features_extractor_6_24_bn3_weight: PARAMETER target='features_extractor.6.24.bn3.weight'\n",
       "            p_features_extractor_6_24_bn3_bias: PARAMETER target='features_extractor.6.24.bn3.bias'\n",
       "            p_features_extractor_6_25_conv1_weight: PARAMETER target='features_extractor.6.25.conv1.weight'\n",
       "            p_features_extractor_6_25_bn1_weight: PARAMETER target='features_extractor.6.25.bn1.weight'\n",
       "            p_features_extractor_6_25_bn1_bias: PARAMETER target='features_extractor.6.25.bn1.bias'\n",
       "            p_features_extractor_6_25_conv2_weight: PARAMETER target='features_extractor.6.25.conv2.weight'\n",
       "            p_features_extractor_6_25_bn2_weight: PARAMETER target='features_extractor.6.25.bn2.weight'\n",
       "            p_features_extractor_6_25_bn2_bias: PARAMETER target='features_extractor.6.25.bn2.bias'\n",
       "            p_features_extractor_6_25_conv3_weight: PARAMETER target='features_extractor.6.25.conv3.weight'\n",
       "            p_features_extractor_6_25_bn3_weight: PARAMETER target='features_extractor.6.25.bn3.weight'\n",
       "            p_features_extractor_6_25_bn3_bias: PARAMETER target='features_extractor.6.25.bn3.bias'\n",
       "            p_features_extractor_6_26_conv1_weight: PARAMETER target='features_extractor.6.26.conv1.weight'\n",
       "            p_features_extractor_6_26_bn1_weight: PARAMETER target='features_extractor.6.26.bn1.weight'\n",
       "            p_features_extractor_6_26_bn1_bias: PARAMETER target='features_extractor.6.26.bn1.bias'\n",
       "            p_features_extractor_6_26_conv2_weight: PARAMETER target='features_extractor.6.26.conv2.weight'\n",
       "            p_features_extractor_6_26_bn2_weight: PARAMETER target='features_extractor.6.26.bn2.weight'\n",
       "            p_features_extractor_6_26_bn2_bias: PARAMETER target='features_extractor.6.26.bn2.bias'\n",
       "            p_features_extractor_6_26_conv3_weight: PARAMETER target='features_extractor.6.26.conv3.weight'\n",
       "            p_features_extractor_6_26_bn3_weight: PARAMETER target='features_extractor.6.26.bn3.weight'\n",
       "            p_features_extractor_6_26_bn3_bias: PARAMETER target='features_extractor.6.26.bn3.bias'\n",
       "            p_features_extractor_6_27_conv1_weight: PARAMETER target='features_extractor.6.27.conv1.weight'\n",
       "            p_features_extractor_6_27_bn1_weight: PARAMETER target='features_extractor.6.27.bn1.weight'\n",
       "            p_features_extractor_6_27_bn1_bias: PARAMETER target='features_extractor.6.27.bn1.bias'\n",
       "            p_features_extractor_6_27_conv2_weight: PARAMETER target='features_extractor.6.27.conv2.weight'\n",
       "            p_features_extractor_6_27_bn2_weight: PARAMETER target='features_extractor.6.27.bn2.weight'\n",
       "            p_features_extractor_6_27_bn2_bias: PARAMETER target='features_extractor.6.27.bn2.bias'\n",
       "            p_features_extractor_6_27_conv3_weight: PARAMETER target='features_extractor.6.27.conv3.weight'\n",
       "            p_features_extractor_6_27_bn3_weight: PARAMETER target='features_extractor.6.27.bn3.weight'\n",
       "            p_features_extractor_6_27_bn3_bias: PARAMETER target='features_extractor.6.27.bn3.bias'\n",
       "            p_features_extractor_6_28_conv1_weight: PARAMETER target='features_extractor.6.28.conv1.weight'\n",
       "            p_features_extractor_6_28_bn1_weight: PARAMETER target='features_extractor.6.28.bn1.weight'\n",
       "            p_features_extractor_6_28_bn1_bias: PARAMETER target='features_extractor.6.28.bn1.bias'\n",
       "            p_features_extractor_6_28_conv2_weight: PARAMETER target='features_extractor.6.28.conv2.weight'\n",
       "            p_features_extractor_6_28_bn2_weight: PARAMETER target='features_extractor.6.28.bn2.weight'\n",
       "            p_features_extractor_6_28_bn2_bias: PARAMETER target='features_extractor.6.28.bn2.bias'\n",
       "            p_features_extractor_6_28_conv3_weight: PARAMETER target='features_extractor.6.28.conv3.weight'\n",
       "            p_features_extractor_6_28_bn3_weight: PARAMETER target='features_extractor.6.28.bn3.weight'\n",
       "            p_features_extractor_6_28_bn3_bias: PARAMETER target='features_extractor.6.28.bn3.bias'\n",
       "            p_features_extractor_6_29_conv1_weight: PARAMETER target='features_extractor.6.29.conv1.weight'\n",
       "            p_features_extractor_6_29_bn1_weight: PARAMETER target='features_extractor.6.29.bn1.weight'\n",
       "            p_features_extractor_6_29_bn1_bias: PARAMETER target='features_extractor.6.29.bn1.bias'\n",
       "            p_features_extractor_6_29_conv2_weight: PARAMETER target='features_extractor.6.29.conv2.weight'\n",
       "            p_features_extractor_6_29_bn2_weight: PARAMETER target='features_extractor.6.29.bn2.weight'\n",
       "            p_features_extractor_6_29_bn2_bias: PARAMETER target='features_extractor.6.29.bn2.bias'\n",
       "            p_features_extractor_6_29_conv3_weight: PARAMETER target='features_extractor.6.29.conv3.weight'\n",
       "            p_features_extractor_6_29_bn3_weight: PARAMETER target='features_extractor.6.29.bn3.weight'\n",
       "            p_features_extractor_6_29_bn3_bias: PARAMETER target='features_extractor.6.29.bn3.bias'\n",
       "            p_features_extractor_6_30_conv1_weight: PARAMETER target='features_extractor.6.30.conv1.weight'\n",
       "            p_features_extractor_6_30_bn1_weight: PARAMETER target='features_extractor.6.30.bn1.weight'\n",
       "            p_features_extractor_6_30_bn1_bias: PARAMETER target='features_extractor.6.30.bn1.bias'\n",
       "            p_features_extractor_6_30_conv2_weight: PARAMETER target='features_extractor.6.30.conv2.weight'\n",
       "            p_features_extractor_6_30_bn2_weight: PARAMETER target='features_extractor.6.30.bn2.weight'\n",
       "            p_features_extractor_6_30_bn2_bias: PARAMETER target='features_extractor.6.30.bn2.bias'\n",
       "            p_features_extractor_6_30_conv3_weight: PARAMETER target='features_extractor.6.30.conv3.weight'\n",
       "            p_features_extractor_6_30_bn3_weight: PARAMETER target='features_extractor.6.30.bn3.weight'\n",
       "            p_features_extractor_6_30_bn3_bias: PARAMETER target='features_extractor.6.30.bn3.bias'\n",
       "            p_features_extractor_6_31_conv1_weight: PARAMETER target='features_extractor.6.31.conv1.weight'\n",
       "            p_features_extractor_6_31_bn1_weight: PARAMETER target='features_extractor.6.31.bn1.weight'\n",
       "            p_features_extractor_6_31_bn1_bias: PARAMETER target='features_extractor.6.31.bn1.bias'\n",
       "            p_features_extractor_6_31_conv2_weight: PARAMETER target='features_extractor.6.31.conv2.weight'\n",
       "            p_features_extractor_6_31_bn2_weight: PARAMETER target='features_extractor.6.31.bn2.weight'\n",
       "            p_features_extractor_6_31_bn2_bias: PARAMETER target='features_extractor.6.31.bn2.bias'\n",
       "            p_features_extractor_6_31_conv3_weight: PARAMETER target='features_extractor.6.31.conv3.weight'\n",
       "            p_features_extractor_6_31_bn3_weight: PARAMETER target='features_extractor.6.31.bn3.weight'\n",
       "            p_features_extractor_6_31_bn3_bias: PARAMETER target='features_extractor.6.31.bn3.bias'\n",
       "            p_features_extractor_6_32_conv1_weight: PARAMETER target='features_extractor.6.32.conv1.weight'\n",
       "            p_features_extractor_6_32_bn1_weight: PARAMETER target='features_extractor.6.32.bn1.weight'\n",
       "            p_features_extractor_6_32_bn1_bias: PARAMETER target='features_extractor.6.32.bn1.bias'\n",
       "            p_features_extractor_6_32_conv2_weight: PARAMETER target='features_extractor.6.32.conv2.weight'\n",
       "            p_features_extractor_6_32_bn2_weight: PARAMETER target='features_extractor.6.32.bn2.weight'\n",
       "            p_features_extractor_6_32_bn2_bias: PARAMETER target='features_extractor.6.32.bn2.bias'\n",
       "            p_features_extractor_6_32_conv3_weight: PARAMETER target='features_extractor.6.32.conv3.weight'\n",
       "            p_features_extractor_6_32_bn3_weight: PARAMETER target='features_extractor.6.32.bn3.weight'\n",
       "            p_features_extractor_6_32_bn3_bias: PARAMETER target='features_extractor.6.32.bn3.bias'\n",
       "            p_features_extractor_6_33_conv1_weight: PARAMETER target='features_extractor.6.33.conv1.weight'\n",
       "            p_features_extractor_6_33_bn1_weight: PARAMETER target='features_extractor.6.33.bn1.weight'\n",
       "            p_features_extractor_6_33_bn1_bias: PARAMETER target='features_extractor.6.33.bn1.bias'\n",
       "            p_features_extractor_6_33_conv2_weight: PARAMETER target='features_extractor.6.33.conv2.weight'\n",
       "            p_features_extractor_6_33_bn2_weight: PARAMETER target='features_extractor.6.33.bn2.weight'\n",
       "            p_features_extractor_6_33_bn2_bias: PARAMETER target='features_extractor.6.33.bn2.bias'\n",
       "            p_features_extractor_6_33_conv3_weight: PARAMETER target='features_extractor.6.33.conv3.weight'\n",
       "            p_features_extractor_6_33_bn3_weight: PARAMETER target='features_extractor.6.33.bn3.weight'\n",
       "            p_features_extractor_6_33_bn3_bias: PARAMETER target='features_extractor.6.33.bn3.bias'\n",
       "            p_features_extractor_6_34_conv1_weight: PARAMETER target='features_extractor.6.34.conv1.weight'\n",
       "            p_features_extractor_6_34_bn1_weight: PARAMETER target='features_extractor.6.34.bn1.weight'\n",
       "            p_features_extractor_6_34_bn1_bias: PARAMETER target='features_extractor.6.34.bn1.bias'\n",
       "            p_features_extractor_6_34_conv2_weight: PARAMETER target='features_extractor.6.34.conv2.weight'\n",
       "            p_features_extractor_6_34_bn2_weight: PARAMETER target='features_extractor.6.34.bn2.weight'\n",
       "            p_features_extractor_6_34_bn2_bias: PARAMETER target='features_extractor.6.34.bn2.bias'\n",
       "            p_features_extractor_6_34_conv3_weight: PARAMETER target='features_extractor.6.34.conv3.weight'\n",
       "            p_features_extractor_6_34_bn3_weight: PARAMETER target='features_extractor.6.34.bn3.weight'\n",
       "            p_features_extractor_6_34_bn3_bias: PARAMETER target='features_extractor.6.34.bn3.bias'\n",
       "            p_features_extractor_6_35_conv1_weight: PARAMETER target='features_extractor.6.35.conv1.weight'\n",
       "            p_features_extractor_6_35_bn1_weight: PARAMETER target='features_extractor.6.35.bn1.weight'\n",
       "            p_features_extractor_6_35_bn1_bias: PARAMETER target='features_extractor.6.35.bn1.bias'\n",
       "            p_features_extractor_6_35_conv2_weight: PARAMETER target='features_extractor.6.35.conv2.weight'\n",
       "            p_features_extractor_6_35_bn2_weight: PARAMETER target='features_extractor.6.35.bn2.weight'\n",
       "            p_features_extractor_6_35_bn2_bias: PARAMETER target='features_extractor.6.35.bn2.bias'\n",
       "            p_features_extractor_6_35_conv3_weight: PARAMETER target='features_extractor.6.35.conv3.weight'\n",
       "            p_features_extractor_6_35_bn3_weight: PARAMETER target='features_extractor.6.35.bn3.weight'\n",
       "            p_features_extractor_6_35_bn3_bias: PARAMETER target='features_extractor.6.35.bn3.bias'\n",
       "            p_features_extractor_7_0_conv1_weight: PARAMETER target='features_extractor.7.0.conv1.weight'\n",
       "            p_features_extractor_7_0_bn1_weight: PARAMETER target='features_extractor.7.0.bn1.weight'\n",
       "            p_features_extractor_7_0_bn1_bias: PARAMETER target='features_extractor.7.0.bn1.bias'\n",
       "            p_features_extractor_7_0_conv2_weight: PARAMETER target='features_extractor.7.0.conv2.weight'\n",
       "            p_features_extractor_7_0_bn2_weight: PARAMETER target='features_extractor.7.0.bn2.weight'\n",
       "            p_features_extractor_7_0_bn2_bias: PARAMETER target='features_extractor.7.0.bn2.bias'\n",
       "            p_features_extractor_7_0_conv3_weight: PARAMETER target='features_extractor.7.0.conv3.weight'\n",
       "            p_features_extractor_7_0_bn3_weight: PARAMETER target='features_extractor.7.0.bn3.weight'\n",
       "            p_features_extractor_7_0_bn3_bias: PARAMETER target='features_extractor.7.0.bn3.bias'\n",
       "            p_features_extractor_7_0_downsample_0_weight: PARAMETER target='features_extractor.7.0.downsample.0.weight'\n",
       "            p_features_extractor_7_0_downsample_1_weight: PARAMETER target='features_extractor.7.0.downsample.1.weight'\n",
       "            p_features_extractor_7_0_downsample_1_bias: PARAMETER target='features_extractor.7.0.downsample.1.bias'\n",
       "            p_features_extractor_7_1_conv1_weight: PARAMETER target='features_extractor.7.1.conv1.weight'\n",
       "            p_features_extractor_7_1_bn1_weight: PARAMETER target='features_extractor.7.1.bn1.weight'\n",
       "            p_features_extractor_7_1_bn1_bias: PARAMETER target='features_extractor.7.1.bn1.bias'\n",
       "            p_features_extractor_7_1_conv2_weight: PARAMETER target='features_extractor.7.1.conv2.weight'\n",
       "            p_features_extractor_7_1_bn2_weight: PARAMETER target='features_extractor.7.1.bn2.weight'\n",
       "            p_features_extractor_7_1_bn2_bias: PARAMETER target='features_extractor.7.1.bn2.bias'\n",
       "            p_features_extractor_7_1_conv3_weight: PARAMETER target='features_extractor.7.1.conv3.weight'\n",
       "            p_features_extractor_7_1_bn3_weight: PARAMETER target='features_extractor.7.1.bn3.weight'\n",
       "            p_features_extractor_7_1_bn3_bias: PARAMETER target='features_extractor.7.1.bn3.bias'\n",
       "            p_features_extractor_7_2_conv1_weight: PARAMETER target='features_extractor.7.2.conv1.weight'\n",
       "            p_features_extractor_7_2_bn1_weight: PARAMETER target='features_extractor.7.2.bn1.weight'\n",
       "            p_features_extractor_7_2_bn1_bias: PARAMETER target='features_extractor.7.2.bn1.bias'\n",
       "            p_features_extractor_7_2_conv2_weight: PARAMETER target='features_extractor.7.2.conv2.weight'\n",
       "            p_features_extractor_7_2_bn2_weight: PARAMETER target='features_extractor.7.2.bn2.weight'\n",
       "            p_features_extractor_7_2_bn2_bias: PARAMETER target='features_extractor.7.2.bn2.bias'\n",
       "            p_features_extractor_7_2_conv3_weight: PARAMETER target='features_extractor.7.2.conv3.weight'\n",
       "            p_features_extractor_7_2_bn3_weight: PARAMETER target='features_extractor.7.2.bn3.weight'\n",
       "            p_features_extractor_7_2_bn3_bias: PARAMETER target='features_extractor.7.2.bn3.bias'\n",
       "            p_output_layer_weight: PARAMETER target='output_layer.weight'\n",
       "            p_output_layer_bias: PARAMETER target='output_layer.bias'\n",
       "            b_base_model_bn1_running_mean: BUFFER target='base_model.bn1.running_mean' persistent=True\n",
       "            b_base_model_bn1_running_var: BUFFER target='base_model.bn1.running_var' persistent=True\n",
       "            b_base_model_bn1_num_batches_tracked: BUFFER target='base_model.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_0_bn1_running_mean: BUFFER target='base_model.layer1.0.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer1_0_bn1_running_var: BUFFER target='base_model.layer1.0.bn1.running_var' persistent=True\n",
       "            b_base_model_layer1_0_bn1_num_batches_tracked: BUFFER target='base_model.layer1.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_0_bn2_running_mean: BUFFER target='base_model.layer1.0.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer1_0_bn2_running_var: BUFFER target='base_model.layer1.0.bn2.running_var' persistent=True\n",
       "            b_base_model_layer1_0_bn2_num_batches_tracked: BUFFER target='base_model.layer1.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_0_bn3_running_mean: BUFFER target='base_model.layer1.0.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer1_0_bn3_running_var: BUFFER target='base_model.layer1.0.bn3.running_var' persistent=True\n",
       "            b_base_model_layer1_0_bn3_num_batches_tracked: BUFFER target='base_model.layer1.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_0_downsample_1_running_mean: BUFFER target='base_model.layer1.0.downsample.1.running_mean' persistent=True\n",
       "            b_base_model_layer1_0_downsample_1_running_var: BUFFER target='base_model.layer1.0.downsample.1.running_var' persistent=True\n",
       "            b_base_model_layer1_0_downsample_1_num_batches_tracked: BUFFER target='base_model.layer1.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_1_bn1_running_mean: BUFFER target='base_model.layer1.1.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer1_1_bn1_running_var: BUFFER target='base_model.layer1.1.bn1.running_var' persistent=True\n",
       "            b_base_model_layer1_1_bn1_num_batches_tracked: BUFFER target='base_model.layer1.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_1_bn2_running_mean: BUFFER target='base_model.layer1.1.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer1_1_bn2_running_var: BUFFER target='base_model.layer1.1.bn2.running_var' persistent=True\n",
       "            b_base_model_layer1_1_bn2_num_batches_tracked: BUFFER target='base_model.layer1.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_1_bn3_running_mean: BUFFER target='base_model.layer1.1.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer1_1_bn3_running_var: BUFFER target='base_model.layer1.1.bn3.running_var' persistent=True\n",
       "            b_base_model_layer1_1_bn3_num_batches_tracked: BUFFER target='base_model.layer1.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_2_bn1_running_mean: BUFFER target='base_model.layer1.2.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer1_2_bn1_running_var: BUFFER target='base_model.layer1.2.bn1.running_var' persistent=True\n",
       "            b_base_model_layer1_2_bn1_num_batches_tracked: BUFFER target='base_model.layer1.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_2_bn2_running_mean: BUFFER target='base_model.layer1.2.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer1_2_bn2_running_var: BUFFER target='base_model.layer1.2.bn2.running_var' persistent=True\n",
       "            b_base_model_layer1_2_bn2_num_batches_tracked: BUFFER target='base_model.layer1.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer1_2_bn3_running_mean: BUFFER target='base_model.layer1.2.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer1_2_bn3_running_var: BUFFER target='base_model.layer1.2.bn3.running_var' persistent=True\n",
       "            b_base_model_layer1_2_bn3_num_batches_tracked: BUFFER target='base_model.layer1.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_0_bn1_running_mean: BUFFER target='base_model.layer2.0.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_0_bn1_running_var: BUFFER target='base_model.layer2.0.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_0_bn1_num_batches_tracked: BUFFER target='base_model.layer2.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_0_bn2_running_mean: BUFFER target='base_model.layer2.0.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_0_bn2_running_var: BUFFER target='base_model.layer2.0.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_0_bn2_num_batches_tracked: BUFFER target='base_model.layer2.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_0_bn3_running_mean: BUFFER target='base_model.layer2.0.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_0_bn3_running_var: BUFFER target='base_model.layer2.0.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_0_bn3_num_batches_tracked: BUFFER target='base_model.layer2.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_0_downsample_1_running_mean: BUFFER target='base_model.layer2.0.downsample.1.running_mean' persistent=True\n",
       "            b_base_model_layer2_0_downsample_1_running_var: BUFFER target='base_model.layer2.0.downsample.1.running_var' persistent=True\n",
       "            b_base_model_layer2_0_downsample_1_num_batches_tracked: BUFFER target='base_model.layer2.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_1_bn1_running_mean: BUFFER target='base_model.layer2.1.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_1_bn1_running_var: BUFFER target='base_model.layer2.1.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_1_bn1_num_batches_tracked: BUFFER target='base_model.layer2.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_1_bn2_running_mean: BUFFER target='base_model.layer2.1.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_1_bn2_running_var: BUFFER target='base_model.layer2.1.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_1_bn2_num_batches_tracked: BUFFER target='base_model.layer2.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_1_bn3_running_mean: BUFFER target='base_model.layer2.1.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_1_bn3_running_var: BUFFER target='base_model.layer2.1.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_1_bn3_num_batches_tracked: BUFFER target='base_model.layer2.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_2_bn1_running_mean: BUFFER target='base_model.layer2.2.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_2_bn1_running_var: BUFFER target='base_model.layer2.2.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_2_bn1_num_batches_tracked: BUFFER target='base_model.layer2.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_2_bn2_running_mean: BUFFER target='base_model.layer2.2.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_2_bn2_running_var: BUFFER target='base_model.layer2.2.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_2_bn2_num_batches_tracked: BUFFER target='base_model.layer2.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_2_bn3_running_mean: BUFFER target='base_model.layer2.2.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_2_bn3_running_var: BUFFER target='base_model.layer2.2.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_2_bn3_num_batches_tracked: BUFFER target='base_model.layer2.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_3_bn1_running_mean: BUFFER target='base_model.layer2.3.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_3_bn1_running_var: BUFFER target='base_model.layer2.3.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_3_bn1_num_batches_tracked: BUFFER target='base_model.layer2.3.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_3_bn2_running_mean: BUFFER target='base_model.layer2.3.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_3_bn2_running_var: BUFFER target='base_model.layer2.3.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_3_bn2_num_batches_tracked: BUFFER target='base_model.layer2.3.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_3_bn3_running_mean: BUFFER target='base_model.layer2.3.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_3_bn3_running_var: BUFFER target='base_model.layer2.3.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_3_bn3_num_batches_tracked: BUFFER target='base_model.layer2.3.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_4_bn1_running_mean: BUFFER target='base_model.layer2.4.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_4_bn1_running_var: BUFFER target='base_model.layer2.4.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_4_bn1_num_batches_tracked: BUFFER target='base_model.layer2.4.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_4_bn2_running_mean: BUFFER target='base_model.layer2.4.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_4_bn2_running_var: BUFFER target='base_model.layer2.4.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_4_bn2_num_batches_tracked: BUFFER target='base_model.layer2.4.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_4_bn3_running_mean: BUFFER target='base_model.layer2.4.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_4_bn3_running_var: BUFFER target='base_model.layer2.4.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_4_bn3_num_batches_tracked: BUFFER target='base_model.layer2.4.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_5_bn1_running_mean: BUFFER target='base_model.layer2.5.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_5_bn1_running_var: BUFFER target='base_model.layer2.5.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_5_bn1_num_batches_tracked: BUFFER target='base_model.layer2.5.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_5_bn2_running_mean: BUFFER target='base_model.layer2.5.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_5_bn2_running_var: BUFFER target='base_model.layer2.5.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_5_bn2_num_batches_tracked: BUFFER target='base_model.layer2.5.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_5_bn3_running_mean: BUFFER target='base_model.layer2.5.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_5_bn3_running_var: BUFFER target='base_model.layer2.5.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_5_bn3_num_batches_tracked: BUFFER target='base_model.layer2.5.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_6_bn1_running_mean: BUFFER target='base_model.layer2.6.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_6_bn1_running_var: BUFFER target='base_model.layer2.6.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_6_bn1_num_batches_tracked: BUFFER target='base_model.layer2.6.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_6_bn2_running_mean: BUFFER target='base_model.layer2.6.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_6_bn2_running_var: BUFFER target='base_model.layer2.6.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_6_bn2_num_batches_tracked: BUFFER target='base_model.layer2.6.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_6_bn3_running_mean: BUFFER target='base_model.layer2.6.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_6_bn3_running_var: BUFFER target='base_model.layer2.6.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_6_bn3_num_batches_tracked: BUFFER target='base_model.layer2.6.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_7_bn1_running_mean: BUFFER target='base_model.layer2.7.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer2_7_bn1_running_var: BUFFER target='base_model.layer2.7.bn1.running_var' persistent=True\n",
       "            b_base_model_layer2_7_bn1_num_batches_tracked: BUFFER target='base_model.layer2.7.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_7_bn2_running_mean: BUFFER target='base_model.layer2.7.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer2_7_bn2_running_var: BUFFER target='base_model.layer2.7.bn2.running_var' persistent=True\n",
       "            b_base_model_layer2_7_bn2_num_batches_tracked: BUFFER target='base_model.layer2.7.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer2_7_bn3_running_mean: BUFFER target='base_model.layer2.7.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer2_7_bn3_running_var: BUFFER target='base_model.layer2.7.bn3.running_var' persistent=True\n",
       "            b_base_model_layer2_7_bn3_num_batches_tracked: BUFFER target='base_model.layer2.7.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_0_bn1_running_mean: BUFFER target='base_model.layer3.0.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_0_bn1_running_var: BUFFER target='base_model.layer3.0.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_0_bn1_num_batches_tracked: BUFFER target='base_model.layer3.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_0_bn2_running_mean: BUFFER target='base_model.layer3.0.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_0_bn2_running_var: BUFFER target='base_model.layer3.0.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_0_bn2_num_batches_tracked: BUFFER target='base_model.layer3.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_0_bn3_running_mean: BUFFER target='base_model.layer3.0.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_0_bn3_running_var: BUFFER target='base_model.layer3.0.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_0_bn3_num_batches_tracked: BUFFER target='base_model.layer3.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_0_downsample_1_running_mean: BUFFER target='base_model.layer3.0.downsample.1.running_mean' persistent=True\n",
       "            b_base_model_layer3_0_downsample_1_running_var: BUFFER target='base_model.layer3.0.downsample.1.running_var' persistent=True\n",
       "            b_base_model_layer3_0_downsample_1_num_batches_tracked: BUFFER target='base_model.layer3.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_1_bn1_running_mean: BUFFER target='base_model.layer3.1.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_1_bn1_running_var: BUFFER target='base_model.layer3.1.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_1_bn1_num_batches_tracked: BUFFER target='base_model.layer3.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_1_bn2_running_mean: BUFFER target='base_model.layer3.1.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_1_bn2_running_var: BUFFER target='base_model.layer3.1.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_1_bn2_num_batches_tracked: BUFFER target='base_model.layer3.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_1_bn3_running_mean: BUFFER target='base_model.layer3.1.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_1_bn3_running_var: BUFFER target='base_model.layer3.1.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_1_bn3_num_batches_tracked: BUFFER target='base_model.layer3.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_2_bn1_running_mean: BUFFER target='base_model.layer3.2.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_2_bn1_running_var: BUFFER target='base_model.layer3.2.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_2_bn1_num_batches_tracked: BUFFER target='base_model.layer3.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_2_bn2_running_mean: BUFFER target='base_model.layer3.2.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_2_bn2_running_var: BUFFER target='base_model.layer3.2.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_2_bn2_num_batches_tracked: BUFFER target='base_model.layer3.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_2_bn3_running_mean: BUFFER target='base_model.layer3.2.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_2_bn3_running_var: BUFFER target='base_model.layer3.2.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_2_bn3_num_batches_tracked: BUFFER target='base_model.layer3.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_3_bn1_running_mean: BUFFER target='base_model.layer3.3.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_3_bn1_running_var: BUFFER target='base_model.layer3.3.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_3_bn1_num_batches_tracked: BUFFER target='base_model.layer3.3.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_3_bn2_running_mean: BUFFER target='base_model.layer3.3.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_3_bn2_running_var: BUFFER target='base_model.layer3.3.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_3_bn2_num_batches_tracked: BUFFER target='base_model.layer3.3.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_3_bn3_running_mean: BUFFER target='base_model.layer3.3.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_3_bn3_running_var: BUFFER target='base_model.layer3.3.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_3_bn3_num_batches_tracked: BUFFER target='base_model.layer3.3.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_4_bn1_running_mean: BUFFER target='base_model.layer3.4.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_4_bn1_running_var: BUFFER target='base_model.layer3.4.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_4_bn1_num_batches_tracked: BUFFER target='base_model.layer3.4.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_4_bn2_running_mean: BUFFER target='base_model.layer3.4.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_4_bn2_running_var: BUFFER target='base_model.layer3.4.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_4_bn2_num_batches_tracked: BUFFER target='base_model.layer3.4.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_4_bn3_running_mean: BUFFER target='base_model.layer3.4.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_4_bn3_running_var: BUFFER target='base_model.layer3.4.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_4_bn3_num_batches_tracked: BUFFER target='base_model.layer3.4.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_5_bn1_running_mean: BUFFER target='base_model.layer3.5.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_5_bn1_running_var: BUFFER target='base_model.layer3.5.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_5_bn1_num_batches_tracked: BUFFER target='base_model.layer3.5.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_5_bn2_running_mean: BUFFER target='base_model.layer3.5.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_5_bn2_running_var: BUFFER target='base_model.layer3.5.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_5_bn2_num_batches_tracked: BUFFER target='base_model.layer3.5.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_5_bn3_running_mean: BUFFER target='base_model.layer3.5.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_5_bn3_running_var: BUFFER target='base_model.layer3.5.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_5_bn3_num_batches_tracked: BUFFER target='base_model.layer3.5.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_6_bn1_running_mean: BUFFER target='base_model.layer3.6.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_6_bn1_running_var: BUFFER target='base_model.layer3.6.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_6_bn1_num_batches_tracked: BUFFER target='base_model.layer3.6.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_6_bn2_running_mean: BUFFER target='base_model.layer3.6.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_6_bn2_running_var: BUFFER target='base_model.layer3.6.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_6_bn2_num_batches_tracked: BUFFER target='base_model.layer3.6.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_6_bn3_running_mean: BUFFER target='base_model.layer3.6.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_6_bn3_running_var: BUFFER target='base_model.layer3.6.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_6_bn3_num_batches_tracked: BUFFER target='base_model.layer3.6.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_7_bn1_running_mean: BUFFER target='base_model.layer3.7.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_7_bn1_running_var: BUFFER target='base_model.layer3.7.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_7_bn1_num_batches_tracked: BUFFER target='base_model.layer3.7.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_7_bn2_running_mean: BUFFER target='base_model.layer3.7.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_7_bn2_running_var: BUFFER target='base_model.layer3.7.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_7_bn2_num_batches_tracked: BUFFER target='base_model.layer3.7.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_7_bn3_running_mean: BUFFER target='base_model.layer3.7.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_7_bn3_running_var: BUFFER target='base_model.layer3.7.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_7_bn3_num_batches_tracked: BUFFER target='base_model.layer3.7.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_8_bn1_running_mean: BUFFER target='base_model.layer3.8.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_8_bn1_running_var: BUFFER target='base_model.layer3.8.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_8_bn1_num_batches_tracked: BUFFER target='base_model.layer3.8.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_8_bn2_running_mean: BUFFER target='base_model.layer3.8.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_8_bn2_running_var: BUFFER target='base_model.layer3.8.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_8_bn2_num_batches_tracked: BUFFER target='base_model.layer3.8.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_8_bn3_running_mean: BUFFER target='base_model.layer3.8.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_8_bn3_running_var: BUFFER target='base_model.layer3.8.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_8_bn3_num_batches_tracked: BUFFER target='base_model.layer3.8.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_9_bn1_running_mean: BUFFER target='base_model.layer3.9.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_9_bn1_running_var: BUFFER target='base_model.layer3.9.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_9_bn1_num_batches_tracked: BUFFER target='base_model.layer3.9.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_9_bn2_running_mean: BUFFER target='base_model.layer3.9.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_9_bn2_running_var: BUFFER target='base_model.layer3.9.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_9_bn2_num_batches_tracked: BUFFER target='base_model.layer3.9.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_9_bn3_running_mean: BUFFER target='base_model.layer3.9.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_9_bn3_running_var: BUFFER target='base_model.layer3.9.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_9_bn3_num_batches_tracked: BUFFER target='base_model.layer3.9.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_10_bn1_running_mean: BUFFER target='base_model.layer3.10.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_10_bn1_running_var: BUFFER target='base_model.layer3.10.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_10_bn1_num_batches_tracked: BUFFER target='base_model.layer3.10.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_10_bn2_running_mean: BUFFER target='base_model.layer3.10.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_10_bn2_running_var: BUFFER target='base_model.layer3.10.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_10_bn2_num_batches_tracked: BUFFER target='base_model.layer3.10.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_10_bn3_running_mean: BUFFER target='base_model.layer3.10.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_10_bn3_running_var: BUFFER target='base_model.layer3.10.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_10_bn3_num_batches_tracked: BUFFER target='base_model.layer3.10.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_11_bn1_running_mean: BUFFER target='base_model.layer3.11.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_11_bn1_running_var: BUFFER target='base_model.layer3.11.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_11_bn1_num_batches_tracked: BUFFER target='base_model.layer3.11.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_11_bn2_running_mean: BUFFER target='base_model.layer3.11.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_11_bn2_running_var: BUFFER target='base_model.layer3.11.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_11_bn2_num_batches_tracked: BUFFER target='base_model.layer3.11.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_11_bn3_running_mean: BUFFER target='base_model.layer3.11.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_11_bn3_running_var: BUFFER target='base_model.layer3.11.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_11_bn3_num_batches_tracked: BUFFER target='base_model.layer3.11.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_12_bn1_running_mean: BUFFER target='base_model.layer3.12.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_12_bn1_running_var: BUFFER target='base_model.layer3.12.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_12_bn1_num_batches_tracked: BUFFER target='base_model.layer3.12.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_12_bn2_running_mean: BUFFER target='base_model.layer3.12.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_12_bn2_running_var: BUFFER target='base_model.layer3.12.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_12_bn2_num_batches_tracked: BUFFER target='base_model.layer3.12.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_12_bn3_running_mean: BUFFER target='base_model.layer3.12.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_12_bn3_running_var: BUFFER target='base_model.layer3.12.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_12_bn3_num_batches_tracked: BUFFER target='base_model.layer3.12.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_13_bn1_running_mean: BUFFER target='base_model.layer3.13.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_13_bn1_running_var: BUFFER target='base_model.layer3.13.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_13_bn1_num_batches_tracked: BUFFER target='base_model.layer3.13.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_13_bn2_running_mean: BUFFER target='base_model.layer3.13.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_13_bn2_running_var: BUFFER target='base_model.layer3.13.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_13_bn2_num_batches_tracked: BUFFER target='base_model.layer3.13.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_13_bn3_running_mean: BUFFER target='base_model.layer3.13.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_13_bn3_running_var: BUFFER target='base_model.layer3.13.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_13_bn3_num_batches_tracked: BUFFER target='base_model.layer3.13.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_14_bn1_running_mean: BUFFER target='base_model.layer3.14.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_14_bn1_running_var: BUFFER target='base_model.layer3.14.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_14_bn1_num_batches_tracked: BUFFER target='base_model.layer3.14.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_14_bn2_running_mean: BUFFER target='base_model.layer3.14.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_14_bn2_running_var: BUFFER target='base_model.layer3.14.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_14_bn2_num_batches_tracked: BUFFER target='base_model.layer3.14.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_14_bn3_running_mean: BUFFER target='base_model.layer3.14.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_14_bn3_running_var: BUFFER target='base_model.layer3.14.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_14_bn3_num_batches_tracked: BUFFER target='base_model.layer3.14.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_15_bn1_running_mean: BUFFER target='base_model.layer3.15.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_15_bn1_running_var: BUFFER target='base_model.layer3.15.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_15_bn1_num_batches_tracked: BUFFER target='base_model.layer3.15.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_15_bn2_running_mean: BUFFER target='base_model.layer3.15.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_15_bn2_running_var: BUFFER target='base_model.layer3.15.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_15_bn2_num_batches_tracked: BUFFER target='base_model.layer3.15.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_15_bn3_running_mean: BUFFER target='base_model.layer3.15.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_15_bn3_running_var: BUFFER target='base_model.layer3.15.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_15_bn3_num_batches_tracked: BUFFER target='base_model.layer3.15.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_16_bn1_running_mean: BUFFER target='base_model.layer3.16.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_16_bn1_running_var: BUFFER target='base_model.layer3.16.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_16_bn1_num_batches_tracked: BUFFER target='base_model.layer3.16.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_16_bn2_running_mean: BUFFER target='base_model.layer3.16.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_16_bn2_running_var: BUFFER target='base_model.layer3.16.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_16_bn2_num_batches_tracked: BUFFER target='base_model.layer3.16.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_16_bn3_running_mean: BUFFER target='base_model.layer3.16.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_16_bn3_running_var: BUFFER target='base_model.layer3.16.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_16_bn3_num_batches_tracked: BUFFER target='base_model.layer3.16.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_17_bn1_running_mean: BUFFER target='base_model.layer3.17.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_17_bn1_running_var: BUFFER target='base_model.layer3.17.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_17_bn1_num_batches_tracked: BUFFER target='base_model.layer3.17.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_17_bn2_running_mean: BUFFER target='base_model.layer3.17.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_17_bn2_running_var: BUFFER target='base_model.layer3.17.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_17_bn2_num_batches_tracked: BUFFER target='base_model.layer3.17.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_17_bn3_running_mean: BUFFER target='base_model.layer3.17.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_17_bn3_running_var: BUFFER target='base_model.layer3.17.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_17_bn3_num_batches_tracked: BUFFER target='base_model.layer3.17.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_18_bn1_running_mean: BUFFER target='base_model.layer3.18.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_18_bn1_running_var: BUFFER target='base_model.layer3.18.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_18_bn1_num_batches_tracked: BUFFER target='base_model.layer3.18.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_18_bn2_running_mean: BUFFER target='base_model.layer3.18.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_18_bn2_running_var: BUFFER target='base_model.layer3.18.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_18_bn2_num_batches_tracked: BUFFER target='base_model.layer3.18.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_18_bn3_running_mean: BUFFER target='base_model.layer3.18.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_18_bn3_running_var: BUFFER target='base_model.layer3.18.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_18_bn3_num_batches_tracked: BUFFER target='base_model.layer3.18.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_19_bn1_running_mean: BUFFER target='base_model.layer3.19.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_19_bn1_running_var: BUFFER target='base_model.layer3.19.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_19_bn1_num_batches_tracked: BUFFER target='base_model.layer3.19.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_19_bn2_running_mean: BUFFER target='base_model.layer3.19.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_19_bn2_running_var: BUFFER target='base_model.layer3.19.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_19_bn2_num_batches_tracked: BUFFER target='base_model.layer3.19.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_19_bn3_running_mean: BUFFER target='base_model.layer3.19.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_19_bn3_running_var: BUFFER target='base_model.layer3.19.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_19_bn3_num_batches_tracked: BUFFER target='base_model.layer3.19.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_20_bn1_running_mean: BUFFER target='base_model.layer3.20.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_20_bn1_running_var: BUFFER target='base_model.layer3.20.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_20_bn1_num_batches_tracked: BUFFER target='base_model.layer3.20.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_20_bn2_running_mean: BUFFER target='base_model.layer3.20.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_20_bn2_running_var: BUFFER target='base_model.layer3.20.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_20_bn2_num_batches_tracked: BUFFER target='base_model.layer3.20.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_20_bn3_running_mean: BUFFER target='base_model.layer3.20.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_20_bn3_running_var: BUFFER target='base_model.layer3.20.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_20_bn3_num_batches_tracked: BUFFER target='base_model.layer3.20.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_21_bn1_running_mean: BUFFER target='base_model.layer3.21.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_21_bn1_running_var: BUFFER target='base_model.layer3.21.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_21_bn1_num_batches_tracked: BUFFER target='base_model.layer3.21.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_21_bn2_running_mean: BUFFER target='base_model.layer3.21.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_21_bn2_running_var: BUFFER target='base_model.layer3.21.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_21_bn2_num_batches_tracked: BUFFER target='base_model.layer3.21.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_21_bn3_running_mean: BUFFER target='base_model.layer3.21.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_21_bn3_running_var: BUFFER target='base_model.layer3.21.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_21_bn3_num_batches_tracked: BUFFER target='base_model.layer3.21.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_22_bn1_running_mean: BUFFER target='base_model.layer3.22.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_22_bn1_running_var: BUFFER target='base_model.layer3.22.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_22_bn1_num_batches_tracked: BUFFER target='base_model.layer3.22.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_22_bn2_running_mean: BUFFER target='base_model.layer3.22.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_22_bn2_running_var: BUFFER target='base_model.layer3.22.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_22_bn2_num_batches_tracked: BUFFER target='base_model.layer3.22.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_22_bn3_running_mean: BUFFER target='base_model.layer3.22.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_22_bn3_running_var: BUFFER target='base_model.layer3.22.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_22_bn3_num_batches_tracked: BUFFER target='base_model.layer3.22.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_23_bn1_running_mean: BUFFER target='base_model.layer3.23.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_23_bn1_running_var: BUFFER target='base_model.layer3.23.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_23_bn1_num_batches_tracked: BUFFER target='base_model.layer3.23.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_23_bn2_running_mean: BUFFER target='base_model.layer3.23.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_23_bn2_running_var: BUFFER target='base_model.layer3.23.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_23_bn2_num_batches_tracked: BUFFER target='base_model.layer3.23.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_23_bn3_running_mean: BUFFER target='base_model.layer3.23.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_23_bn3_running_var: BUFFER target='base_model.layer3.23.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_23_bn3_num_batches_tracked: BUFFER target='base_model.layer3.23.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_24_bn1_running_mean: BUFFER target='base_model.layer3.24.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_24_bn1_running_var: BUFFER target='base_model.layer3.24.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_24_bn1_num_batches_tracked: BUFFER target='base_model.layer3.24.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_24_bn2_running_mean: BUFFER target='base_model.layer3.24.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_24_bn2_running_var: BUFFER target='base_model.layer3.24.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_24_bn2_num_batches_tracked: BUFFER target='base_model.layer3.24.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_24_bn3_running_mean: BUFFER target='base_model.layer3.24.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_24_bn3_running_var: BUFFER target='base_model.layer3.24.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_24_bn3_num_batches_tracked: BUFFER target='base_model.layer3.24.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_25_bn1_running_mean: BUFFER target='base_model.layer3.25.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_25_bn1_running_var: BUFFER target='base_model.layer3.25.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_25_bn1_num_batches_tracked: BUFFER target='base_model.layer3.25.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_25_bn2_running_mean: BUFFER target='base_model.layer3.25.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_25_bn2_running_var: BUFFER target='base_model.layer3.25.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_25_bn2_num_batches_tracked: BUFFER target='base_model.layer3.25.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_25_bn3_running_mean: BUFFER target='base_model.layer3.25.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_25_bn3_running_var: BUFFER target='base_model.layer3.25.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_25_bn3_num_batches_tracked: BUFFER target='base_model.layer3.25.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_26_bn1_running_mean: BUFFER target='base_model.layer3.26.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_26_bn1_running_var: BUFFER target='base_model.layer3.26.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_26_bn1_num_batches_tracked: BUFFER target='base_model.layer3.26.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_26_bn2_running_mean: BUFFER target='base_model.layer3.26.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_26_bn2_running_var: BUFFER target='base_model.layer3.26.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_26_bn2_num_batches_tracked: BUFFER target='base_model.layer3.26.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_26_bn3_running_mean: BUFFER target='base_model.layer3.26.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_26_bn3_running_var: BUFFER target='base_model.layer3.26.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_26_bn3_num_batches_tracked: BUFFER target='base_model.layer3.26.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_27_bn1_running_mean: BUFFER target='base_model.layer3.27.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_27_bn1_running_var: BUFFER target='base_model.layer3.27.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_27_bn1_num_batches_tracked: BUFFER target='base_model.layer3.27.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_27_bn2_running_mean: BUFFER target='base_model.layer3.27.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_27_bn2_running_var: BUFFER target='base_model.layer3.27.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_27_bn2_num_batches_tracked: BUFFER target='base_model.layer3.27.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_27_bn3_running_mean: BUFFER target='base_model.layer3.27.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_27_bn3_running_var: BUFFER target='base_model.layer3.27.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_27_bn3_num_batches_tracked: BUFFER target='base_model.layer3.27.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_28_bn1_running_mean: BUFFER target='base_model.layer3.28.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_28_bn1_running_var: BUFFER target='base_model.layer3.28.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_28_bn1_num_batches_tracked: BUFFER target='base_model.layer3.28.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_28_bn2_running_mean: BUFFER target='base_model.layer3.28.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_28_bn2_running_var: BUFFER target='base_model.layer3.28.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_28_bn2_num_batches_tracked: BUFFER target='base_model.layer3.28.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_28_bn3_running_mean: BUFFER target='base_model.layer3.28.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_28_bn3_running_var: BUFFER target='base_model.layer3.28.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_28_bn3_num_batches_tracked: BUFFER target='base_model.layer3.28.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_29_bn1_running_mean: BUFFER target='base_model.layer3.29.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_29_bn1_running_var: BUFFER target='base_model.layer3.29.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_29_bn1_num_batches_tracked: BUFFER target='base_model.layer3.29.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_29_bn2_running_mean: BUFFER target='base_model.layer3.29.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_29_bn2_running_var: BUFFER target='base_model.layer3.29.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_29_bn2_num_batches_tracked: BUFFER target='base_model.layer3.29.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_29_bn3_running_mean: BUFFER target='base_model.layer3.29.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_29_bn3_running_var: BUFFER target='base_model.layer3.29.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_29_bn3_num_batches_tracked: BUFFER target='base_model.layer3.29.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_30_bn1_running_mean: BUFFER target='base_model.layer3.30.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_30_bn1_running_var: BUFFER target='base_model.layer3.30.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_30_bn1_num_batches_tracked: BUFFER target='base_model.layer3.30.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_30_bn2_running_mean: BUFFER target='base_model.layer3.30.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_30_bn2_running_var: BUFFER target='base_model.layer3.30.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_30_bn2_num_batches_tracked: BUFFER target='base_model.layer3.30.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_30_bn3_running_mean: BUFFER target='base_model.layer3.30.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_30_bn3_running_var: BUFFER target='base_model.layer3.30.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_30_bn3_num_batches_tracked: BUFFER target='base_model.layer3.30.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_31_bn1_running_mean: BUFFER target='base_model.layer3.31.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_31_bn1_running_var: BUFFER target='base_model.layer3.31.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_31_bn1_num_batches_tracked: BUFFER target='base_model.layer3.31.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_31_bn2_running_mean: BUFFER target='base_model.layer3.31.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_31_bn2_running_var: BUFFER target='base_model.layer3.31.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_31_bn2_num_batches_tracked: BUFFER target='base_model.layer3.31.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_31_bn3_running_mean: BUFFER target='base_model.layer3.31.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_31_bn3_running_var: BUFFER target='base_model.layer3.31.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_31_bn3_num_batches_tracked: BUFFER target='base_model.layer3.31.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_32_bn1_running_mean: BUFFER target='base_model.layer3.32.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_32_bn1_running_var: BUFFER target='base_model.layer3.32.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_32_bn1_num_batches_tracked: BUFFER target='base_model.layer3.32.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_32_bn2_running_mean: BUFFER target='base_model.layer3.32.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_32_bn2_running_var: BUFFER target='base_model.layer3.32.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_32_bn2_num_batches_tracked: BUFFER target='base_model.layer3.32.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_32_bn3_running_mean: BUFFER target='base_model.layer3.32.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_32_bn3_running_var: BUFFER target='base_model.layer3.32.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_32_bn3_num_batches_tracked: BUFFER target='base_model.layer3.32.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_33_bn1_running_mean: BUFFER target='base_model.layer3.33.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_33_bn1_running_var: BUFFER target='base_model.layer3.33.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_33_bn1_num_batches_tracked: BUFFER target='base_model.layer3.33.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_33_bn2_running_mean: BUFFER target='base_model.layer3.33.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_33_bn2_running_var: BUFFER target='base_model.layer3.33.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_33_bn2_num_batches_tracked: BUFFER target='base_model.layer3.33.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_33_bn3_running_mean: BUFFER target='base_model.layer3.33.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_33_bn3_running_var: BUFFER target='base_model.layer3.33.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_33_bn3_num_batches_tracked: BUFFER target='base_model.layer3.33.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_34_bn1_running_mean: BUFFER target='base_model.layer3.34.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_34_bn1_running_var: BUFFER target='base_model.layer3.34.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_34_bn1_num_batches_tracked: BUFFER target='base_model.layer3.34.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_34_bn2_running_mean: BUFFER target='base_model.layer3.34.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_34_bn2_running_var: BUFFER target='base_model.layer3.34.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_34_bn2_num_batches_tracked: BUFFER target='base_model.layer3.34.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_34_bn3_running_mean: BUFFER target='base_model.layer3.34.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_34_bn3_running_var: BUFFER target='base_model.layer3.34.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_34_bn3_num_batches_tracked: BUFFER target='base_model.layer3.34.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_35_bn1_running_mean: BUFFER target='base_model.layer3.35.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer3_35_bn1_running_var: BUFFER target='base_model.layer3.35.bn1.running_var' persistent=True\n",
       "            b_base_model_layer3_35_bn1_num_batches_tracked: BUFFER target='base_model.layer3.35.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_35_bn2_running_mean: BUFFER target='base_model.layer3.35.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer3_35_bn2_running_var: BUFFER target='base_model.layer3.35.bn2.running_var' persistent=True\n",
       "            b_base_model_layer3_35_bn2_num_batches_tracked: BUFFER target='base_model.layer3.35.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer3_35_bn3_running_mean: BUFFER target='base_model.layer3.35.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer3_35_bn3_running_var: BUFFER target='base_model.layer3.35.bn3.running_var' persistent=True\n",
       "            b_base_model_layer3_35_bn3_num_batches_tracked: BUFFER target='base_model.layer3.35.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_0_bn1_running_mean: BUFFER target='base_model.layer4.0.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer4_0_bn1_running_var: BUFFER target='base_model.layer4.0.bn1.running_var' persistent=True\n",
       "            b_base_model_layer4_0_bn1_num_batches_tracked: BUFFER target='base_model.layer4.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_0_bn2_running_mean: BUFFER target='base_model.layer4.0.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer4_0_bn2_running_var: BUFFER target='base_model.layer4.0.bn2.running_var' persistent=True\n",
       "            b_base_model_layer4_0_bn2_num_batches_tracked: BUFFER target='base_model.layer4.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_0_bn3_running_mean: BUFFER target='base_model.layer4.0.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer4_0_bn3_running_var: BUFFER target='base_model.layer4.0.bn3.running_var' persistent=True\n",
       "            b_base_model_layer4_0_bn3_num_batches_tracked: BUFFER target='base_model.layer4.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_0_downsample_1_running_mean: BUFFER target='base_model.layer4.0.downsample.1.running_mean' persistent=True\n",
       "            b_base_model_layer4_0_downsample_1_running_var: BUFFER target='base_model.layer4.0.downsample.1.running_var' persistent=True\n",
       "            b_base_model_layer4_0_downsample_1_num_batches_tracked: BUFFER target='base_model.layer4.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_1_bn1_running_mean: BUFFER target='base_model.layer4.1.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer4_1_bn1_running_var: BUFFER target='base_model.layer4.1.bn1.running_var' persistent=True\n",
       "            b_base_model_layer4_1_bn1_num_batches_tracked: BUFFER target='base_model.layer4.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_1_bn2_running_mean: BUFFER target='base_model.layer4.1.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer4_1_bn2_running_var: BUFFER target='base_model.layer4.1.bn2.running_var' persistent=True\n",
       "            b_base_model_layer4_1_bn2_num_batches_tracked: BUFFER target='base_model.layer4.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_1_bn3_running_mean: BUFFER target='base_model.layer4.1.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer4_1_bn3_running_var: BUFFER target='base_model.layer4.1.bn3.running_var' persistent=True\n",
       "            b_base_model_layer4_1_bn3_num_batches_tracked: BUFFER target='base_model.layer4.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_2_bn1_running_mean: BUFFER target='base_model.layer4.2.bn1.running_mean' persistent=True\n",
       "            b_base_model_layer4_2_bn1_running_var: BUFFER target='base_model.layer4.2.bn1.running_var' persistent=True\n",
       "            b_base_model_layer4_2_bn1_num_batches_tracked: BUFFER target='base_model.layer4.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_2_bn2_running_mean: BUFFER target='base_model.layer4.2.bn2.running_mean' persistent=True\n",
       "            b_base_model_layer4_2_bn2_running_var: BUFFER target='base_model.layer4.2.bn2.running_var' persistent=True\n",
       "            b_base_model_layer4_2_bn2_num_batches_tracked: BUFFER target='base_model.layer4.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_base_model_layer4_2_bn3_running_mean: BUFFER target='base_model.layer4.2.bn3.running_mean' persistent=True\n",
       "            b_base_model_layer4_2_bn3_running_var: BUFFER target='base_model.layer4.2.bn3.running_var' persistent=True\n",
       "            b_base_model_layer4_2_bn3_num_batches_tracked: BUFFER target='base_model.layer4.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_1_running_mean: BUFFER target='features_extractor.1.running_mean' persistent=True\n",
       "            b_features_extractor_1_running_var: BUFFER target='features_extractor.1.running_var' persistent=True\n",
       "            b_features_extractor_1_num_batches_tracked: BUFFER target='features_extractor.1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_0_bn1_running_mean: BUFFER target='features_extractor.4.0.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_4_0_bn1_running_var: BUFFER target='features_extractor.4.0.bn1.running_var' persistent=True\n",
       "            b_features_extractor_4_0_bn1_num_batches_tracked: BUFFER target='features_extractor.4.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_0_bn2_running_mean: BUFFER target='features_extractor.4.0.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_4_0_bn2_running_var: BUFFER target='features_extractor.4.0.bn2.running_var' persistent=True\n",
       "            b_features_extractor_4_0_bn2_num_batches_tracked: BUFFER target='features_extractor.4.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_0_bn3_running_mean: BUFFER target='features_extractor.4.0.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_4_0_bn3_running_var: BUFFER target='features_extractor.4.0.bn3.running_var' persistent=True\n",
       "            b_features_extractor_4_0_bn3_num_batches_tracked: BUFFER target='features_extractor.4.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_0_downsample_1_running_mean: BUFFER target='features_extractor.4.0.downsample.1.running_mean' persistent=True\n",
       "            b_features_extractor_4_0_downsample_1_running_var: BUFFER target='features_extractor.4.0.downsample.1.running_var' persistent=True\n",
       "            b_features_extractor_4_0_downsample_1_num_batches_tracked: BUFFER target='features_extractor.4.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_1_bn1_running_mean: BUFFER target='features_extractor.4.1.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_4_1_bn1_running_var: BUFFER target='features_extractor.4.1.bn1.running_var' persistent=True\n",
       "            b_features_extractor_4_1_bn1_num_batches_tracked: BUFFER target='features_extractor.4.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_1_bn2_running_mean: BUFFER target='features_extractor.4.1.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_4_1_bn2_running_var: BUFFER target='features_extractor.4.1.bn2.running_var' persistent=True\n",
       "            b_features_extractor_4_1_bn2_num_batches_tracked: BUFFER target='features_extractor.4.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_1_bn3_running_mean: BUFFER target='features_extractor.4.1.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_4_1_bn3_running_var: BUFFER target='features_extractor.4.1.bn3.running_var' persistent=True\n",
       "            b_features_extractor_4_1_bn3_num_batches_tracked: BUFFER target='features_extractor.4.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_2_bn1_running_mean: BUFFER target='features_extractor.4.2.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_4_2_bn1_running_var: BUFFER target='features_extractor.4.2.bn1.running_var' persistent=True\n",
       "            b_features_extractor_4_2_bn1_num_batches_tracked: BUFFER target='features_extractor.4.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_2_bn2_running_mean: BUFFER target='features_extractor.4.2.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_4_2_bn2_running_var: BUFFER target='features_extractor.4.2.bn2.running_var' persistent=True\n",
       "            b_features_extractor_4_2_bn2_num_batches_tracked: BUFFER target='features_extractor.4.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_4_2_bn3_running_mean: BUFFER target='features_extractor.4.2.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_4_2_bn3_running_var: BUFFER target='features_extractor.4.2.bn3.running_var' persistent=True\n",
       "            b_features_extractor_4_2_bn3_num_batches_tracked: BUFFER target='features_extractor.4.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_0_bn1_running_mean: BUFFER target='features_extractor.5.0.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_0_bn1_running_var: BUFFER target='features_extractor.5.0.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_0_bn1_num_batches_tracked: BUFFER target='features_extractor.5.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_0_bn2_running_mean: BUFFER target='features_extractor.5.0.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_0_bn2_running_var: BUFFER target='features_extractor.5.0.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_0_bn2_num_batches_tracked: BUFFER target='features_extractor.5.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_0_bn3_running_mean: BUFFER target='features_extractor.5.0.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_0_bn3_running_var: BUFFER target='features_extractor.5.0.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_0_bn3_num_batches_tracked: BUFFER target='features_extractor.5.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_0_downsample_1_running_mean: BUFFER target='features_extractor.5.0.downsample.1.running_mean' persistent=True\n",
       "            b_features_extractor_5_0_downsample_1_running_var: BUFFER target='features_extractor.5.0.downsample.1.running_var' persistent=True\n",
       "            b_features_extractor_5_0_downsample_1_num_batches_tracked: BUFFER target='features_extractor.5.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_1_bn1_running_mean: BUFFER target='features_extractor.5.1.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_1_bn1_running_var: BUFFER target='features_extractor.5.1.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_1_bn1_num_batches_tracked: BUFFER target='features_extractor.5.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_1_bn2_running_mean: BUFFER target='features_extractor.5.1.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_1_bn2_running_var: BUFFER target='features_extractor.5.1.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_1_bn2_num_batches_tracked: BUFFER target='features_extractor.5.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_1_bn3_running_mean: BUFFER target='features_extractor.5.1.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_1_bn3_running_var: BUFFER target='features_extractor.5.1.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_1_bn3_num_batches_tracked: BUFFER target='features_extractor.5.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_2_bn1_running_mean: BUFFER target='features_extractor.5.2.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_2_bn1_running_var: BUFFER target='features_extractor.5.2.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_2_bn1_num_batches_tracked: BUFFER target='features_extractor.5.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_2_bn2_running_mean: BUFFER target='features_extractor.5.2.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_2_bn2_running_var: BUFFER target='features_extractor.5.2.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_2_bn2_num_batches_tracked: BUFFER target='features_extractor.5.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_2_bn3_running_mean: BUFFER target='features_extractor.5.2.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_2_bn3_running_var: BUFFER target='features_extractor.5.2.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_2_bn3_num_batches_tracked: BUFFER target='features_extractor.5.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_3_bn1_running_mean: BUFFER target='features_extractor.5.3.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_3_bn1_running_var: BUFFER target='features_extractor.5.3.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_3_bn1_num_batches_tracked: BUFFER target='features_extractor.5.3.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_3_bn2_running_mean: BUFFER target='features_extractor.5.3.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_3_bn2_running_var: BUFFER target='features_extractor.5.3.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_3_bn2_num_batches_tracked: BUFFER target='features_extractor.5.3.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_3_bn3_running_mean: BUFFER target='features_extractor.5.3.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_3_bn3_running_var: BUFFER target='features_extractor.5.3.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_3_bn3_num_batches_tracked: BUFFER target='features_extractor.5.3.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_4_bn1_running_mean: BUFFER target='features_extractor.5.4.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_4_bn1_running_var: BUFFER target='features_extractor.5.4.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_4_bn1_num_batches_tracked: BUFFER target='features_extractor.5.4.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_4_bn2_running_mean: BUFFER target='features_extractor.5.4.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_4_bn2_running_var: BUFFER target='features_extractor.5.4.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_4_bn2_num_batches_tracked: BUFFER target='features_extractor.5.4.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_4_bn3_running_mean: BUFFER target='features_extractor.5.4.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_4_bn3_running_var: BUFFER target='features_extractor.5.4.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_4_bn3_num_batches_tracked: BUFFER target='features_extractor.5.4.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_5_bn1_running_mean: BUFFER target='features_extractor.5.5.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_5_bn1_running_var: BUFFER target='features_extractor.5.5.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_5_bn1_num_batches_tracked: BUFFER target='features_extractor.5.5.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_5_bn2_running_mean: BUFFER target='features_extractor.5.5.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_5_bn2_running_var: BUFFER target='features_extractor.5.5.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_5_bn2_num_batches_tracked: BUFFER target='features_extractor.5.5.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_5_bn3_running_mean: BUFFER target='features_extractor.5.5.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_5_bn3_running_var: BUFFER target='features_extractor.5.5.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_5_bn3_num_batches_tracked: BUFFER target='features_extractor.5.5.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_6_bn1_running_mean: BUFFER target='features_extractor.5.6.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_6_bn1_running_var: BUFFER target='features_extractor.5.6.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_6_bn1_num_batches_tracked: BUFFER target='features_extractor.5.6.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_6_bn2_running_mean: BUFFER target='features_extractor.5.6.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_6_bn2_running_var: BUFFER target='features_extractor.5.6.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_6_bn2_num_batches_tracked: BUFFER target='features_extractor.5.6.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_6_bn3_running_mean: BUFFER target='features_extractor.5.6.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_6_bn3_running_var: BUFFER target='features_extractor.5.6.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_6_bn3_num_batches_tracked: BUFFER target='features_extractor.5.6.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_7_bn1_running_mean: BUFFER target='features_extractor.5.7.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_5_7_bn1_running_var: BUFFER target='features_extractor.5.7.bn1.running_var' persistent=True\n",
       "            b_features_extractor_5_7_bn1_num_batches_tracked: BUFFER target='features_extractor.5.7.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_7_bn2_running_mean: BUFFER target='features_extractor.5.7.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_5_7_bn2_running_var: BUFFER target='features_extractor.5.7.bn2.running_var' persistent=True\n",
       "            b_features_extractor_5_7_bn2_num_batches_tracked: BUFFER target='features_extractor.5.7.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_5_7_bn3_running_mean: BUFFER target='features_extractor.5.7.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_5_7_bn3_running_var: BUFFER target='features_extractor.5.7.bn3.running_var' persistent=True\n",
       "            b_features_extractor_5_7_bn3_num_batches_tracked: BUFFER target='features_extractor.5.7.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_0_bn1_running_mean: BUFFER target='features_extractor.6.0.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_0_bn1_running_var: BUFFER target='features_extractor.6.0.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_0_bn1_num_batches_tracked: BUFFER target='features_extractor.6.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_0_bn2_running_mean: BUFFER target='features_extractor.6.0.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_0_bn2_running_var: BUFFER target='features_extractor.6.0.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_0_bn2_num_batches_tracked: BUFFER target='features_extractor.6.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_0_bn3_running_mean: BUFFER target='features_extractor.6.0.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_0_bn3_running_var: BUFFER target='features_extractor.6.0.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_0_bn3_num_batches_tracked: BUFFER target='features_extractor.6.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_0_downsample_1_running_mean: BUFFER target='features_extractor.6.0.downsample.1.running_mean' persistent=True\n",
       "            b_features_extractor_6_0_downsample_1_running_var: BUFFER target='features_extractor.6.0.downsample.1.running_var' persistent=True\n",
       "            b_features_extractor_6_0_downsample_1_num_batches_tracked: BUFFER target='features_extractor.6.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_1_bn1_running_mean: BUFFER target='features_extractor.6.1.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_1_bn1_running_var: BUFFER target='features_extractor.6.1.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_1_bn1_num_batches_tracked: BUFFER target='features_extractor.6.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_1_bn2_running_mean: BUFFER target='features_extractor.6.1.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_1_bn2_running_var: BUFFER target='features_extractor.6.1.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_1_bn2_num_batches_tracked: BUFFER target='features_extractor.6.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_1_bn3_running_mean: BUFFER target='features_extractor.6.1.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_1_bn3_running_var: BUFFER target='features_extractor.6.1.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_1_bn3_num_batches_tracked: BUFFER target='features_extractor.6.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_2_bn1_running_mean: BUFFER target='features_extractor.6.2.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_2_bn1_running_var: BUFFER target='features_extractor.6.2.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_2_bn1_num_batches_tracked: BUFFER target='features_extractor.6.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_2_bn2_running_mean: BUFFER target='features_extractor.6.2.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_2_bn2_running_var: BUFFER target='features_extractor.6.2.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_2_bn2_num_batches_tracked: BUFFER target='features_extractor.6.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_2_bn3_running_mean: BUFFER target='features_extractor.6.2.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_2_bn3_running_var: BUFFER target='features_extractor.6.2.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_2_bn3_num_batches_tracked: BUFFER target='features_extractor.6.2.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_3_bn1_running_mean: BUFFER target='features_extractor.6.3.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_3_bn1_running_var: BUFFER target='features_extractor.6.3.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_3_bn1_num_batches_tracked: BUFFER target='features_extractor.6.3.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_3_bn2_running_mean: BUFFER target='features_extractor.6.3.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_3_bn2_running_var: BUFFER target='features_extractor.6.3.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_3_bn2_num_batches_tracked: BUFFER target='features_extractor.6.3.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_3_bn3_running_mean: BUFFER target='features_extractor.6.3.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_3_bn3_running_var: BUFFER target='features_extractor.6.3.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_3_bn3_num_batches_tracked: BUFFER target='features_extractor.6.3.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_4_bn1_running_mean: BUFFER target='features_extractor.6.4.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_4_bn1_running_var: BUFFER target='features_extractor.6.4.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_4_bn1_num_batches_tracked: BUFFER target='features_extractor.6.4.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_4_bn2_running_mean: BUFFER target='features_extractor.6.4.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_4_bn2_running_var: BUFFER target='features_extractor.6.4.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_4_bn2_num_batches_tracked: BUFFER target='features_extractor.6.4.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_4_bn3_running_mean: BUFFER target='features_extractor.6.4.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_4_bn3_running_var: BUFFER target='features_extractor.6.4.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_4_bn3_num_batches_tracked: BUFFER target='features_extractor.6.4.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_5_bn1_running_mean: BUFFER target='features_extractor.6.5.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_5_bn1_running_var: BUFFER target='features_extractor.6.5.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_5_bn1_num_batches_tracked: BUFFER target='features_extractor.6.5.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_5_bn2_running_mean: BUFFER target='features_extractor.6.5.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_5_bn2_running_var: BUFFER target='features_extractor.6.5.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_5_bn2_num_batches_tracked: BUFFER target='features_extractor.6.5.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_5_bn3_running_mean: BUFFER target='features_extractor.6.5.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_5_bn3_running_var: BUFFER target='features_extractor.6.5.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_5_bn3_num_batches_tracked: BUFFER target='features_extractor.6.5.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_6_bn1_running_mean: BUFFER target='features_extractor.6.6.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_6_bn1_running_var: BUFFER target='features_extractor.6.6.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_6_bn1_num_batches_tracked: BUFFER target='features_extractor.6.6.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_6_bn2_running_mean: BUFFER target='features_extractor.6.6.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_6_bn2_running_var: BUFFER target='features_extractor.6.6.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_6_bn2_num_batches_tracked: BUFFER target='features_extractor.6.6.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_6_bn3_running_mean: BUFFER target='features_extractor.6.6.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_6_bn3_running_var: BUFFER target='features_extractor.6.6.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_6_bn3_num_batches_tracked: BUFFER target='features_extractor.6.6.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_7_bn1_running_mean: BUFFER target='features_extractor.6.7.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_7_bn1_running_var: BUFFER target='features_extractor.6.7.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_7_bn1_num_batches_tracked: BUFFER target='features_extractor.6.7.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_7_bn2_running_mean: BUFFER target='features_extractor.6.7.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_7_bn2_running_var: BUFFER target='features_extractor.6.7.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_7_bn2_num_batches_tracked: BUFFER target='features_extractor.6.7.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_7_bn3_running_mean: BUFFER target='features_extractor.6.7.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_7_bn3_running_var: BUFFER target='features_extractor.6.7.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_7_bn3_num_batches_tracked: BUFFER target='features_extractor.6.7.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_8_bn1_running_mean: BUFFER target='features_extractor.6.8.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_8_bn1_running_var: BUFFER target='features_extractor.6.8.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_8_bn1_num_batches_tracked: BUFFER target='features_extractor.6.8.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_8_bn2_running_mean: BUFFER target='features_extractor.6.8.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_8_bn2_running_var: BUFFER target='features_extractor.6.8.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_8_bn2_num_batches_tracked: BUFFER target='features_extractor.6.8.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_8_bn3_running_mean: BUFFER target='features_extractor.6.8.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_8_bn3_running_var: BUFFER target='features_extractor.6.8.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_8_bn3_num_batches_tracked: BUFFER target='features_extractor.6.8.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_9_bn1_running_mean: BUFFER target='features_extractor.6.9.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_9_bn1_running_var: BUFFER target='features_extractor.6.9.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_9_bn1_num_batches_tracked: BUFFER target='features_extractor.6.9.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_9_bn2_running_mean: BUFFER target='features_extractor.6.9.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_9_bn2_running_var: BUFFER target='features_extractor.6.9.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_9_bn2_num_batches_tracked: BUFFER target='features_extractor.6.9.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_9_bn3_running_mean: BUFFER target='features_extractor.6.9.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_9_bn3_running_var: BUFFER target='features_extractor.6.9.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_9_bn3_num_batches_tracked: BUFFER target='features_extractor.6.9.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_10_bn1_running_mean: BUFFER target='features_extractor.6.10.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_10_bn1_running_var: BUFFER target='features_extractor.6.10.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_10_bn1_num_batches_tracked: BUFFER target='features_extractor.6.10.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_10_bn2_running_mean: BUFFER target='features_extractor.6.10.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_10_bn2_running_var: BUFFER target='features_extractor.6.10.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_10_bn2_num_batches_tracked: BUFFER target='features_extractor.6.10.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_10_bn3_running_mean: BUFFER target='features_extractor.6.10.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_10_bn3_running_var: BUFFER target='features_extractor.6.10.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_10_bn3_num_batches_tracked: BUFFER target='features_extractor.6.10.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_11_bn1_running_mean: BUFFER target='features_extractor.6.11.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_11_bn1_running_var: BUFFER target='features_extractor.6.11.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_11_bn1_num_batches_tracked: BUFFER target='features_extractor.6.11.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_11_bn2_running_mean: BUFFER target='features_extractor.6.11.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_11_bn2_running_var: BUFFER target='features_extractor.6.11.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_11_bn2_num_batches_tracked: BUFFER target='features_extractor.6.11.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_11_bn3_running_mean: BUFFER target='features_extractor.6.11.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_11_bn3_running_var: BUFFER target='features_extractor.6.11.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_11_bn3_num_batches_tracked: BUFFER target='features_extractor.6.11.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_12_bn1_running_mean: BUFFER target='features_extractor.6.12.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_12_bn1_running_var: BUFFER target='features_extractor.6.12.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_12_bn1_num_batches_tracked: BUFFER target='features_extractor.6.12.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_12_bn2_running_mean: BUFFER target='features_extractor.6.12.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_12_bn2_running_var: BUFFER target='features_extractor.6.12.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_12_bn2_num_batches_tracked: BUFFER target='features_extractor.6.12.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_12_bn3_running_mean: BUFFER target='features_extractor.6.12.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_12_bn3_running_var: BUFFER target='features_extractor.6.12.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_12_bn3_num_batches_tracked: BUFFER target='features_extractor.6.12.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_13_bn1_running_mean: BUFFER target='features_extractor.6.13.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_13_bn1_running_var: BUFFER target='features_extractor.6.13.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_13_bn1_num_batches_tracked: BUFFER target='features_extractor.6.13.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_13_bn2_running_mean: BUFFER target='features_extractor.6.13.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_13_bn2_running_var: BUFFER target='features_extractor.6.13.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_13_bn2_num_batches_tracked: BUFFER target='features_extractor.6.13.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_13_bn3_running_mean: BUFFER target='features_extractor.6.13.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_13_bn3_running_var: BUFFER target='features_extractor.6.13.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_13_bn3_num_batches_tracked: BUFFER target='features_extractor.6.13.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_14_bn1_running_mean: BUFFER target='features_extractor.6.14.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_14_bn1_running_var: BUFFER target='features_extractor.6.14.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_14_bn1_num_batches_tracked: BUFFER target='features_extractor.6.14.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_14_bn2_running_mean: BUFFER target='features_extractor.6.14.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_14_bn2_running_var: BUFFER target='features_extractor.6.14.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_14_bn2_num_batches_tracked: BUFFER target='features_extractor.6.14.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_14_bn3_running_mean: BUFFER target='features_extractor.6.14.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_14_bn3_running_var: BUFFER target='features_extractor.6.14.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_14_bn3_num_batches_tracked: BUFFER target='features_extractor.6.14.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_15_bn1_running_mean: BUFFER target='features_extractor.6.15.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_15_bn1_running_var: BUFFER target='features_extractor.6.15.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_15_bn1_num_batches_tracked: BUFFER target='features_extractor.6.15.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_15_bn2_running_mean: BUFFER target='features_extractor.6.15.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_15_bn2_running_var: BUFFER target='features_extractor.6.15.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_15_bn2_num_batches_tracked: BUFFER target='features_extractor.6.15.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_15_bn3_running_mean: BUFFER target='features_extractor.6.15.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_15_bn3_running_var: BUFFER target='features_extractor.6.15.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_15_bn3_num_batches_tracked: BUFFER target='features_extractor.6.15.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_16_bn1_running_mean: BUFFER target='features_extractor.6.16.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_16_bn1_running_var: BUFFER target='features_extractor.6.16.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_16_bn1_num_batches_tracked: BUFFER target='features_extractor.6.16.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_16_bn2_running_mean: BUFFER target='features_extractor.6.16.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_16_bn2_running_var: BUFFER target='features_extractor.6.16.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_16_bn2_num_batches_tracked: BUFFER target='features_extractor.6.16.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_16_bn3_running_mean: BUFFER target='features_extractor.6.16.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_16_bn3_running_var: BUFFER target='features_extractor.6.16.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_16_bn3_num_batches_tracked: BUFFER target='features_extractor.6.16.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_17_bn1_running_mean: BUFFER target='features_extractor.6.17.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_17_bn1_running_var: BUFFER target='features_extractor.6.17.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_17_bn1_num_batches_tracked: BUFFER target='features_extractor.6.17.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_17_bn2_running_mean: BUFFER target='features_extractor.6.17.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_17_bn2_running_var: BUFFER target='features_extractor.6.17.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_17_bn2_num_batches_tracked: BUFFER target='features_extractor.6.17.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_17_bn3_running_mean: BUFFER target='features_extractor.6.17.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_17_bn3_running_var: BUFFER target='features_extractor.6.17.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_17_bn3_num_batches_tracked: BUFFER target='features_extractor.6.17.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_18_bn1_running_mean: BUFFER target='features_extractor.6.18.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_18_bn1_running_var: BUFFER target='features_extractor.6.18.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_18_bn1_num_batches_tracked: BUFFER target='features_extractor.6.18.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_18_bn2_running_mean: BUFFER target='features_extractor.6.18.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_18_bn2_running_var: BUFFER target='features_extractor.6.18.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_18_bn2_num_batches_tracked: BUFFER target='features_extractor.6.18.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_18_bn3_running_mean: BUFFER target='features_extractor.6.18.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_18_bn3_running_var: BUFFER target='features_extractor.6.18.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_18_bn3_num_batches_tracked: BUFFER target='features_extractor.6.18.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_19_bn1_running_mean: BUFFER target='features_extractor.6.19.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_19_bn1_running_var: BUFFER target='features_extractor.6.19.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_19_bn1_num_batches_tracked: BUFFER target='features_extractor.6.19.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_19_bn2_running_mean: BUFFER target='features_extractor.6.19.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_19_bn2_running_var: BUFFER target='features_extractor.6.19.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_19_bn2_num_batches_tracked: BUFFER target='features_extractor.6.19.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_19_bn3_running_mean: BUFFER target='features_extractor.6.19.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_19_bn3_running_var: BUFFER target='features_extractor.6.19.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_19_bn3_num_batches_tracked: BUFFER target='features_extractor.6.19.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_20_bn1_running_mean: BUFFER target='features_extractor.6.20.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_20_bn1_running_var: BUFFER target='features_extractor.6.20.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_20_bn1_num_batches_tracked: BUFFER target='features_extractor.6.20.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_20_bn2_running_mean: BUFFER target='features_extractor.6.20.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_20_bn2_running_var: BUFFER target='features_extractor.6.20.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_20_bn2_num_batches_tracked: BUFFER target='features_extractor.6.20.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_20_bn3_running_mean: BUFFER target='features_extractor.6.20.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_20_bn3_running_var: BUFFER target='features_extractor.6.20.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_20_bn3_num_batches_tracked: BUFFER target='features_extractor.6.20.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_21_bn1_running_mean: BUFFER target='features_extractor.6.21.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_21_bn1_running_var: BUFFER target='features_extractor.6.21.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_21_bn1_num_batches_tracked: BUFFER target='features_extractor.6.21.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_21_bn2_running_mean: BUFFER target='features_extractor.6.21.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_21_bn2_running_var: BUFFER target='features_extractor.6.21.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_21_bn2_num_batches_tracked: BUFFER target='features_extractor.6.21.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_21_bn3_running_mean: BUFFER target='features_extractor.6.21.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_21_bn3_running_var: BUFFER target='features_extractor.6.21.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_21_bn3_num_batches_tracked: BUFFER target='features_extractor.6.21.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_22_bn1_running_mean: BUFFER target='features_extractor.6.22.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_22_bn1_running_var: BUFFER target='features_extractor.6.22.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_22_bn1_num_batches_tracked: BUFFER target='features_extractor.6.22.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_22_bn2_running_mean: BUFFER target='features_extractor.6.22.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_22_bn2_running_var: BUFFER target='features_extractor.6.22.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_22_bn2_num_batches_tracked: BUFFER target='features_extractor.6.22.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_22_bn3_running_mean: BUFFER target='features_extractor.6.22.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_22_bn3_running_var: BUFFER target='features_extractor.6.22.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_22_bn3_num_batches_tracked: BUFFER target='features_extractor.6.22.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_23_bn1_running_mean: BUFFER target='features_extractor.6.23.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_23_bn1_running_var: BUFFER target='features_extractor.6.23.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_23_bn1_num_batches_tracked: BUFFER target='features_extractor.6.23.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_23_bn2_running_mean: BUFFER target='features_extractor.6.23.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_23_bn2_running_var: BUFFER target='features_extractor.6.23.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_23_bn2_num_batches_tracked: BUFFER target='features_extractor.6.23.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_23_bn3_running_mean: BUFFER target='features_extractor.6.23.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_23_bn3_running_var: BUFFER target='features_extractor.6.23.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_23_bn3_num_batches_tracked: BUFFER target='features_extractor.6.23.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_24_bn1_running_mean: BUFFER target='features_extractor.6.24.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_24_bn1_running_var: BUFFER target='features_extractor.6.24.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_24_bn1_num_batches_tracked: BUFFER target='features_extractor.6.24.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_24_bn2_running_mean: BUFFER target='features_extractor.6.24.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_24_bn2_running_var: BUFFER target='features_extractor.6.24.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_24_bn2_num_batches_tracked: BUFFER target='features_extractor.6.24.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_24_bn3_running_mean: BUFFER target='features_extractor.6.24.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_24_bn3_running_var: BUFFER target='features_extractor.6.24.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_24_bn3_num_batches_tracked: BUFFER target='features_extractor.6.24.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_25_bn1_running_mean: BUFFER target='features_extractor.6.25.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_25_bn1_running_var: BUFFER target='features_extractor.6.25.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_25_bn1_num_batches_tracked: BUFFER target='features_extractor.6.25.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_25_bn2_running_mean: BUFFER target='features_extractor.6.25.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_25_bn2_running_var: BUFFER target='features_extractor.6.25.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_25_bn2_num_batches_tracked: BUFFER target='features_extractor.6.25.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_25_bn3_running_mean: BUFFER target='features_extractor.6.25.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_25_bn3_running_var: BUFFER target='features_extractor.6.25.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_25_bn3_num_batches_tracked: BUFFER target='features_extractor.6.25.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_26_bn1_running_mean: BUFFER target='features_extractor.6.26.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_26_bn1_running_var: BUFFER target='features_extractor.6.26.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_26_bn1_num_batches_tracked: BUFFER target='features_extractor.6.26.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_26_bn2_running_mean: BUFFER target='features_extractor.6.26.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_26_bn2_running_var: BUFFER target='features_extractor.6.26.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_26_bn2_num_batches_tracked: BUFFER target='features_extractor.6.26.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_26_bn3_running_mean: BUFFER target='features_extractor.6.26.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_26_bn3_running_var: BUFFER target='features_extractor.6.26.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_26_bn3_num_batches_tracked: BUFFER target='features_extractor.6.26.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_27_bn1_running_mean: BUFFER target='features_extractor.6.27.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_27_bn1_running_var: BUFFER target='features_extractor.6.27.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_27_bn1_num_batches_tracked: BUFFER target='features_extractor.6.27.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_27_bn2_running_mean: BUFFER target='features_extractor.6.27.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_27_bn2_running_var: BUFFER target='features_extractor.6.27.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_27_bn2_num_batches_tracked: BUFFER target='features_extractor.6.27.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_27_bn3_running_mean: BUFFER target='features_extractor.6.27.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_27_bn3_running_var: BUFFER target='features_extractor.6.27.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_27_bn3_num_batches_tracked: BUFFER target='features_extractor.6.27.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_28_bn1_running_mean: BUFFER target='features_extractor.6.28.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_28_bn1_running_var: BUFFER target='features_extractor.6.28.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_28_bn1_num_batches_tracked: BUFFER target='features_extractor.6.28.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_28_bn2_running_mean: BUFFER target='features_extractor.6.28.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_28_bn2_running_var: BUFFER target='features_extractor.6.28.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_28_bn2_num_batches_tracked: BUFFER target='features_extractor.6.28.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_28_bn3_running_mean: BUFFER target='features_extractor.6.28.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_28_bn3_running_var: BUFFER target='features_extractor.6.28.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_28_bn3_num_batches_tracked: BUFFER target='features_extractor.6.28.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_29_bn1_running_mean: BUFFER target='features_extractor.6.29.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_29_bn1_running_var: BUFFER target='features_extractor.6.29.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_29_bn1_num_batches_tracked: BUFFER target='features_extractor.6.29.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_29_bn2_running_mean: BUFFER target='features_extractor.6.29.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_29_bn2_running_var: BUFFER target='features_extractor.6.29.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_29_bn2_num_batches_tracked: BUFFER target='features_extractor.6.29.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_29_bn3_running_mean: BUFFER target='features_extractor.6.29.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_29_bn3_running_var: BUFFER target='features_extractor.6.29.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_29_bn3_num_batches_tracked: BUFFER target='features_extractor.6.29.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_30_bn1_running_mean: BUFFER target='features_extractor.6.30.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_30_bn1_running_var: BUFFER target='features_extractor.6.30.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_30_bn1_num_batches_tracked: BUFFER target='features_extractor.6.30.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_30_bn2_running_mean: BUFFER target='features_extractor.6.30.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_30_bn2_running_var: BUFFER target='features_extractor.6.30.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_30_bn2_num_batches_tracked: BUFFER target='features_extractor.6.30.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_30_bn3_running_mean: BUFFER target='features_extractor.6.30.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_30_bn3_running_var: BUFFER target='features_extractor.6.30.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_30_bn3_num_batches_tracked: BUFFER target='features_extractor.6.30.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_31_bn1_running_mean: BUFFER target='features_extractor.6.31.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_31_bn1_running_var: BUFFER target='features_extractor.6.31.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_31_bn1_num_batches_tracked: BUFFER target='features_extractor.6.31.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_31_bn2_running_mean: BUFFER target='features_extractor.6.31.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_31_bn2_running_var: BUFFER target='features_extractor.6.31.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_31_bn2_num_batches_tracked: BUFFER target='features_extractor.6.31.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_31_bn3_running_mean: BUFFER target='features_extractor.6.31.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_31_bn3_running_var: BUFFER target='features_extractor.6.31.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_31_bn3_num_batches_tracked: BUFFER target='features_extractor.6.31.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_32_bn1_running_mean: BUFFER target='features_extractor.6.32.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_32_bn1_running_var: BUFFER target='features_extractor.6.32.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_32_bn1_num_batches_tracked: BUFFER target='features_extractor.6.32.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_32_bn2_running_mean: BUFFER target='features_extractor.6.32.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_32_bn2_running_var: BUFFER target='features_extractor.6.32.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_32_bn2_num_batches_tracked: BUFFER target='features_extractor.6.32.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_32_bn3_running_mean: BUFFER target='features_extractor.6.32.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_32_bn3_running_var: BUFFER target='features_extractor.6.32.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_32_bn3_num_batches_tracked: BUFFER target='features_extractor.6.32.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_33_bn1_running_mean: BUFFER target='features_extractor.6.33.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_33_bn1_running_var: BUFFER target='features_extractor.6.33.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_33_bn1_num_batches_tracked: BUFFER target='features_extractor.6.33.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_33_bn2_running_mean: BUFFER target='features_extractor.6.33.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_33_bn2_running_var: BUFFER target='features_extractor.6.33.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_33_bn2_num_batches_tracked: BUFFER target='features_extractor.6.33.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_33_bn3_running_mean: BUFFER target='features_extractor.6.33.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_33_bn3_running_var: BUFFER target='features_extractor.6.33.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_33_bn3_num_batches_tracked: BUFFER target='features_extractor.6.33.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_34_bn1_running_mean: BUFFER target='features_extractor.6.34.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_34_bn1_running_var: BUFFER target='features_extractor.6.34.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_34_bn1_num_batches_tracked: BUFFER target='features_extractor.6.34.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_34_bn2_running_mean: BUFFER target='features_extractor.6.34.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_34_bn2_running_var: BUFFER target='features_extractor.6.34.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_34_bn2_num_batches_tracked: BUFFER target='features_extractor.6.34.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_34_bn3_running_mean: BUFFER target='features_extractor.6.34.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_34_bn3_running_var: BUFFER target='features_extractor.6.34.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_34_bn3_num_batches_tracked: BUFFER target='features_extractor.6.34.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_35_bn1_running_mean: BUFFER target='features_extractor.6.35.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_6_35_bn1_running_var: BUFFER target='features_extractor.6.35.bn1.running_var' persistent=True\n",
       "            b_features_extractor_6_35_bn1_num_batches_tracked: BUFFER target='features_extractor.6.35.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_35_bn2_running_mean: BUFFER target='features_extractor.6.35.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_6_35_bn2_running_var: BUFFER target='features_extractor.6.35.bn2.running_var' persistent=True\n",
       "            b_features_extractor_6_35_bn2_num_batches_tracked: BUFFER target='features_extractor.6.35.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_6_35_bn3_running_mean: BUFFER target='features_extractor.6.35.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_6_35_bn3_running_var: BUFFER target='features_extractor.6.35.bn3.running_var' persistent=True\n",
       "            b_features_extractor_6_35_bn3_num_batches_tracked: BUFFER target='features_extractor.6.35.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_0_bn1_running_mean: BUFFER target='features_extractor.7.0.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_7_0_bn1_running_var: BUFFER target='features_extractor.7.0.bn1.running_var' persistent=True\n",
       "            b_features_extractor_7_0_bn1_num_batches_tracked: BUFFER target='features_extractor.7.0.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_0_bn2_running_mean: BUFFER target='features_extractor.7.0.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_7_0_bn2_running_var: BUFFER target='features_extractor.7.0.bn2.running_var' persistent=True\n",
       "            b_features_extractor_7_0_bn2_num_batches_tracked: BUFFER target='features_extractor.7.0.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_0_bn3_running_mean: BUFFER target='features_extractor.7.0.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_7_0_bn3_running_var: BUFFER target='features_extractor.7.0.bn3.running_var' persistent=True\n",
       "            b_features_extractor_7_0_bn3_num_batches_tracked: BUFFER target='features_extractor.7.0.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_0_downsample_1_running_mean: BUFFER target='features_extractor.7.0.downsample.1.running_mean' persistent=True\n",
       "            b_features_extractor_7_0_downsample_1_running_var: BUFFER target='features_extractor.7.0.downsample.1.running_var' persistent=True\n",
       "            b_features_extractor_7_0_downsample_1_num_batches_tracked: BUFFER target='features_extractor.7.0.downsample.1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_1_bn1_running_mean: BUFFER target='features_extractor.7.1.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_7_1_bn1_running_var: BUFFER target='features_extractor.7.1.bn1.running_var' persistent=True\n",
       "            b_features_extractor_7_1_bn1_num_batches_tracked: BUFFER target='features_extractor.7.1.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_1_bn2_running_mean: BUFFER target='features_extractor.7.1.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_7_1_bn2_running_var: BUFFER target='features_extractor.7.1.bn2.running_var' persistent=True\n",
       "            b_features_extractor_7_1_bn2_num_batches_tracked: BUFFER target='features_extractor.7.1.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_1_bn3_running_mean: BUFFER target='features_extractor.7.1.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_7_1_bn3_running_var: BUFFER target='features_extractor.7.1.bn3.running_var' persistent=True\n",
       "            b_features_extractor_7_1_bn3_num_batches_tracked: BUFFER target='features_extractor.7.1.bn3.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_2_bn1_running_mean: BUFFER target='features_extractor.7.2.bn1.running_mean' persistent=True\n",
       "            b_features_extractor_7_2_bn1_running_var: BUFFER target='features_extractor.7.2.bn1.running_var' persistent=True\n",
       "            b_features_extractor_7_2_bn1_num_batches_tracked: BUFFER target='features_extractor.7.2.bn1.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_2_bn2_running_mean: BUFFER target='features_extractor.7.2.bn2.running_mean' persistent=True\n",
       "            b_features_extractor_7_2_bn2_running_var: BUFFER target='features_extractor.7.2.bn2.running_var' persistent=True\n",
       "            b_features_extractor_7_2_bn2_num_batches_tracked: BUFFER target='features_extractor.7.2.bn2.num_batches_tracked' persistent=True\n",
       "            b_features_extractor_7_2_bn3_running_mean: BUFFER target='features_extractor.7.2.bn3.running_mean' persistent=True\n",
       "            b_features_extractor_7_2_bn3_running_var: BUFFER target='features_extractor.7.2.bn3.running_var' persistent=True\n",
       "            b_features_extractor_7_2_bn3_num_batches_tracked: BUFFER target='features_extractor.7.2.bn3.num_batches_tracked' persistent=True\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {s77: VR[0, 65535]}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exporting to ONNX for serverles model deployment\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_path = \"food_classifier_resnet152_v2.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
