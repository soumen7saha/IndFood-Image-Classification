{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588d74fb-ae5c-4815-be9c-2d02ec4dc7f7",
   "metadata": {},
   "source": [
    "## Training using MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641901fa-8475-411a-a4d8-cd7b6c802b6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:28.429222Z",
     "iopub.status.busy": "2025-12-27T14:26:28.428318Z",
     "iopub.status.idle": "2025-12-27T14:26:28.434392Z",
     "shell.execute_reply": "2025-12-27T14:26:28.433359Z",
     "shell.execute_reply.started": "2025-12-27T14:26:28.429222Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a1be62-13f5-4d6b-b85a-d657fc1754d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:28.731520Z",
     "iopub.status.busy": "2025-12-27T14:26:28.730565Z",
     "iopub.status.idle": "2025-12-27T14:26:35.092666Z",
     "shell.execute_reply": "2025-12-27T14:26:35.092666Z",
     "shell.execute_reply.started": "2025-12-27T14:26:28.731520Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695ce271-7b41-461f-b991-eda5f9768164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:35.092666Z",
     "iopub.status.busy": "2025-12-27T14:26:35.092666Z",
     "iopub.status.idle": "2025-12-27T14:26:35.103387Z",
     "shell.execute_reply": "2025-12-27T14:26:35.100980Z",
     "shell.execute_reply.started": "2025-12-27T14:26:35.092666Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d43e04-8768-4b2a-9cd6-f0531a714f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:35.104948Z",
     "iopub.status.busy": "2025-12-27T14:26:35.104501Z",
     "iopub.status.idle": "2025-12-27T14:26:35.116396Z",
     "shell.execute_reply": "2025-12-27T14:26:35.116396Z",
     "shell.execute_reply.started": "2025-12-27T14:26:35.104948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1+cu126'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc915298-5d19-487d-a421-bcc81414408c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:47.729067Z",
     "iopub.status.busy": "2025-12-27T14:26:47.728065Z",
     "iopub.status.idle": "2025-12-27T14:26:47.770278Z",
     "shell.execute_reply": "2025-12-27T14:26:47.770278Z",
     "shell.execute_reply.started": "2025-12-27T14:26:47.729067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efea2f9b-993c-4ef9-8342-bdc05900de1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:50.043507Z",
     "iopub.status.busy": "2025-12-27T14:26:50.043507Z",
     "iopub.status.idle": "2025-12-27T14:26:50.049311Z",
     "shell.execute_reply": "2025-12-27T14:26:50.048299Z",
     "shell.execute_reply.started": "2025-12-27T14:26:50.043507Z"
    }
   },
   "outputs": [],
   "source": [
    "# models.resnet152(weights='IMAGENET1K_V2')\n",
    "# models.convnext_small(weights='IMAGENET1K_V1')\n",
    "# models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "# models.mobilenet_v2(weights='IMAGENET1K_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c7c09a-8195-46e6-8027-394fa8054356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:59.436291Z",
     "iopub.status.busy": "2025-12-27T14:26:59.434667Z",
     "iopub.status.idle": "2025-12-27T14:26:59.446170Z",
     "shell.execute_reply": "2025-12-27T14:26:59.445140Z",
     "shell.execute_reply.started": "2025-12-27T14:26:59.436200Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: i for i,cls in enumerate(self.classes)}\n",
    "\n",
    "        for label_name in self.classes:\n",
    "            label_dir = os.path.join(data_dir, label_name)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5299690-073a-4792-bb67-b73c25dd05db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:26:59.820507Z",
     "iopub.status.busy": "2025-12-27T14:26:59.819489Z",
     "iopub.status.idle": "2025-12-27T14:26:59.827468Z",
     "shell.execute_reply": "2025-12-27T14:26:59.826458Z",
     "shell.execute_reply.started": "2025-12-27T14:26:59.820507Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "\n",
    "# ImageNet Normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms - just resize and normalize\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((232, 232)),\n",
    "    transforms.RandomRotation(15),           # Rotate up to 10 degrees\n",
    "    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),  # Zoom\n",
    "    transforms.RandomHorizontalFlip(),       # Horizontal flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170995c6-6b81-43f8-8c0d-517c49dfb3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:00.552416Z",
     "iopub.status.busy": "2025-12-27T14:27:00.551405Z",
     "iopub.status.idle": "2025-12-27T14:27:01.072672Z",
     "shell.execute_reply": "2025-12-27T14:27:01.072672Z",
     "shell.execute_reply.started": "2025-12-27T14:27:00.552416Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = FoodDataset(\n",
    "    data_dir='./indfood-data/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = FoodDataset(\n",
    "    data_dir='./indfood-data/val',\n",
    "    transform=val_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb52fb68-4f94-4831-b4bf-9ba8e9401c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:01.681890Z",
     "iopub.status.busy": "2025-12-27T14:27:01.680887Z",
     "iopub.status.idle": "2025-12-27T14:27:01.702288Z",
     "shell.execute_reply": "2025-12-27T14:27:01.702288Z",
     "shell.execute_reply.started": "2025-12-27T14:27:01.681890Z"
    }
   },
   "outputs": [],
   "source": [
    "total_train_len = len(train_dataset)\n",
    "total_val_len = len(val_dataset)\n",
    "\n",
    "# Define the length of the smaller dataset you want to use\n",
    "subset_train_len = 5000\n",
    "subset_val_len = 800\n",
    "\n",
    "# Define the lengths for the split: [desired_length, remaining_length]\n",
    "train_lengths = [subset_train_len, total_train_len - subset_train_len]\n",
    "val_lengths = [subset_val_len, total_val_len - subset_val_len]\n",
    "\n",
    "# Randomly split the original dataset into two new datasets, You get a list of datasets; take the first one [0]\n",
    "smaller_train_dataset = random_split(train_dataset, train_lengths)[0]\n",
    "smaller_val_dataset = random_split(val_dataset, val_lengths)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99f3b675-07aa-4e21-947e-debf6922dee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:02.555245Z",
     "iopub.status.busy": "2025-12-27T14:27:02.555245Z",
     "iopub.status.idle": "2025-12-27T14:27:02.561690Z",
     "shell.execute_reply": "2025-12-27T14:27:02.561690Z",
     "shell.execute_reply.started": "2025-12-27T14:27:02.555245Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(smaller_train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(smaller_val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d2574d9-7bab-4ad1-9e03-67a903c1c5c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:02.937170Z",
     "iopub.status.busy": "2025-12-27T14:27:02.937170Z",
     "iopub.status.idle": "2025-12-27T14:27:02.944977Z",
     "shell.execute_reply": "2025-12-27T14:27:02.943959Z",
     "shell.execute_reply.started": "2025-12-27T14:27:02.937170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 800)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smaller_train_dataset), len(smaller_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f51df8a-527d-45cc-a73d-bb8b57ae3091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:03.508103Z",
     "iopub.status.busy": "2025-12-27T14:27:03.508103Z",
     "iopub.status.idle": "2025-12-27T14:27:03.520395Z",
     "shell.execute_reply": "2025-12-27T14:27:03.520395Z",
     "shell.execute_reply.started": "2025-12-27T14:27:03.508103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aloo_gobi',\n",
       " 'aloo_matar',\n",
       " 'aloo_methi',\n",
       " 'aloo_paratha',\n",
       " 'aloo_shimla_mirch',\n",
       " 'aloo_tikki',\n",
       " 'amritsari_kulcha',\n",
       " 'anda_curry',\n",
       " 'ariselu',\n",
       " 'balushahi',\n",
       " 'banana_chips',\n",
       " 'bandar_laddu',\n",
       " 'basundi',\n",
       " 'besan_laddu',\n",
       " 'bhindi_masala',\n",
       " 'biryani',\n",
       " 'boondi',\n",
       " 'boondi_laddu',\n",
       " 'butter_chicken',\n",
       " 'chaas',\n",
       " 'chak_hao_kheer',\n",
       " 'cham_cham',\n",
       " 'chana_masala',\n",
       " 'chapati',\n",
       " 'chicken_pizza',\n",
       " 'chicken_razala',\n",
       " 'chicken_tikka',\n",
       " 'chicken_tikka_masala',\n",
       " 'chicken_wings',\n",
       " 'chikki',\n",
       " 'chivda',\n",
       " 'chole_bhature',\n",
       " 'daal_baati_churma',\n",
       " 'daal_puri',\n",
       " 'dabeli',\n",
       " 'dal_khichdi',\n",
       " 'dal_makhani',\n",
       " 'dal_tadka',\n",
       " 'dharwad_pedha',\n",
       " 'dhokla',\n",
       " 'double_ka_meetha',\n",
       " 'dum_aloo',\n",
       " 'falooda',\n",
       " 'fish_curry',\n",
       " 'gajar_ka_halwa',\n",
       " 'garlic_bread',\n",
       " 'gavvalu',\n",
       " 'ghevar',\n",
       " 'grilled_sandwich',\n",
       " 'gujhia',\n",
       " 'gulab_jamun',\n",
       " 'hara_bhara_kabab',\n",
       " 'idiyappam',\n",
       " 'idli',\n",
       " 'imarti',\n",
       " 'jalebi',\n",
       " 'kachori',\n",
       " 'kadai_paneer',\n",
       " 'kadhi_pakoda',\n",
       " 'kaju_katli',\n",
       " 'kakinada_khaja',\n",
       " 'kalakand',\n",
       " 'karela_bharta',\n",
       " 'khakhra',\n",
       " 'kheer',\n",
       " 'kofta',\n",
       " 'kulfi',\n",
       " 'lassi',\n",
       " 'ledikeni',\n",
       " 'litti_chokha',\n",
       " 'lyangcha',\n",
       " 'maach_jhol',\n",
       " 'makki_di_roti_sarson_da_saag',\n",
       " 'malpua',\n",
       " 'margherita_pizza',\n",
       " 'masala_dosa',\n",
       " 'masala_papad',\n",
       " 'medu_vada',\n",
       " 'misal_pav',\n",
       " 'misi_roti',\n",
       " 'misti_doi',\n",
       " 'modak',\n",
       " 'moong_dal_halwa',\n",
       " 'murukku',\n",
       " 'mysore_pak',\n",
       " 'naan',\n",
       " 'navratan_korma',\n",
       " 'neer_dosa',\n",
       " 'onion_pakoda',\n",
       " 'palak_paneer',\n",
       " 'paneer_masala',\n",
       " 'paneer_pizza',\n",
       " 'pani_puri',\n",
       " 'paniyaram',\n",
       " 'papdi_chaat',\n",
       " 'patrode',\n",
       " 'pav_bhaji',\n",
       " 'pepperoni_pizza',\n",
       " 'phirni',\n",
       " 'pithe',\n",
       " 'poha',\n",
       " 'pongal',\n",
       " 'poornalu',\n",
       " 'pootharekulu',\n",
       " 'puri_bhaji',\n",
       " 'qubani_ka_meetha',\n",
       " 'rabri',\n",
       " 'rajma_chawal',\n",
       " 'ras_malai',\n",
       " 'rasgulla',\n",
       " 'rava_dosa',\n",
       " 'sabudana_khichdi',\n",
       " 'sabudana_vada',\n",
       " 'samosa',\n",
       " 'sandesh',\n",
       " 'seekh_kebab',\n",
       " 'set_dosa',\n",
       " 'sev_puri',\n",
       " 'shankarpali',\n",
       " 'sheer_korma',\n",
       " 'sheera',\n",
       " 'shrikhand',\n",
       " 'soan_papdi',\n",
       " 'solkadhi',\n",
       " 'steamed_momo',\n",
       " 'sutar_feni',\n",
       " 'thali',\n",
       " 'thukpa',\n",
       " 'unni_appam',\n",
       " 'uttapam',\n",
       " 'vada_pav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_dataset.class_to_idx)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e91c78e-69a2-48a2-813a-3accfe83b1bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:04.022779Z",
     "iopub.status.busy": "2025-12-27T14:27:04.022779Z",
     "iopub.status.idle": "2025-12-27T14:27:04.030060Z",
     "shell.execute_reply": "2025-12-27T14:27:04.029027Z",
     "shell.execute_reply.started": "2025-12-27T14:27:04.022779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e48f9d9a-739a-4e0c-a912-6a58fff8bc61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T14:43:54.066651Z",
     "iopub.status.busy": "2025-12-26T14:43:54.065600Z",
     "iopub.status.idle": "2025-12-26T14:43:54.076716Z",
     "shell.execute_reply": "2025-12-26T14:43:54.074668Z",
     "shell.execute_reply.started": "2025-12-26T14:43:54.066651Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodClassifierMobileNet(nn.Module):\n",
    "    def __init__(self, num_classes=131):\n",
    "        super(FoodClassifierMobileNet, self).__init__()\n",
    "\n",
    "        # load pre-trained mobilenet_v2\n",
    "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "\n",
    "        # freeze base model parameters\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove original classifier\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "\n",
    "        # add custom layers\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.output_layer = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a112f7a4-cee7-45e3-8f49-2d503b30dca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T14:43:55.034862Z",
     "iopub.status.busy": "2025-12-26T14:43:55.034862Z",
     "iopub.status.idle": "2025-12-26T14:43:55.165839Z",
     "shell.execute_reply": "2025-12-26T14:43:55.165839Z",
     "shell.execute_reply.started": "2025-12-26T14:43:55.034862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FoodClassifierMobileNet(\n",
       "  (base_model): MobileNetV2(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (16): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (17): InvertedResidual(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (18): Conv2dNormActivation(\n",
       "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (global_avg_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (output_layer): Linear(in_features=1280, out_features=131, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FoodClassifierMobileNet(num_classes=131)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4dcb8be-82e5-4632-b9fe-f0d25b485649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:29.726126Z",
     "iopub.status.busy": "2025-12-27T14:27:29.726126Z",
     "iopub.status.idle": "2025-12-27T14:27:29.732290Z",
     "shell.execute_reply": "2025-12-27T14:27:29.731265Z",
     "shell.execute_reply.started": "2025-12-27T14:27:29.726126Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238757f8-e143-4319-8825-731b7fc6dd43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:30.183494Z",
     "iopub.status.busy": "2025-12-27T14:27:30.183494Z",
     "iopub.status.idle": "2025-12-27T14:27:30.190215Z",
     "shell.execute_reply": "2025-12-27T14:27:30.189106Z",
     "shell.execute_reply.started": "2025-12-27T14:27:30.183494Z"
    }
   },
   "outputs": [],
   "source": [
    "# tuning the learning rate\n",
    "def make_model(learning_rate=0.01):\n",
    "    model = FoodClassifierMobileNet(num_classes=131)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db73c17-c927-4412-911c-a8e2be894bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:30.663180Z",
     "iopub.status.busy": "2025-12-27T14:27:30.662180Z",
     "iopub.status.idle": "2025-12-27T14:27:30.675104Z",
     "shell.execute_reply": "2025-12-27T14:27:30.673329Z",
     "shell.execute_reply.started": "2025-12-27T14:27:30.663180Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device):\n",
    "    best_val_accuracy = 0.0  # Initialize variable to track the best validation accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            checkpoint_path = f'food_mobilenet_v12_{epoch+1:02d}_{val_acc:.3f}.pth'\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Checkpoint saved: {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c961dd-45a3-4f79-a818-85802bf481a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tuning the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aebf1d6b-40fb-4e60-b0ae-10f2cfbf98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T14:44:50.143561Z",
     "iopub.status.busy": "2025-12-26T14:44:50.142561Z",
     "iopub.status.idle": "2025-12-26T15:37:20.016624Z",
     "shell.execute_reply": "2025-12-26T15:37:20.016287Z",
     "shell.execute_reply.started": "2025-12-26T14:44:50.143561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.1\n",
      "Epoch 1/10\n",
      "  Train Loss: 15.6091, Train Acc: 0.3356\n",
      "  Val Loss: 12.1315, Val Acc: 0.4238\n",
      "Checkpoint saved: food_mobilenet_v11_01_0.424.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 10.0580, Train Acc: 0.4986\n",
      "  Val Loss: 12.7408, Val Acc: 0.4662\n",
      "Checkpoint saved: food_mobilenet_v11_02_0.466.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 8.7136, Train Acc: 0.5838\n",
      "  Val Loss: 15.1680, Val Acc: 0.4550\n",
      "Epoch 4/10\n",
      "  Train Loss: 8.0598, Train Acc: 0.6072\n",
      "  Val Loss: 17.3433, Val Acc: 0.4575\n",
      "Epoch 5/10\n",
      "  Train Loss: 7.7045, Train Acc: 0.6482\n",
      "  Val Loss: 17.6519, Val Acc: 0.5025\n",
      "Checkpoint saved: food_mobilenet_v11_05_0.502.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 7.1766, Train Acc: 0.6606\n",
      "  Val Loss: 20.0583, Val Acc: 0.4537\n",
      "Epoch 7/10\n",
      "  Train Loss: 7.9855, Train Acc: 0.6716\n",
      "  Val Loss: 19.1760, Val Acc: 0.5175\n",
      "Checkpoint saved: food_mobilenet_v11_07_0.517.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 6.6399, Train Acc: 0.7036\n",
      "  Val Loss: 21.0723, Val Acc: 0.5062\n",
      "Epoch 9/10\n",
      "  Train Loss: 7.1124, Train Acc: 0.7024\n",
      "  Val Loss: 19.7149, Val Acc: 0.5200\n",
      "Checkpoint saved: food_mobilenet_v11_09_0.520.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 6.8699, Train Acc: 0.7194\n",
      "  Val Loss: 22.0946, Val Acc: 0.5225\n",
      "Checkpoint saved: food_mobilenet_v11_10_0.522.pth\n",
      "\n",
      "\n",
      "learning rate = 0.01\n",
      "Epoch 1/10\n",
      "  Train Loss: 2.6110, Train Acc: 0.4272\n",
      "  Val Loss: 2.0087, Val Acc: 0.5125\n",
      "Checkpoint saved: food_mobilenet_v11_01_0.512.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 1.3689, Train Acc: 0.6314\n",
      "  Val Loss: 2.1020, Val Acc: 0.5387\n",
      "Checkpoint saved: food_mobilenet_v11_02_0.539.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.1421, Train Acc: 0.6774\n",
      "  Val Loss: 2.1847, Val Acc: 0.5350\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.9948, Train Acc: 0.7144\n",
      "  Val Loss: 2.3307, Val Acc: 0.5125\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.8790, Train Acc: 0.7494\n",
      "  Val Loss: 2.3314, Val Acc: 0.5437\n",
      "Checkpoint saved: food_mobilenet_v11_05_0.544.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.8870, Train Acc: 0.7458\n",
      "  Val Loss: 2.2678, Val Acc: 0.5863\n",
      "Checkpoint saved: food_mobilenet_v11_06_0.586.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.8168, Train Acc: 0.7704\n",
      "  Val Loss: 2.4477, Val Acc: 0.5487\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.7974, Train Acc: 0.7752\n",
      "  Val Loss: 2.5901, Val Acc: 0.5363\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.7833, Train Acc: 0.7752\n",
      "  Val Loss: 2.6680, Val Acc: 0.5375\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.7398, Train Acc: 0.7884\n",
      "  Val Loss: 2.7282, Val Acc: 0.5387\n",
      "\n",
      "\n",
      "learning rate = 0.001\n",
      "Epoch 1/10\n",
      "  Train Loss: 3.1950, Train Acc: 0.3044\n",
      "  Val Loss: 2.7206, Val Acc: 0.3925\n",
      "Checkpoint saved: food_mobilenet_v11_01_0.393.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.1178, Train Acc: 0.5294\n",
      "  Val Loss: 2.2742, Val Acc: 0.4650\n",
      "Checkpoint saved: food_mobilenet_v11_02_0.465.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.6932, Train Acc: 0.6066\n",
      "  Val Loss: 2.0042, Val Acc: 0.5375\n",
      "Checkpoint saved: food_mobilenet_v11_03_0.537.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.4509, Train Acc: 0.6510\n",
      "  Val Loss: 1.8454, Val Acc: 0.5563\n",
      "Checkpoint saved: food_mobilenet_v11_04_0.556.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.2899, Train Acc: 0.6862\n",
      "  Val Loss: 1.7794, Val Acc: 0.5775\n",
      "Checkpoint saved: food_mobilenet_v11_05_0.578.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.1509, Train Acc: 0.7126\n",
      "  Val Loss: 1.6927, Val Acc: 0.5837\n",
      "Checkpoint saved: food_mobilenet_v11_06_0.584.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.0650, Train Acc: 0.7340\n",
      "  Val Loss: 1.6596, Val Acc: 0.5813\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.0145, Train Acc: 0.7434\n",
      "  Val Loss: 1.6348, Val Acc: 0.6025\n",
      "Checkpoint saved: food_mobilenet_v11_08_0.603.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.9356, Train Acc: 0.7598\n",
      "  Val Loss: 1.6193, Val Acc: 0.5962\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.8809, Train Acc: 0.7728\n",
      "  Val Loss: 1.6203, Val Acc: 0.6025\n",
      "\n",
      "\n",
      "learning rate = 0.0001\n",
      "Epoch 1/10\n",
      "  Train Loss: 4.1968, Train Acc: 0.0880\n",
      "  Val Loss: 3.9338, Val Acc: 0.1400\n",
      "Checkpoint saved: food_mobilenet_v11_01_0.140.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 3.6740, Train Acc: 0.1992\n",
      "  Val Loss: 3.6702, Val Acc: 0.2112\n",
      "Checkpoint saved: food_mobilenet_v11_02_0.211.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 3.4365, Train Acc: 0.2724\n",
      "  Val Loss: 3.5025, Val Acc: 0.2450\n",
      "Checkpoint saved: food_mobilenet_v11_03_0.245.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 3.2282, Train Acc: 0.3164\n",
      "  Val Loss: 3.3277, Val Acc: 0.2850\n",
      "Checkpoint saved: food_mobilenet_v11_04_0.285.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 3.0558, Train Acc: 0.3572\n",
      "  Val Loss: 3.1934, Val Acc: 0.3050\n",
      "Checkpoint saved: food_mobilenet_v11_05_0.305.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 2.9002, Train Acc: 0.3892\n",
      "  Val Loss: 3.0819, Val Acc: 0.3287\n",
      "Checkpoint saved: food_mobilenet_v11_06_0.329.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 2.7653, Train Acc: 0.4132\n",
      "  Val Loss: 2.9653, Val Acc: 0.3538\n",
      "Checkpoint saved: food_mobilenet_v11_07_0.354.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 2.6421, Train Acc: 0.4432\n",
      "  Val Loss: 2.8711, Val Acc: 0.3613\n",
      "Checkpoint saved: food_mobilenet_v11_08_0.361.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 2.5260, Train Acc: 0.4620\n",
      "  Val Loss: 2.7657, Val Acc: 0.3875\n",
      "Checkpoint saved: food_mobilenet_v11_09_0.388.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 2.4210, Train Acc: 0.4780\n",
      "  Val Loss: 2.7156, Val Acc: 0.3987\n",
      "Checkpoint saved: food_mobilenet_v11_10_0.399.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    print(\"learning rate =\", lr)\n",
    "    model, optimizer = make_model(lr)\n",
    "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3bb0061-95d2-473b-b206-3b8e5d237b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:42:46.905050Z",
     "iopub.status.busy": "2025-12-26T15:42:46.904011Z",
     "iopub.status.idle": "2025-12-26T15:42:46.910882Z",
     "shell.execute_reply": "2025-12-26T15:42:46.908820Z",
     "shell.execute_reply.started": "2025-12-26T15:42:46.905050Z"
    }
   },
   "outputs": [],
   "source": [
    "# best lr : 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847d48a-4492-40ae-8d05-39ad29336560",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tuning the Number of Inner Layers to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60c998f4-c449-4059-996c-38f49cdcf0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:39.840006Z",
     "iopub.status.busy": "2025-12-27T14:27:39.838935Z",
     "iopub.status.idle": "2025-12-27T14:27:39.848811Z",
     "shell.execute_reply": "2025-12-27T14:27:39.847563Z",
     "shell.execute_reply.started": "2025-12-27T14:27:39.840006Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodClassifierMobileNet(nn.Module):\n",
    "    def __init__(self, size_inner=100, num_classes=131):\n",
    "        super(FoodClassifierMobileNet, self).__init__()\n",
    "\n",
    "        # load pre-trained mobilenet_v2\n",
    "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "\n",
    "        # freeze base model parameters\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove original classifier\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "\n",
    "        # add custom layers\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # add inner layers\n",
    "        self.inner = nn.Linear(1280, size_inner)  # New inner layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.inner(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_model(\n",
    "        learning_rate=0.01,\n",
    "        size_inner=100\n",
    "):\n",
    "    model = FoodClassifierMobileNet(\n",
    "        num_classes=131,\n",
    "        size_inner=size_inner\n",
    "    )\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7055760-ab52-4751-ac07-22646005d9b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T14:27:43.100005Z",
     "iopub.status.busy": "2025-12-27T14:27:43.098750Z",
     "iopub.status.idle": "2025-12-27T16:15:53.117985Z",
     "shell.execute_reply": "2025-12-27T16:15:53.109319Z",
     "shell.execute_reply.started": "2025-12-27T14:27:43.100005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_inner : 1000\n",
      "Epoch 1/10\n",
      "  Train Loss: 2.8275, Train Acc: 0.3644\n",
      "  Val Loss: 2.1877, Val Acc: 0.4450\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.445.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 1.7432, Train Acc: 0.5574\n",
      "  Val Loss: 1.7905, Val Acc: 0.5325\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.532.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.4374, Train Acc: 0.6176\n",
      "  Val Loss: 1.6958, Val Acc: 0.5563\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.556.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.2261, Train Acc: 0.6646\n",
      "  Val Loss: 1.6512, Val Acc: 0.5713\n",
      "Checkpoint saved: food_mobilenet_v12_04_0.571.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.0648, Train Acc: 0.7038\n",
      "  Val Loss: 1.5784, Val Acc: 0.5763\n",
      "Checkpoint saved: food_mobilenet_v12_05_0.576.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.9597, Train Acc: 0.7276\n",
      "  Val Loss: 1.6305, Val Acc: 0.5700\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.8676, Train Acc: 0.7518\n",
      "  Val Loss: 1.5895, Val Acc: 0.5737\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.7869, Train Acc: 0.7716\n",
      "  Val Loss: 1.6780, Val Acc: 0.5700\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.7210, Train Acc: 0.7858\n",
      "  Val Loss: 1.6956, Val Acc: 0.5725\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.6390, Train Acc: 0.8156\n",
      "  Val Loss: 1.5530, Val Acc: 0.6162\n",
      "Checkpoint saved: food_mobilenet_v12_10_0.616.pth\n",
      "\n",
      "size_inner : 500\n",
      "Epoch 1/10\n",
      "  Train Loss: 2.9618, Train Acc: 0.3404\n",
      "  Val Loss: 2.3296, Val Acc: 0.4587\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.459.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 1.8333, Train Acc: 0.5430\n",
      "  Val Loss: 1.8541, Val Acc: 0.5400\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.540.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.4507, Train Acc: 0.6162\n",
      "  Val Loss: 1.7410, Val Acc: 0.5563\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.556.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.3118, Train Acc: 0.6448\n",
      "  Val Loss: 1.6454, Val Acc: 0.5850\n",
      "Checkpoint saved: food_mobilenet_v12_04_0.585.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.1468, Train Acc: 0.6816\n",
      "  Val Loss: 1.6685, Val Acc: 0.5513\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.0212, Train Acc: 0.7088\n",
      "  Val Loss: 1.6102, Val Acc: 0.5787\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.9624, Train Acc: 0.7296\n",
      "  Val Loss: 1.5267, Val Acc: 0.6112\n",
      "Checkpoint saved: food_mobilenet_v12_07_0.611.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.8646, Train Acc: 0.7450\n",
      "  Val Loss: 1.5859, Val Acc: 0.5975\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.8280, Train Acc: 0.7590\n",
      "  Val Loss: 1.6182, Val Acc: 0.6088\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.7486, Train Acc: 0.7780\n",
      "  Val Loss: 1.6071, Val Acc: 0.6025\n",
      "\n",
      "size_inner : 200\n",
      "Epoch 1/10\n",
      "  Train Loss: 3.1829, Train Acc: 0.3146\n",
      "  Val Loss: 2.5498, Val Acc: 0.4300\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.430.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.0569, Train Acc: 0.5186\n",
      "  Val Loss: 2.0023, Val Acc: 0.5212\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.521.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.6617, Train Acc: 0.5778\n",
      "  Val Loss: 1.8314, Val Acc: 0.5350\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.535.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.4614, Train Acc: 0.6198\n",
      "  Val Loss: 1.7037, Val Acc: 0.5725\n",
      "Checkpoint saved: food_mobilenet_v12_04_0.573.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.3041, Train Acc: 0.6546\n",
      "  Val Loss: 1.6278, Val Acc: 0.5675\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.1668, Train Acc: 0.6800\n",
      "  Val Loss: 1.6075, Val Acc: 0.5813\n",
      "Checkpoint saved: food_mobilenet_v12_06_0.581.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.0931, Train Acc: 0.6990\n",
      "  Val Loss: 1.6136, Val Acc: 0.5663\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.0389, Train Acc: 0.7172\n",
      "  Val Loss: 1.5876, Val Acc: 0.5850\n",
      "Checkpoint saved: food_mobilenet_v12_08_0.585.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.9511, Train Acc: 0.7308\n",
      "  Val Loss: 1.5780, Val Acc: 0.5837\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.9066, Train Acc: 0.7432\n",
      "  Val Loss: 1.5822, Val Acc: 0.5813\n",
      "\n",
      "size_inner : 100\n",
      "Epoch 1/10\n",
      "  Train Loss: 3.4941, Train Acc: 0.2500\n",
      "  Val Loss: 2.9509, Val Acc: 0.3625\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.362.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.3828, Train Acc: 0.4668\n",
      "  Val Loss: 2.3488, Val Acc: 0.4525\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.453.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.9385, Train Acc: 0.5412\n",
      "  Val Loss: 2.0723, Val Acc: 0.4888\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.489.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.6688, Train Acc: 0.5766\n",
      "  Val Loss: 1.8943, Val Acc: 0.5275\n",
      "Checkpoint saved: food_mobilenet_v12_04_0.527.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.5247, Train Acc: 0.6110\n",
      "  Val Loss: 1.7673, Val Acc: 0.5350\n",
      "Checkpoint saved: food_mobilenet_v12_05_0.535.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.4076, Train Acc: 0.6236\n",
      "  Val Loss: 1.7270, Val Acc: 0.5550\n",
      "Checkpoint saved: food_mobilenet_v12_06_0.555.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.3006, Train Acc: 0.6572\n",
      "  Val Loss: 1.6455, Val Acc: 0.5637\n",
      "Checkpoint saved: food_mobilenet_v12_07_0.564.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.2357, Train Acc: 0.6648\n",
      "  Val Loss: 1.6444, Val Acc: 0.5637\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.1700, Train Acc: 0.6868\n",
      "  Val Loss: 1.6555, Val Acc: 0.5663\n",
      "Checkpoint saved: food_mobilenet_v12_09_0.566.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.1046, Train Acc: 0.6920\n",
      "  Val Loss: 1.5759, Val Acc: 0.5887\n",
      "Checkpoint saved: food_mobilenet_v12_10_0.589.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for size_inner in [1000, 500, 200, 100]:\n",
    "    print(f\"size_inner : {size_inner}\")\n",
    "    model, optimizer = make_model(\n",
    "        learning_rate=0.001,\n",
    "        size_inner=size_inner\n",
    "    )\n",
    "    \n",
    "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba9a4f1-49c2-4aa9-93f5-718bb420a336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T20:54:35.864587Z",
     "iopub.status.busy": "2025-12-27T20:54:35.863008Z",
     "iopub.status.idle": "2025-12-27T20:54:35.870510Z",
     "shell.execute_reply": "2025-12-27T20:54:35.869502Z",
     "shell.execute_reply.started": "2025-12-27T20:54:35.864587Z"
    }
   },
   "outputs": [],
   "source": [
    "# best inner layers size : 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59c469-5738-42df-9b9e-7f6626e4affb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tuning the Drop Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "593fec61-d9e0-42c3-ae7f-1e199bd0e443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T20:56:16.664658Z",
     "iopub.status.busy": "2025-12-27T20:56:16.661658Z",
     "iopub.status.idle": "2025-12-27T20:56:16.712997Z",
     "shell.execute_reply": "2025-12-27T20:56:16.706980Z",
     "shell.execute_reply.started": "2025-12-27T20:56:16.663658Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodClassifierMobileNet(nn.Module):\n",
    "    def __init__(self, size_inner=100, droprate=0.2, num_classes=131):\n",
    "        super(FoodClassifierMobileNet, self).__init__()\n",
    "\n",
    "        # load pre-trained mobilenet_v2\n",
    "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V2')\n",
    "\n",
    "        # freeze base model parameters\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove original classifier\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "\n",
    "        # add custom layers\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # add inner layers\n",
    "        self.inner = nn.Linear(1280, size_inner)  # New inner layer\n",
    "        self.relu = nn.ReLU()\n",
    "        # add dropout\n",
    "        self.dropout = nn.Dropout(droprate)\n",
    "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.inner(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # apply dropout\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_model(\n",
    "        learning_rate=0.01,\n",
    "        size_inner=1000,\n",
    "        droprate=0.2\n",
    "):\n",
    "    model = FoodClassifierMobileNet(\n",
    "        num_classes=131,\n",
    "        size_inner=size_inner,\n",
    "        droprate=droprate\n",
    "    )\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "751e21d3-c821-41c0-b1dd-caaca99c9d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T20:56:17.500416Z",
     "iopub.status.busy": "2025-12-27T20:56:17.499417Z",
     "iopub.status.idle": "2025-12-28T02:47:04.018563Z",
     "shell.execute_reply": "2025-12-28T02:47:04.018563Z",
     "shell.execute_reply.started": "2025-12-27T20:56:17.500416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_rate : 0.1\n",
      "Epoch 1/50\n",
      "  Train Loss: 2.8504, Train Acc: 0.3514\n",
      "  Val Loss: 2.2383, Val Acc: 0.4363\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.436.pth\n",
      "Epoch 2/50\n",
      "  Train Loss: 1.7720, Train Acc: 0.5558\n",
      "  Val Loss: 1.8477, Val Acc: 0.5363\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.536.pth\n",
      "Epoch 3/50\n",
      "  Train Loss: 1.4165, Train Acc: 0.6214\n",
      "  Val Loss: 1.7015, Val Acc: 0.5613\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.561.pth\n",
      "Epoch 4/50\n",
      "  Train Loss: 1.2411, Train Acc: 0.6568\n",
      "  Val Loss: 1.6817, Val Acc: 0.5413\n",
      "Epoch 5/50\n",
      "  Train Loss: 1.0813, Train Acc: 0.6900\n",
      "  Val Loss: 1.6409, Val Acc: 0.5613\n",
      "Epoch 6/50\n",
      "  Train Loss: 0.9880, Train Acc: 0.7160\n",
      "  Val Loss: 1.5979, Val Acc: 0.5962\n",
      "Checkpoint saved: food_mobilenet_v12_06_0.596.pth\n",
      "Epoch 7/50\n",
      "  Train Loss: 0.8865, Train Acc: 0.7384\n",
      "  Val Loss: 1.5938, Val Acc: 0.5988\n",
      "Checkpoint saved: food_mobilenet_v12_07_0.599.pth\n",
      "Epoch 8/50\n",
      "  Train Loss: 0.8206, Train Acc: 0.7640\n",
      "  Val Loss: 1.6362, Val Acc: 0.5850\n",
      "Epoch 9/50\n",
      "  Train Loss: 0.7505, Train Acc: 0.7766\n",
      "  Val Loss: 1.6458, Val Acc: 0.5775\n",
      "Epoch 10/50\n",
      "  Train Loss: 0.7212, Train Acc: 0.7868\n",
      "  Val Loss: 1.6057, Val Acc: 0.5813\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.6521, Train Acc: 0.8030\n",
      "  Val Loss: 1.6928, Val Acc: 0.5650\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.5969, Train Acc: 0.8190\n",
      "  Val Loss: 1.6805, Val Acc: 0.5687\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.5776, Train Acc: 0.8194\n",
      "  Val Loss: 1.6732, Val Acc: 0.5975\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.5252, Train Acc: 0.8394\n",
      "  Val Loss: 1.7056, Val Acc: 0.5925\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.4755, Train Acc: 0.8616\n",
      "  Val Loss: 1.6386, Val Acc: 0.6038\n",
      "Checkpoint saved: food_mobilenet_v12_15_0.604.pth\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.4742, Train Acc: 0.8530\n",
      "  Val Loss: 1.6602, Val Acc: 0.5938\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.4331, Train Acc: 0.8628\n",
      "  Val Loss: 1.8022, Val Acc: 0.5863\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.4200, Train Acc: 0.8710\n",
      "  Val Loss: 1.7590, Val Acc: 0.6025\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.4127, Train Acc: 0.8736\n",
      "  Val Loss: 1.8701, Val Acc: 0.5787\n",
      "Epoch 20/50\n",
      "  Train Loss: 0.4155, Train Acc: 0.8708\n",
      "  Val Loss: 1.7534, Val Acc: 0.5975\n",
      "Epoch 21/50\n",
      "  Train Loss: 0.3953, Train Acc: 0.8750\n",
      "  Val Loss: 1.8573, Val Acc: 0.5763\n",
      "Epoch 22/50\n",
      "  Train Loss: 0.3429, Train Acc: 0.8920\n",
      "  Val Loss: 1.8623, Val Acc: 0.5763\n",
      "Epoch 23/50\n",
      "  Train Loss: 0.3249, Train Acc: 0.9010\n",
      "  Val Loss: 1.8968, Val Acc: 0.5763\n",
      "Epoch 24/50\n",
      "  Train Loss: 0.3269, Train Acc: 0.8996\n",
      "  Val Loss: 1.8200, Val Acc: 0.5875\n",
      "Epoch 25/50\n",
      "  Train Loss: 0.3177, Train Acc: 0.9000\n",
      "  Val Loss: 1.8094, Val Acc: 0.5975\n",
      "Epoch 26/50\n",
      "  Train Loss: 0.2996, Train Acc: 0.9082\n",
      "  Val Loss: 1.9607, Val Acc: 0.5863\n",
      "Epoch 27/50\n",
      "  Train Loss: 0.3090, Train Acc: 0.9084\n",
      "  Val Loss: 1.9152, Val Acc: 0.5737\n",
      "Epoch 28/50\n",
      "  Train Loss: 0.2870, Train Acc: 0.9112\n",
      "  Val Loss: 1.9399, Val Acc: 0.5900\n",
      "Epoch 29/50\n",
      "  Train Loss: 0.2664, Train Acc: 0.9176\n",
      "  Val Loss: 1.9179, Val Acc: 0.5988\n",
      "Epoch 30/50\n",
      "  Train Loss: 0.2739, Train Acc: 0.9170\n",
      "  Val Loss: 1.9445, Val Acc: 0.5950\n",
      "Epoch 31/50\n",
      "  Train Loss: 0.2646, Train Acc: 0.9150\n",
      "  Val Loss: 1.9780, Val Acc: 0.5875\n",
      "Epoch 32/50\n",
      "  Train Loss: 0.2692, Train Acc: 0.9180\n",
      "  Val Loss: 1.9824, Val Acc: 0.5863\n",
      "Epoch 33/50\n",
      "  Train Loss: 0.2460, Train Acc: 0.9248\n",
      "  Val Loss: 2.0307, Val Acc: 0.5887\n",
      "Epoch 34/50\n",
      "  Train Loss: 0.2395, Train Acc: 0.9268\n",
      "  Val Loss: 2.1164, Val Acc: 0.5737\n",
      "Epoch 35/50\n",
      "  Train Loss: 0.2265, Train Acc: 0.9282\n",
      "  Val Loss: 2.1364, Val Acc: 0.5837\n",
      "Epoch 36/50\n",
      "  Train Loss: 0.2330, Train Acc: 0.9314\n",
      "  Val Loss: 2.1275, Val Acc: 0.5863\n",
      "Epoch 37/50\n",
      "  Train Loss: 0.2359, Train Acc: 0.9256\n",
      "  Val Loss: 1.9708, Val Acc: 0.5725\n",
      "Epoch 38/50\n",
      "  Train Loss: 0.2273, Train Acc: 0.9270\n",
      "  Val Loss: 2.1825, Val Acc: 0.5763\n",
      "Epoch 39/50\n",
      "  Train Loss: 0.2165, Train Acc: 0.9286\n",
      "  Val Loss: 2.1752, Val Acc: 0.5863\n",
      "Epoch 40/50\n",
      "  Train Loss: 0.2203, Train Acc: 0.9324\n",
      "  Val Loss: 2.1584, Val Acc: 0.5938\n",
      "Epoch 41/50\n",
      "  Train Loss: 0.2246, Train Acc: 0.9292\n",
      "  Val Loss: 2.0901, Val Acc: 0.5775\n",
      "Epoch 42/50\n",
      "  Train Loss: 0.2142, Train Acc: 0.9360\n",
      "  Val Loss: 2.2437, Val Acc: 0.5450\n",
      "Epoch 43/50\n",
      "  Train Loss: 0.1862, Train Acc: 0.9410\n",
      "  Val Loss: 2.2651, Val Acc: 0.5737\n",
      "Epoch 44/50\n",
      "  Train Loss: 0.1775, Train Acc: 0.9372\n",
      "  Val Loss: 2.1247, Val Acc: 0.6038\n",
      "Epoch 45/50\n",
      "  Train Loss: 0.1914, Train Acc: 0.9392\n",
      "  Val Loss: 2.2691, Val Acc: 0.5713\n",
      "Epoch 46/50\n",
      "  Train Loss: 0.1873, Train Acc: 0.9400\n",
      "  Val Loss: 2.1378, Val Acc: 0.5913\n",
      "Epoch 47/50\n",
      "  Train Loss: 0.2025, Train Acc: 0.9334\n",
      "  Val Loss: 2.0849, Val Acc: 0.6000\n",
      "Epoch 48/50\n",
      "  Train Loss: 0.1621, Train Acc: 0.9506\n",
      "  Val Loss: 2.1931, Val Acc: 0.5837\n",
      "Epoch 49/50\n",
      "  Train Loss: 0.1675, Train Acc: 0.9454\n",
      "  Val Loss: 2.2606, Val Acc: 0.5925\n",
      "Epoch 50/50\n",
      "  Train Loss: 0.1865, Train Acc: 0.9400\n",
      "  Val Loss: 2.3732, Val Acc: 0.5837\n",
      "\n",
      "drop_rate : 0.2\n",
      "Epoch 1/50\n",
      "  Train Loss: 2.8989, Train Acc: 0.3452\n",
      "  Val Loss: 2.2706, Val Acc: 0.4537\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.454.pth\n",
      "Epoch 2/50\n",
      "  Train Loss: 1.7844, Train Acc: 0.5496\n",
      "  Val Loss: 1.7950, Val Acc: 0.5275\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.527.pth\n",
      "Epoch 3/50\n",
      "  Train Loss: 1.4894, Train Acc: 0.5964\n",
      "  Val Loss: 1.6739, Val Acc: 0.5687\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.569.pth\n",
      "Epoch 4/50\n",
      "  Train Loss: 1.2829, Train Acc: 0.6432\n",
      "  Val Loss: 1.6686, Val Acc: 0.5600\n",
      "Epoch 5/50\n",
      "  Train Loss: 1.1666, Train Acc: 0.6710\n",
      "  Val Loss: 1.6564, Val Acc: 0.5863\n",
      "Checkpoint saved: food_mobilenet_v12_05_0.586.pth\n",
      "Epoch 6/50\n",
      "  Train Loss: 1.0251, Train Acc: 0.7040\n",
      "  Val Loss: 1.6235, Val Acc: 0.5775\n",
      "Epoch 7/50\n",
      "  Train Loss: 0.9373, Train Acc: 0.7262\n",
      "  Val Loss: 1.5833, Val Acc: 0.5837\n",
      "Epoch 8/50\n",
      "  Train Loss: 0.8747, Train Acc: 0.7458\n",
      "  Val Loss: 1.6343, Val Acc: 0.5863\n",
      "Epoch 9/50\n",
      "  Train Loss: 0.8063, Train Acc: 0.7656\n",
      "  Val Loss: 1.6468, Val Acc: 0.5900\n",
      "Checkpoint saved: food_mobilenet_v12_09_0.590.pth\n",
      "Epoch 10/50\n",
      "  Train Loss: 0.7714, Train Acc: 0.7732\n",
      "  Val Loss: 1.6805, Val Acc: 0.6075\n",
      "Checkpoint saved: food_mobilenet_v12_10_0.608.pth\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.7179, Train Acc: 0.7930\n",
      "  Val Loss: 1.6762, Val Acc: 0.5750\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.6808, Train Acc: 0.7964\n",
      "  Val Loss: 1.6768, Val Acc: 0.5737\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.6089, Train Acc: 0.8154\n",
      "  Val Loss: 1.7696, Val Acc: 0.5700\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.5807, Train Acc: 0.8212\n",
      "  Val Loss: 1.7101, Val Acc: 0.5763\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.5534, Train Acc: 0.8302\n",
      "  Val Loss: 1.7830, Val Acc: 0.5875\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.5319, Train Acc: 0.8378\n",
      "  Val Loss: 1.7051, Val Acc: 0.5925\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.4959, Train Acc: 0.8436\n",
      "  Val Loss: 1.7398, Val Acc: 0.5837\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.4893, Train Acc: 0.8464\n",
      "  Val Loss: 1.7350, Val Acc: 0.5863\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.4517, Train Acc: 0.8590\n",
      "  Val Loss: 1.8163, Val Acc: 0.5887\n",
      "Epoch 20/50\n",
      "  Train Loss: 0.4353, Train Acc: 0.8598\n",
      "  Val Loss: 1.8173, Val Acc: 0.5625\n",
      "Epoch 21/50\n",
      "  Train Loss: 0.4338, Train Acc: 0.8654\n",
      "  Val Loss: 1.8767, Val Acc: 0.5537\n",
      "Epoch 22/50\n",
      "  Train Loss: 0.4239, Train Acc: 0.8684\n",
      "  Val Loss: 1.8515, Val Acc: 0.5713\n",
      "Epoch 23/50\n",
      "  Train Loss: 0.4013, Train Acc: 0.8720\n",
      "  Val Loss: 1.7871, Val Acc: 0.6038\n",
      "Epoch 24/50\n",
      "  Train Loss: 0.3990, Train Acc: 0.8752\n",
      "  Val Loss: 1.8209, Val Acc: 0.5975\n",
      "Epoch 25/50\n",
      "  Train Loss: 0.3696, Train Acc: 0.8848\n",
      "  Val Loss: 1.9013, Val Acc: 0.5900\n",
      "Epoch 26/50\n",
      "  Train Loss: 0.3719, Train Acc: 0.8822\n",
      "  Val Loss: 1.8566, Val Acc: 0.5913\n",
      "Epoch 27/50\n",
      "  Train Loss: 0.3342, Train Acc: 0.8966\n",
      "  Val Loss: 1.9332, Val Acc: 0.5713\n",
      "Epoch 28/50\n",
      "  Train Loss: 0.3317, Train Acc: 0.8962\n",
      "  Val Loss: 1.8722, Val Acc: 0.5988\n",
      "Epoch 29/50\n",
      "  Train Loss: 0.3440, Train Acc: 0.8916\n",
      "  Val Loss: 1.9218, Val Acc: 0.5863\n",
      "Epoch 30/50\n",
      "  Train Loss: 0.3041, Train Acc: 0.9022\n",
      "  Val Loss: 1.9230, Val Acc: 0.5900\n",
      "Epoch 31/50\n",
      "  Train Loss: 0.3083, Train Acc: 0.9002\n",
      "  Val Loss: 1.9979, Val Acc: 0.5887\n",
      "Epoch 32/50\n",
      "  Train Loss: 0.3037, Train Acc: 0.9050\n",
      "  Val Loss: 1.9608, Val Acc: 0.6038\n",
      "Epoch 33/50\n",
      "  Train Loss: 0.2838, Train Acc: 0.9138\n",
      "  Val Loss: 1.9476, Val Acc: 0.5950\n",
      "Epoch 34/50\n",
      "  Train Loss: 0.2815, Train Acc: 0.9094\n",
      "  Val Loss: 1.9816, Val Acc: 0.5787\n",
      "Epoch 35/50\n",
      "  Train Loss: 0.2972, Train Acc: 0.9054\n",
      "  Val Loss: 1.9940, Val Acc: 0.5825\n",
      "Epoch 36/50\n",
      "  Train Loss: 0.2662, Train Acc: 0.9186\n",
      "  Val Loss: 2.0159, Val Acc: 0.5900\n",
      "Epoch 37/50\n",
      "  Train Loss: 0.2638, Train Acc: 0.9158\n",
      "  Val Loss: 2.0524, Val Acc: 0.5875\n",
      "Epoch 38/50\n",
      "  Train Loss: 0.2699, Train Acc: 0.9124\n",
      "  Val Loss: 2.0782, Val Acc: 0.5775\n",
      "Epoch 39/50\n",
      "  Train Loss: 0.2662, Train Acc: 0.9118\n",
      "  Val Loss: 2.0745, Val Acc: 0.5887\n",
      "Epoch 40/50\n",
      "  Train Loss: 0.2451, Train Acc: 0.9248\n",
      "  Val Loss: 2.1158, Val Acc: 0.5875\n",
      "Epoch 41/50\n",
      "  Train Loss: 0.2544, Train Acc: 0.9186\n",
      "  Val Loss: 2.0988, Val Acc: 0.5837\n",
      "Epoch 42/50\n",
      "  Train Loss: 0.2415, Train Acc: 0.9224\n",
      "  Val Loss: 2.2034, Val Acc: 0.5600\n",
      "Epoch 43/50\n",
      "  Train Loss: 0.2342, Train Acc: 0.9276\n",
      "  Val Loss: 2.1528, Val Acc: 0.5775\n",
      "Epoch 44/50\n",
      "  Train Loss: 0.2414, Train Acc: 0.9192\n",
      "  Val Loss: 2.1799, Val Acc: 0.5713\n",
      "Epoch 45/50\n",
      "  Train Loss: 0.2283, Train Acc: 0.9306\n",
      "  Val Loss: 2.2458, Val Acc: 0.5800\n",
      "Epoch 46/50\n",
      "  Train Loss: 0.2229, Train Acc: 0.9282\n",
      "  Val Loss: 2.2440, Val Acc: 0.5913\n",
      "Epoch 47/50\n",
      "  Train Loss: 0.2452, Train Acc: 0.9248\n",
      "  Val Loss: 2.2063, Val Acc: 0.5825\n",
      "Epoch 48/50\n",
      "  Train Loss: 0.2228, Train Acc: 0.9256\n",
      "  Val Loss: 2.2279, Val Acc: 0.5775\n",
      "Epoch 49/50\n",
      "  Train Loss: 0.2326, Train Acc: 0.9246\n",
      "  Val Loss: 2.3383, Val Acc: 0.5887\n",
      "Epoch 50/50\n",
      "  Train Loss: 0.1979, Train Acc: 0.9380\n",
      "  Val Loss: 2.1815, Val Acc: 0.5837\n",
      "\n",
      "drop_rate : 0.3\n",
      "Epoch 1/50\n",
      "  Train Loss: 2.9885, Train Acc: 0.3280\n",
      "  Val Loss: 2.3346, Val Acc: 0.4562\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.456.pth\n",
      "Epoch 2/50\n",
      "  Train Loss: 1.8683, Train Acc: 0.5332\n",
      "  Val Loss: 1.9593, Val Acc: 0.5262\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.526.pth\n",
      "Epoch 3/50\n",
      "  Train Loss: 1.5912, Train Acc: 0.5790\n",
      "  Val Loss: 1.6932, Val Acc: 0.5700\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.570.pth\n",
      "Epoch 4/50\n",
      "  Train Loss: 1.3501, Train Acc: 0.6250\n",
      "  Val Loss: 1.7014, Val Acc: 0.5550\n",
      "Epoch 5/50\n",
      "  Train Loss: 1.2108, Train Acc: 0.6626\n",
      "  Val Loss: 1.7007, Val Acc: 0.5500\n",
      "Epoch 6/50\n",
      "  Train Loss: 1.1239, Train Acc: 0.6822\n",
      "  Val Loss: 1.6884, Val Acc: 0.5787\n",
      "Checkpoint saved: food_mobilenet_v12_06_0.579.pth\n",
      "Epoch 7/50\n",
      "  Train Loss: 1.0358, Train Acc: 0.6962\n",
      "  Val Loss: 1.6138, Val Acc: 0.5775\n",
      "Epoch 8/50\n",
      "  Train Loss: 0.9601, Train Acc: 0.7196\n",
      "  Val Loss: 1.5923, Val Acc: 0.5962\n",
      "Checkpoint saved: food_mobilenet_v12_08_0.596.pth\n",
      "Epoch 9/50\n",
      "  Train Loss: 0.8666, Train Acc: 0.7412\n",
      "  Val Loss: 1.6482, Val Acc: 0.5850\n",
      "Epoch 10/50\n",
      "  Train Loss: 0.8404, Train Acc: 0.7546\n",
      "  Val Loss: 1.5924, Val Acc: 0.6038\n",
      "Checkpoint saved: food_mobilenet_v12_10_0.604.pth\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.8006, Train Acc: 0.7600\n",
      "  Val Loss: 1.6002, Val Acc: 0.6050\n",
      "Checkpoint saved: food_mobilenet_v12_11_0.605.pth\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.7304, Train Acc: 0.7728\n",
      "  Val Loss: 1.6261, Val Acc: 0.6025\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.7059, Train Acc: 0.7846\n",
      "  Val Loss: 1.6425, Val Acc: 0.5900\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.6842, Train Acc: 0.7950\n",
      "  Val Loss: 1.7502, Val Acc: 0.5900\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.6155, Train Acc: 0.8156\n",
      "  Val Loss: 1.7254, Val Acc: 0.5775\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.6031, Train Acc: 0.8132\n",
      "  Val Loss: 1.6215, Val Acc: 0.6038\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.6050, Train Acc: 0.8114\n",
      "  Val Loss: 1.6731, Val Acc: 0.5950\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.5726, Train Acc: 0.8222\n",
      "  Val Loss: 1.6721, Val Acc: 0.6088\n",
      "Checkpoint saved: food_mobilenet_v12_18_0.609.pth\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.5327, Train Acc: 0.8368\n",
      "  Val Loss: 1.7323, Val Acc: 0.5950\n",
      "Epoch 20/50\n",
      "  Train Loss: 0.4886, Train Acc: 0.8528\n",
      "  Val Loss: 1.7565, Val Acc: 0.6050\n",
      "Epoch 21/50\n",
      "  Train Loss: 0.5166, Train Acc: 0.8408\n",
      "  Val Loss: 1.7313, Val Acc: 0.5975\n",
      "Epoch 22/50\n",
      "  Train Loss: 0.4905, Train Acc: 0.8538\n",
      "  Val Loss: 1.7780, Val Acc: 0.5775\n",
      "Epoch 23/50\n",
      "  Train Loss: 0.4543, Train Acc: 0.8598\n",
      "  Val Loss: 1.7551, Val Acc: 0.5813\n",
      "Epoch 24/50\n",
      "  Train Loss: 0.4235, Train Acc: 0.8676\n",
      "  Val Loss: 1.7634, Val Acc: 0.6050\n",
      "Epoch 25/50\n",
      "  Train Loss: 0.4280, Train Acc: 0.8642\n",
      "  Val Loss: 1.7528, Val Acc: 0.6050\n",
      "Epoch 26/50\n",
      "  Train Loss: 0.4312, Train Acc: 0.8580\n",
      "  Val Loss: 1.7408, Val Acc: 0.6038\n",
      "Epoch 27/50\n",
      "  Train Loss: 0.3970, Train Acc: 0.8742\n",
      "  Val Loss: 1.7526, Val Acc: 0.6138\n",
      "Checkpoint saved: food_mobilenet_v12_27_0.614.pth\n",
      "Epoch 28/50\n",
      "  Train Loss: 0.4068, Train Acc: 0.8704\n",
      "  Val Loss: 1.8907, Val Acc: 0.5887\n",
      "Epoch 29/50\n",
      "  Train Loss: 0.3840, Train Acc: 0.8744\n",
      "  Val Loss: 1.8512, Val Acc: 0.6025\n",
      "Epoch 30/50\n",
      "  Train Loss: 0.3970, Train Acc: 0.8768\n",
      "  Val Loss: 1.8215, Val Acc: 0.6012\n",
      "Epoch 31/50\n",
      "  Train Loss: 0.3711, Train Acc: 0.8754\n",
      "  Val Loss: 1.8412, Val Acc: 0.6062\n",
      "Epoch 32/50\n",
      "  Train Loss: 0.3556, Train Acc: 0.8850\n",
      "  Val Loss: 1.8319, Val Acc: 0.5900\n",
      "Epoch 33/50\n",
      "  Train Loss: 0.3498, Train Acc: 0.8856\n",
      "  Val Loss: 1.8759, Val Acc: 0.5887\n",
      "Epoch 34/50\n",
      "  Train Loss: 0.3585, Train Acc: 0.8906\n",
      "  Val Loss: 1.8296, Val Acc: 0.6188\n",
      "Checkpoint saved: food_mobilenet_v12_34_0.619.pth\n",
      "Epoch 35/50\n",
      "  Train Loss: 0.3502, Train Acc: 0.8918\n",
      "  Val Loss: 1.8601, Val Acc: 0.6138\n",
      "Epoch 36/50\n",
      "  Train Loss: 0.3316, Train Acc: 0.8918\n",
      "  Val Loss: 1.8786, Val Acc: 0.6038\n",
      "Epoch 37/50\n",
      "  Train Loss: 0.3422, Train Acc: 0.8968\n",
      "  Val Loss: 1.8658, Val Acc: 0.6012\n",
      "Epoch 38/50\n",
      "  Train Loss: 0.3230, Train Acc: 0.8944\n",
      "  Val Loss: 1.9097, Val Acc: 0.5863\n",
      "Epoch 39/50\n",
      "  Train Loss: 0.3221, Train Acc: 0.8962\n",
      "  Val Loss: 1.9379, Val Acc: 0.5913\n",
      "Epoch 40/50\n",
      "  Train Loss: 0.3161, Train Acc: 0.8932\n",
      "  Val Loss: 1.8864, Val Acc: 0.5900\n",
      "Epoch 41/50\n",
      "  Train Loss: 0.3245, Train Acc: 0.8966\n",
      "  Val Loss: 1.8512, Val Acc: 0.6075\n",
      "Epoch 42/50\n",
      "  Train Loss: 0.3100, Train Acc: 0.8986\n",
      "  Val Loss: 1.9644, Val Acc: 0.6050\n",
      "Epoch 43/50\n",
      "  Train Loss: 0.2845, Train Acc: 0.9084\n",
      "  Val Loss: 2.0822, Val Acc: 0.5713\n",
      "Epoch 44/50\n",
      "  Train Loss: 0.3086, Train Acc: 0.9012\n",
      "  Val Loss: 2.0299, Val Acc: 0.5813\n",
      "Epoch 45/50\n",
      "  Train Loss: 0.2730, Train Acc: 0.9114\n",
      "  Val Loss: 1.9390, Val Acc: 0.6088\n",
      "Epoch 46/50\n",
      "  Train Loss: 0.2867, Train Acc: 0.9074\n",
      "  Val Loss: 1.9771, Val Acc: 0.6138\n",
      "Epoch 47/50\n",
      "  Train Loss: 0.3006, Train Acc: 0.9060\n",
      "  Val Loss: 1.9969, Val Acc: 0.6038\n",
      "Epoch 48/50\n",
      "  Train Loss: 0.2690, Train Acc: 0.9106\n",
      "  Val Loss: 2.0071, Val Acc: 0.5950\n",
      "Epoch 49/50\n",
      "  Train Loss: 0.2498, Train Acc: 0.9156\n",
      "  Val Loss: 2.0652, Val Acc: 0.5900\n",
      "Epoch 50/50\n",
      "  Train Loss: 0.2586, Train Acc: 0.9152\n",
      "  Val Loss: 2.1059, Val Acc: 0.5900\n",
      "\n",
      "drop_rate : 0.4\n",
      "Epoch 1/50\n",
      "  Train Loss: 3.0375, Train Acc: 0.3130\n",
      "  Val Loss: 2.3878, Val Acc: 0.4288\n",
      "Checkpoint saved: food_mobilenet_v12_01_0.429.pth\n",
      "Epoch 2/50\n",
      "  Train Loss: 1.9579, Train Acc: 0.5188\n",
      "  Val Loss: 1.9141, Val Acc: 0.5200\n",
      "Checkpoint saved: food_mobilenet_v12_02_0.520.pth\n",
      "Epoch 3/50\n",
      "  Train Loss: 1.6400, Train Acc: 0.5730\n",
      "  Val Loss: 1.7651, Val Acc: 0.5487\n",
      "Checkpoint saved: food_mobilenet_v12_03_0.549.pth\n",
      "Epoch 4/50\n",
      "  Train Loss: 1.4486, Train Acc: 0.6132\n",
      "  Val Loss: 1.6562, Val Acc: 0.5825\n",
      "Checkpoint saved: food_mobilenet_v12_04_0.583.pth\n",
      "Epoch 5/50\n",
      "  Train Loss: 1.3088, Train Acc: 0.6356\n",
      "  Val Loss: 1.5856, Val Acc: 0.5863\n",
      "Checkpoint saved: food_mobilenet_v12_05_0.586.pth\n",
      "Epoch 6/50\n",
      "  Train Loss: 1.2102, Train Acc: 0.6648\n",
      "  Val Loss: 1.5724, Val Acc: 0.5925\n",
      "Checkpoint saved: food_mobilenet_v12_06_0.593.pth\n",
      "Epoch 7/50\n",
      "  Train Loss: 1.1186, Train Acc: 0.6792\n",
      "  Val Loss: 1.5595, Val Acc: 0.6050\n",
      "Checkpoint saved: food_mobilenet_v12_07_0.605.pth\n",
      "Epoch 8/50\n",
      "  Train Loss: 1.0430, Train Acc: 0.6996\n",
      "  Val Loss: 1.5608, Val Acc: 0.5850\n",
      "Epoch 9/50\n",
      "  Train Loss: 0.9826, Train Acc: 0.7182\n",
      "  Val Loss: 1.5980, Val Acc: 0.5875\n",
      "Epoch 10/50\n",
      "  Train Loss: 0.9184, Train Acc: 0.7318\n",
      "  Val Loss: 1.5946, Val Acc: 0.5887\n",
      "Epoch 11/50\n",
      "  Train Loss: 0.8716, Train Acc: 0.7440\n",
      "  Val Loss: 1.5737, Val Acc: 0.5962\n",
      "Epoch 12/50\n",
      "  Train Loss: 0.8361, Train Acc: 0.7516\n",
      "  Val Loss: 1.5598, Val Acc: 0.6112\n",
      "Checkpoint saved: food_mobilenet_v12_12_0.611.pth\n",
      "Epoch 13/50\n",
      "  Train Loss: 0.7813, Train Acc: 0.7582\n",
      "  Val Loss: 1.6028, Val Acc: 0.6175\n",
      "Checkpoint saved: food_mobilenet_v12_13_0.618.pth\n",
      "Epoch 14/50\n",
      "  Train Loss: 0.7391, Train Acc: 0.7710\n",
      "  Val Loss: 1.6148, Val Acc: 0.6000\n",
      "Epoch 15/50\n",
      "  Train Loss: 0.7329, Train Acc: 0.7826\n",
      "  Val Loss: 1.6293, Val Acc: 0.5962\n",
      "Epoch 16/50\n",
      "  Train Loss: 0.6995, Train Acc: 0.7856\n",
      "  Val Loss: 1.6553, Val Acc: 0.5962\n",
      "Epoch 17/50\n",
      "  Train Loss: 0.6899, Train Acc: 0.7900\n",
      "  Val Loss: 1.6187, Val Acc: 0.6062\n",
      "Epoch 18/50\n",
      "  Train Loss: 0.6462, Train Acc: 0.8028\n",
      "  Val Loss: 1.6746, Val Acc: 0.5925\n",
      "Epoch 19/50\n",
      "  Train Loss: 0.6203, Train Acc: 0.8074\n",
      "  Val Loss: 1.6143, Val Acc: 0.6225\n",
      "Checkpoint saved: food_mobilenet_v12_19_0.623.pth\n",
      "Epoch 20/50\n",
      "  Train Loss: 0.5894, Train Acc: 0.8174\n",
      "  Val Loss: 1.6808, Val Acc: 0.6075\n",
      "Epoch 21/50\n",
      "  Train Loss: 0.6034, Train Acc: 0.8128\n",
      "  Val Loss: 1.6668, Val Acc: 0.6038\n",
      "Epoch 22/50\n",
      "  Train Loss: 0.5665, Train Acc: 0.8216\n",
      "  Val Loss: 1.6445, Val Acc: 0.6000\n",
      "Epoch 23/50\n",
      "  Train Loss: 0.5737, Train Acc: 0.8244\n",
      "  Val Loss: 1.7434, Val Acc: 0.6050\n",
      "Epoch 24/50\n",
      "  Train Loss: 0.5420, Train Acc: 0.8256\n",
      "  Val Loss: 1.7225, Val Acc: 0.5938\n",
      "Epoch 25/50\n",
      "  Train Loss: 0.5023, Train Acc: 0.8450\n",
      "  Val Loss: 1.8044, Val Acc: 0.6088\n",
      "Epoch 26/50\n",
      "  Train Loss: 0.5067, Train Acc: 0.8436\n",
      "  Val Loss: 1.7877, Val Acc: 0.5988\n",
      "Epoch 27/50\n",
      "  Train Loss: 0.5053, Train Acc: 0.8416\n",
      "  Val Loss: 1.8061, Val Acc: 0.6000\n",
      "Epoch 28/50\n",
      "  Train Loss: 0.4971, Train Acc: 0.8430\n",
      "  Val Loss: 1.7708, Val Acc: 0.5962\n",
      "Epoch 29/50\n",
      "  Train Loss: 0.4827, Train Acc: 0.8506\n",
      "  Val Loss: 1.8004, Val Acc: 0.6075\n",
      "Epoch 30/50\n",
      "  Train Loss: 0.4750, Train Acc: 0.8468\n",
      "  Val Loss: 1.8384, Val Acc: 0.5975\n",
      "Epoch 31/50\n",
      "  Train Loss: 0.4780, Train Acc: 0.8434\n",
      "  Val Loss: 1.7771, Val Acc: 0.5975\n",
      "Epoch 32/50\n",
      "  Train Loss: 0.4300, Train Acc: 0.8642\n",
      "  Val Loss: 1.9400, Val Acc: 0.6038\n",
      "Epoch 33/50\n",
      "  Train Loss: 0.4438, Train Acc: 0.8578\n",
      "  Val Loss: 1.8155, Val Acc: 0.6012\n",
      "Epoch 34/50\n",
      "  Train Loss: 0.4247, Train Acc: 0.8676\n",
      "  Val Loss: 1.8528, Val Acc: 0.5975\n",
      "Epoch 35/50\n",
      "  Train Loss: 0.4248, Train Acc: 0.8676\n",
      "  Val Loss: 1.7800, Val Acc: 0.6062\n",
      "Epoch 36/50\n",
      "  Train Loss: 0.4017, Train Acc: 0.8736\n",
      "  Val Loss: 1.8515, Val Acc: 0.6000\n",
      "Epoch 37/50\n",
      "  Train Loss: 0.4141, Train Acc: 0.8642\n",
      "  Val Loss: 1.8732, Val Acc: 0.6188\n",
      "Epoch 38/50\n",
      "  Train Loss: 0.4120, Train Acc: 0.8642\n",
      "  Val Loss: 1.8617, Val Acc: 0.6200\n",
      "Epoch 39/50\n",
      "  Train Loss: 0.4056, Train Acc: 0.8718\n",
      "  Val Loss: 1.8549, Val Acc: 0.6075\n",
      "Epoch 40/50\n",
      "  Train Loss: 0.3848, Train Acc: 0.8728\n",
      "  Val Loss: 1.9439, Val Acc: 0.6025\n",
      "Epoch 41/50\n",
      "  Train Loss: 0.3633, Train Acc: 0.8836\n",
      "  Val Loss: 2.0067, Val Acc: 0.5913\n",
      "Epoch 42/50\n",
      "  Train Loss: 0.3716, Train Acc: 0.8806\n",
      "  Val Loss: 1.9105, Val Acc: 0.6100\n",
      "Epoch 43/50\n",
      "  Train Loss: 0.3601, Train Acc: 0.8792\n",
      "  Val Loss: 2.0077, Val Acc: 0.5763\n",
      "Epoch 44/50\n",
      "  Train Loss: 0.3573, Train Acc: 0.8892\n",
      "  Val Loss: 2.0067, Val Acc: 0.6088\n",
      "Epoch 45/50\n",
      "  Train Loss: 0.3760, Train Acc: 0.8828\n",
      "  Val Loss: 1.9741, Val Acc: 0.5950\n",
      "Epoch 46/50\n",
      "  Train Loss: 0.3862, Train Acc: 0.8766\n",
      "  Val Loss: 1.9978, Val Acc: 0.5887\n",
      "Epoch 47/50\n",
      "  Train Loss: 0.3675, Train Acc: 0.8850\n",
      "  Val Loss: 2.0393, Val Acc: 0.5925\n",
      "Epoch 48/50\n",
      "  Train Loss: 0.3581, Train Acc: 0.8854\n",
      "  Val Loss: 1.9842, Val Acc: 0.5988\n",
      "Epoch 49/50\n",
      "  Train Loss: 0.3407, Train Acc: 0.8906\n",
      "  Val Loss: 2.0869, Val Acc: 0.5962\n",
      "Epoch 50/50\n",
      "  Train Loss: 0.3378, Train Acc: 0.8908\n",
      "  Val Loss: 2.0409, Val Acc: 0.5875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for drop_rate in [0.1, 0.2, 0.3, 0.4]:\n",
    "    print(f\"drop_rate : {drop_rate}\")\n",
    "    model, optimizer = make_model(\n",
    "        learning_rate=0.001,\n",
    "        size_inner=1000,\n",
    "        droprate=drop_rate\n",
    "    )\n",
    "    \n",
    "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f3e12e4-59bf-4a26-8ba9-0cb4aa878354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T05:45:26.707095Z",
     "iopub.status.busy": "2025-12-28T05:45:26.707095Z",
     "iopub.status.idle": "2025-12-28T05:45:26.709952Z",
     "shell.execute_reply": "2025-12-28T05:45:26.709952Z",
     "shell.execute_reply.started": "2025-12-28T05:45:26.707095Z"
    }
   },
   "outputs": [],
   "source": [
    "# best drop rate : 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edf59f-f798-417d-9ef0-fceff6493e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 50\n",
    "# model, optimizer = make_model(\n",
    "#     learning_rate=0.001,\n",
    "#     size_inner=1000,\n",
    "#     droprate=0.4\n",
    "# )\n",
    "\n",
    "# train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfeed13-b87e-4109-96aa-fbed19d1928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baec0c13-316f-4f69-a05f-da3d3b7c7356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cbcb50-530a-432f-940d-a45db6e68311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Exporting to ONNX for serverles model deployment\n",
    "# dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# # Export to ONNX\n",
    "# onnx_path = \"food_classifier_mobilenet_v2.onnx\"\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     dummy_input,\n",
    "#     onnx_path,\n",
    "#     verbose=True,\n",
    "#     input_names=['input'],\n",
    "#     output_names=['output'],\n",
    "#     dynamic_axes={\n",
    "#         'input': {0: 'batch_size'},\n",
    "#         'output': {0: 'batch_size'}\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417969a-70e3-47e1-b507-bd970d6c41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load model from a checkpoint\n",
    "# path = './clothing_v4_23_0.830.pth'\n",
    "# model = ClothingClassifierMobileNet(size_inner=100, droprate=0.2, num_classes=10)\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model.to(device)\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b0fd4-c0ec-4174-9aab-0085385e1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = val_transforms(img)\n",
    "# batch_t = torch.unsqueeze(x, 0).to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b8325-76fa-4955-b0f6-9ffe84013152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(zip(classes, output[0].to('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
