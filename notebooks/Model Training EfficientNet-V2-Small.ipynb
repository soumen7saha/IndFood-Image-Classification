{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588d74fb-ae5c-4815-be9c-2d02ec4dc7f7",
   "metadata": {},
   "source": [
    "## Training using EfficientNet-V2-Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a1be62-13f5-4d6b-b85a-d657fc1754d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:07:06.035106Z",
     "iopub.status.busy": "2025-12-26T16:07:06.035106Z",
     "iopub.status.idle": "2025-12-26T16:07:12.396946Z",
     "shell.execute_reply": "2025-12-26T16:07:12.396946Z",
     "shell.execute_reply.started": "2025-12-26T16:07:06.035106Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695ce271-7b41-461f-b991-eda5f9768164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:07:12.396946Z",
     "iopub.status.busy": "2025-12-26T16:07:12.396946Z",
     "iopub.status.idle": "2025-12-26T16:07:12.404063Z",
     "shell.execute_reply": "2025-12-26T16:07:12.403077Z",
     "shell.execute_reply.started": "2025-12-26T16:07:12.396946Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be0b689-3ab2-42cb-94d5-532c2728a701",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:49:35.511513Z",
     "iopub.status.busy": "2025-12-26T15:49:35.510477Z",
     "iopub.status.idle": "2025-12-26T15:49:35.515736Z",
     "shell.execute_reply": "2025-12-26T15:49:35.514674Z",
     "shell.execute_reply.started": "2025-12-26T15:49:35.511513Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d43e04-8768-4b2a-9cd6-f0531a714f90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:07:12.405011Z",
     "iopub.status.busy": "2025-12-26T16:07:12.405011Z",
     "iopub.status.idle": "2025-12-26T16:07:12.422842Z",
     "shell.execute_reply": "2025-12-26T16:07:12.421295Z",
     "shell.execute_reply.started": "2025-12-26T16:07:12.405011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.1+cu126'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc915298-5d19-487d-a421-bcc81414408c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:07:12.571827Z",
     "iopub.status.busy": "2025-12-26T16:07:12.570809Z",
     "iopub.status.idle": "2025-12-26T16:07:12.636866Z",
     "shell.execute_reply": "2025-12-26T16:07:12.632856Z",
     "shell.execute_reply.started": "2025-12-26T16:07:12.571827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efea2f9b-993c-4ef9-8342-bdc05900de1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:07:16.009430Z",
     "iopub.status.busy": "2025-12-26T16:07:16.008430Z",
     "iopub.status.idle": "2025-12-26T16:07:16.014099Z",
     "shell.execute_reply": "2025-12-26T16:07:16.014099Z",
     "shell.execute_reply.started": "2025-12-26T16:07:16.009430Z"
    }
   },
   "outputs": [],
   "source": [
    "# models.resnet152(weights='IMAGENET1K_V2')\n",
    "# models.convnext_small(weights='IMAGENET1K_V1')\n",
    "# models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "# models.mobilenet_v2(weights='IMAGENET1K_V2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c7c09a-8195-46e6-8027-394fa8054356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:07:17.617268Z",
     "iopub.status.busy": "2025-12-26T16:07:17.617268Z",
     "iopub.status.idle": "2025-12-26T16:07:17.628766Z",
     "shell.execute_reply": "2025-12-26T16:07:17.626704Z",
     "shell.execute_reply.started": "2025-12-26T16:07:17.617268Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(data_dir))\n",
    "        self.class_to_idx = {cls: i for i,cls in enumerate(self.classes)}\n",
    "\n",
    "        for label_name in self.classes:\n",
    "            label_dir = os.path.join(data_dir, label_name)\n",
    "            for img_name in os.listdir(label_dir):\n",
    "                self.image_paths.append(os.path.join(label_dir, img_name))\n",
    "                self.labels.append(self.class_to_idx[label_name])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5299690-073a-4792-bb67-b73c25dd05db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:08:30.121941Z",
     "iopub.status.busy": "2025-12-26T16:08:30.121941Z",
     "iopub.status.idle": "2025-12-26T16:08:30.131449Z",
     "shell.execute_reply": "2025-12-26T16:08:30.129389Z",
     "shell.execute_reply.started": "2025-12-26T16:08:30.121941Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 384\n",
    "\n",
    "# ImageNet Normalization values\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Simple transforms - just resize and normalize\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomRotation(15),           # Rotate up to 10 degrees\n",
    "    transforms.RandomResizedCrop(384, scale=(0.0, 1.0)),  # Zoom\n",
    "    transforms.RandomHorizontalFlip(),       # Horizontal flip\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((input_size, input_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170995c6-6b81-43f8-8c0d-517c49dfb3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:08:32.586018Z",
     "iopub.status.busy": "2025-12-26T16:08:32.586018Z",
     "iopub.status.idle": "2025-12-26T16:08:33.094652Z",
     "shell.execute_reply": "2025-12-26T16:08:33.094652Z",
     "shell.execute_reply.started": "2025-12-26T16:08:32.586018Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = FoodDataset(\n",
    "    data_dir='./indfood-data/train',\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = FoodDataset(\n",
    "    data_dir='./indfood-data/val',\n",
    "    transform=val_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb52fb68-4f94-4831-b4bf-9ba8e9401c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:09:28.380761Z",
     "iopub.status.busy": "2025-12-26T16:09:28.379698Z",
     "iopub.status.idle": "2025-12-26T16:09:28.401842Z",
     "shell.execute_reply": "2025-12-26T16:09:28.400809Z",
     "shell.execute_reply.started": "2025-12-26T16:09:28.380761Z"
    }
   },
   "outputs": [],
   "source": [
    "total_train_len = len(train_dataset)\n",
    "total_val_len = len(val_dataset)\n",
    "\n",
    "# Define the length of the smaller dataset you want to use\n",
    "subset_train_len = 6000\n",
    "subset_val_len = 1500\n",
    "\n",
    "# Define the lengths for the split: [desired_length, remaining_length]\n",
    "train_lengths = [subset_train_len, total_train_len - subset_train_len]\n",
    "val_lengths = [subset_val_len, total_val_len - subset_val_len]\n",
    "\n",
    "# Randomly split the original dataset into two new datasets, You get a list of datasets; take the first one [0]\n",
    "smaller_train_dataset = random_split(train_dataset, train_lengths)[0]\n",
    "smaller_val_dataset = random_split(val_dataset, val_lengths)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f3b675-07aa-4e21-947e-debf6922dee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:09:31.796658Z",
     "iopub.status.busy": "2025-12-26T16:09:31.796658Z",
     "iopub.status.idle": "2025-12-26T16:09:31.802236Z",
     "shell.execute_reply": "2025-12-26T16:09:31.802236Z",
     "shell.execute_reply.started": "2025-12-26T16:09:31.796658Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(smaller_train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(smaller_val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b06fc0e5-7547-4f8c-9d19-c962e73bfd3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:09:47.157507Z",
     "iopub.status.busy": "2025-12-26T16:09:47.156507Z",
     "iopub.status.idle": "2025-12-26T16:09:47.164695Z",
     "shell.execute_reply": "2025-12-26T16:09:47.162691Z",
     "shell.execute_reply.started": "2025-12-26T16:09:47.157507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114965, 20370)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2574d9-7bab-4ad1-9e03-67a903c1c5c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:09:48.596376Z",
     "iopub.status.busy": "2025-12-26T16:09:48.596376Z",
     "iopub.status.idle": "2025-12-26T16:09:48.607383Z",
     "shell.execute_reply": "2025-12-26T16:09:48.605503Z",
     "shell.execute_reply.started": "2025-12-26T16:09:48.596376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 1500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smaller_train_dataset), len(smaller_val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f51df8a-527d-45cc-a73d-bb8b57ae3091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:09:52.554401Z",
     "iopub.status.busy": "2025-12-26T16:09:52.553402Z",
     "iopub.status.idle": "2025-12-26T16:09:52.566715Z",
     "shell.execute_reply": "2025-12-26T16:09:52.564458Z",
     "shell.execute_reply.started": "2025-12-26T16:09:52.554401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aloo_gobi',\n",
       " 'aloo_matar',\n",
       " 'aloo_methi',\n",
       " 'aloo_paratha',\n",
       " 'aloo_shimla_mirch',\n",
       " 'aloo_tikki',\n",
       " 'amritsari_kulcha',\n",
       " 'anda_curry',\n",
       " 'ariselu',\n",
       " 'balushahi',\n",
       " 'banana_chips',\n",
       " 'bandar_laddu',\n",
       " 'basundi',\n",
       " 'besan_laddu',\n",
       " 'bhindi_masala',\n",
       " 'biryani',\n",
       " 'boondi',\n",
       " 'boondi_laddu',\n",
       " 'butter_chicken',\n",
       " 'chaas',\n",
       " 'chak_hao_kheer',\n",
       " 'cham_cham',\n",
       " 'chana_masala',\n",
       " 'chapati',\n",
       " 'chicken_pizza',\n",
       " 'chicken_razala',\n",
       " 'chicken_tikka',\n",
       " 'chicken_tikka_masala',\n",
       " 'chicken_wings',\n",
       " 'chikki',\n",
       " 'chivda',\n",
       " 'chole_bhature',\n",
       " 'daal_baati_churma',\n",
       " 'daal_puri',\n",
       " 'dabeli',\n",
       " 'dal_khichdi',\n",
       " 'dal_makhani',\n",
       " 'dal_tadka',\n",
       " 'dharwad_pedha',\n",
       " 'dhokla',\n",
       " 'double_ka_meetha',\n",
       " 'dum_aloo',\n",
       " 'falooda',\n",
       " 'fish_curry',\n",
       " 'gajar_ka_halwa',\n",
       " 'garlic_bread',\n",
       " 'gavvalu',\n",
       " 'ghevar',\n",
       " 'grilled_sandwich',\n",
       " 'gujhia',\n",
       " 'gulab_jamun',\n",
       " 'hara_bhara_kabab',\n",
       " 'idiyappam',\n",
       " 'idli',\n",
       " 'imarti',\n",
       " 'jalebi',\n",
       " 'kachori',\n",
       " 'kadai_paneer',\n",
       " 'kadhi_pakoda',\n",
       " 'kaju_katli',\n",
       " 'kakinada_khaja',\n",
       " 'kalakand',\n",
       " 'karela_bharta',\n",
       " 'khakhra',\n",
       " 'kheer',\n",
       " 'kofta',\n",
       " 'kulfi',\n",
       " 'lassi',\n",
       " 'ledikeni',\n",
       " 'litti_chokha',\n",
       " 'lyangcha',\n",
       " 'maach_jhol',\n",
       " 'makki_di_roti_sarson_da_saag',\n",
       " 'malpua',\n",
       " 'margherita_pizza',\n",
       " 'masala_dosa',\n",
       " 'masala_papad',\n",
       " 'medu_vada',\n",
       " 'misal_pav',\n",
       " 'misi_roti',\n",
       " 'misti_doi',\n",
       " 'modak',\n",
       " 'moong_dal_halwa',\n",
       " 'murukku',\n",
       " 'mysore_pak',\n",
       " 'naan',\n",
       " 'navratan_korma',\n",
       " 'neer_dosa',\n",
       " 'onion_pakoda',\n",
       " 'palak_paneer',\n",
       " 'paneer_masala',\n",
       " 'paneer_pizza',\n",
       " 'pani_puri',\n",
       " 'paniyaram',\n",
       " 'papdi_chaat',\n",
       " 'patrode',\n",
       " 'pav_bhaji',\n",
       " 'pepperoni_pizza',\n",
       " 'phirni',\n",
       " 'pithe',\n",
       " 'poha',\n",
       " 'pongal',\n",
       " 'poornalu',\n",
       " 'pootharekulu',\n",
       " 'puri_bhaji',\n",
       " 'qubani_ka_meetha',\n",
       " 'rabri',\n",
       " 'rajma_chawal',\n",
       " 'ras_malai',\n",
       " 'rasgulla',\n",
       " 'rava_dosa',\n",
       " 'sabudana_khichdi',\n",
       " 'sabudana_vada',\n",
       " 'samosa',\n",
       " 'sandesh',\n",
       " 'seekh_kebab',\n",
       " 'set_dosa',\n",
       " 'sev_puri',\n",
       " 'shankarpali',\n",
       " 'sheer_korma',\n",
       " 'sheera',\n",
       " 'shrikhand',\n",
       " 'soan_papdi',\n",
       " 'solkadhi',\n",
       " 'steamed_momo',\n",
       " 'sutar_feni',\n",
       " 'thali',\n",
       " 'thukpa',\n",
       " 'unni_appam',\n",
       " 'uttapam',\n",
       " 'vada_pav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_dataset.class_to_idx)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e91c78e-69a2-48a2-813a-3accfe83b1bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:09:53.023657Z",
     "iopub.status.busy": "2025-12-26T16:09:53.023657Z",
     "iopub.status.idle": "2025-12-26T16:09:53.034176Z",
     "shell.execute_reply": "2025-12-26T16:09:53.031713Z",
     "shell.execute_reply.started": "2025-12-26T16:09:53.023657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e48f9d9a-739a-4e0c-a912-6a58fff8bc61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:12:14.253972Z",
     "iopub.status.busy": "2025-12-26T16:12:14.253972Z",
     "iopub.status.idle": "2025-12-26T16:12:14.261465Z",
     "shell.execute_reply": "2025-12-26T16:12:14.259452Z",
     "shell.execute_reply.started": "2025-12-26T16:12:14.253972Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodClassifierEffNet(nn.Module):\n",
    "    def __init__(self, num_classes=131):\n",
    "        super(FoodClassifierEffNet, self).__init__()\n",
    "\n",
    "        # load pre-trained eff_net\n",
    "        self.base_model = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # freeze base model parameters\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove original classifier\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "\n",
    "        # add custom layers\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.output_layer = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a112f7a4-cee7-45e3-8f49-2d503b30dca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:12:14.606839Z",
     "iopub.status.busy": "2025-12-26T16:12:14.606839Z",
     "iopub.status.idle": "2025-12-26T16:12:15.591628Z",
     "shell.execute_reply": "2025-12-26T16:12:15.591628Z",
     "shell.execute_reply.started": "2025-12-26T16:12:14.606839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FoodClassifierEffNet(\n",
       "  (base_model): EfficientNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        )\n",
       "        (1): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
       "        )\n",
       "        (1): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
       "        )\n",
       "        (2): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
       "        )\n",
       "        (3): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
       "        )\n",
       "        (1): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
       "        )\n",
       "        (2): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "        )\n",
       "        (3): FusedMBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "              (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
       "        )\n",
       "        (8): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
       "              (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "        )\n",
       "        (1): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
       "        )\n",
       "        (2): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
       "        )\n",
       "        (3): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
       "        )\n",
       "        (4): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
       "        )\n",
       "        (5): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
       "        )\n",
       "        (6): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
       "        )\n",
       "        (7): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "        )\n",
       "        (8): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
       "        )\n",
       "        (9): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
       "        )\n",
       "        (10): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
       "        )\n",
       "        (11): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
       "        )\n",
       "        (12): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
       "        )\n",
       "        (13): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
       "        )\n",
       "        (14): MBConv(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "              (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (2): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): SiLU(inplace=True)\n",
       "              (scale_activation): Sigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
       "        )\n",
       "      )\n",
       "      (7): Conv2dNormActivation(\n",
       "        (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Identity()\n",
       "  )\n",
       "  (global_avg_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (output_layer): Linear(in_features=1280, out_features=131, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FoodClassifierEffNet(num_classes=131)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4dcb8be-82e5-4632-b9fe-f0d25b485649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:12:15.591628Z",
     "iopub.status.busy": "2025-12-26T16:12:15.591628Z",
     "iopub.status.idle": "2025-12-26T16:12:15.599612Z",
     "shell.execute_reply": "2025-12-26T16:12:15.598565Z",
     "shell.execute_reply.started": "2025-12-26T16:12:15.591628Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "238757f8-e143-4319-8825-731b7fc6dd43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:12:15.600615Z",
     "iopub.status.busy": "2025-12-26T16:12:15.600615Z",
     "iopub.status.idle": "2025-12-26T16:12:15.610407Z",
     "shell.execute_reply": "2025-12-26T16:12:15.609086Z",
     "shell.execute_reply.started": "2025-12-26T16:12:15.600615Z"
    }
   },
   "outputs": [],
   "source": [
    "# tuning the learning rate\n",
    "def make_model(learning_rate=0.01):\n",
    "    model = FoodClassifierEffNet(num_classes=131)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3db73c17-c927-4412-911c-a8e2be894bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T03:48:52.361907Z",
     "iopub.status.busy": "2025-12-27T03:48:52.360923Z",
     "iopub.status.idle": "2025-12-27T03:48:52.375547Z",
     "shell.execute_reply": "2025-12-27T03:48:52.373530Z",
     "shell.execute_reply.started": "2025-12-27T03:48:52.361907Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device):\n",
    "    best_val_accuracy = 0.0  # Initialize variable to track the best validation accuracy\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            checkpoint_path = f'food_effnet_v23_{epoch+1:02d}_{val_acc:.3f}.pth'\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f'Checkpoint saved: {checkpoint_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c961dd-45a3-4f79-a818-85802bf481a8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tuning the Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aebf1d6b-40fb-4e60-b0ae-10f2cfbf98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T16:12:16.896579Z",
     "iopub.status.busy": "2025-12-26T16:12:16.895577Z",
     "iopub.status.idle": "2025-12-26T18:50:29.612392Z",
     "shell.execute_reply": "2025-12-26T18:50:29.612392Z",
     "shell.execute_reply.started": "2025-12-26T16:12:16.896579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.1\n",
      "Epoch 1/10\n",
      "  Train Loss: 14.8507, Train Acc: 0.3152\n",
      "  Val Loss: 10.8857, Val Acc: 0.4593\n",
      "Checkpoint saved: food_effnet_v21_01_0.459.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 14.5278, Train Acc: 0.4203\n",
      "  Val Loss: 12.2458, Val Acc: 0.4980\n",
      "Checkpoint saved: food_effnet_v21_02_0.498.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 14.6965, Train Acc: 0.4550\n",
      "  Val Loss: 12.4444, Val Acc: 0.5300\n",
      "Checkpoint saved: food_effnet_v21_03_0.530.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 15.1088, Train Acc: 0.4860\n",
      "  Val Loss: 13.9250, Val Acc: 0.5320\n",
      "Checkpoint saved: food_effnet_v21_04_0.532.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 15.2407, Train Acc: 0.5065\n",
      "  Val Loss: 13.1603, Val Acc: 0.5613\n",
      "Checkpoint saved: food_effnet_v21_05_0.561.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 14.6913, Train Acc: 0.5232\n",
      "  Val Loss: 14.9979, Val Acc: 0.5293\n",
      "Epoch 7/10\n",
      "  Train Loss: 15.2218, Train Acc: 0.5287\n",
      "  Val Loss: 14.2781, Val Acc: 0.5567\n",
      "Epoch 8/10\n",
      "  Train Loss: 14.8524, Train Acc: 0.5530\n",
      "  Val Loss: 15.6292, Val Acc: 0.5633\n",
      "Checkpoint saved: food_effnet_v21_08_0.563.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 15.3075, Train Acc: 0.5503\n",
      "  Val Loss: 14.1008, Val Acc: 0.5867\n",
      "Checkpoint saved: food_effnet_v21_09_0.587.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 14.5608, Train Acc: 0.5612\n",
      "  Val Loss: 14.9250, Val Acc: 0.5840\n",
      "\n",
      "\n",
      "learning rate = 0.01\n",
      "Epoch 1/10\n",
      "  Train Loss: 2.7637, Train Acc: 0.3982\n",
      "  Val Loss: 1.8398, Val Acc: 0.5653\n",
      "Checkpoint saved: food_effnet_v21_01_0.565.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.1032, Train Acc: 0.5055\n",
      "  Val Loss: 1.7686, Val Acc: 0.5620\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.9386, Train Acc: 0.5492\n",
      "  Val Loss: 1.8052, Val Acc: 0.5913\n",
      "Checkpoint saved: food_effnet_v21_03_0.591.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.9251, Train Acc: 0.5568\n",
      "  Val Loss: 1.8552, Val Acc: 0.5887\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.9349, Train Acc: 0.5682\n",
      "  Val Loss: 1.9538, Val Acc: 0.5773\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.9175, Train Acc: 0.5783\n",
      "  Val Loss: 1.8848, Val Acc: 0.6080\n",
      "Checkpoint saved: food_effnet_v21_06_0.608.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.8356, Train Acc: 0.5982\n",
      "  Val Loss: 1.8413, Val Acc: 0.6133\n",
      "Checkpoint saved: food_effnet_v21_07_0.613.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.8413, Train Acc: 0.5958\n",
      "  Val Loss: 1.9187, Val Acc: 0.6080\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.8543, Train Acc: 0.5993\n",
      "  Val Loss: 1.9898, Val Acc: 0.5953\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.8158, Train Acc: 0.6008\n",
      "  Val Loss: 2.0219, Val Acc: 0.6033\n",
      "\n",
      "\n",
      "learning rate = 0.001\n",
      "Epoch 1/10\n",
      "  Train Loss: 3.3384, Train Acc: 0.3205\n",
      "  Val Loss: 2.5557, Val Acc: 0.5220\n",
      "Checkpoint saved: food_effnet_v21_01_0.522.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.4039, Train Acc: 0.4787\n",
      "  Val Loss: 2.0299, Val Acc: 0.5660\n",
      "Checkpoint saved: food_effnet_v21_02_0.566.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 2.0464, Train Acc: 0.5280\n",
      "  Val Loss: 1.8030, Val Acc: 0.6060\n",
      "Checkpoint saved: food_effnet_v21_03_0.606.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.8436, Train Acc: 0.5608\n",
      "  Val Loss: 1.6414, Val Acc: 0.6233\n",
      "Checkpoint saved: food_effnet_v21_04_0.623.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.7174, Train Acc: 0.5795\n",
      "  Val Loss: 1.5601, Val Acc: 0.6480\n",
      "Checkpoint saved: food_effnet_v21_05_0.648.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.6461, Train Acc: 0.5968\n",
      "  Val Loss: 1.5117, Val Acc: 0.6493\n",
      "Checkpoint saved: food_effnet_v21_06_0.649.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.5935, Train Acc: 0.6002\n",
      "  Val Loss: 1.4422, Val Acc: 0.6667\n",
      "Checkpoint saved: food_effnet_v21_07_0.667.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.5386, Train Acc: 0.6182\n",
      "  Val Loss: 1.4585, Val Acc: 0.6560\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.4966, Train Acc: 0.6255\n",
      "  Val Loss: 1.3795, Val Acc: 0.6673\n",
      "Checkpoint saved: food_effnet_v21_09_0.667.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.4821, Train Acc: 0.6202\n",
      "  Val Loss: 1.3563, Val Acc: 0.6693\n",
      "Checkpoint saved: food_effnet_v21_10_0.669.pth\n",
      "\n",
      "\n",
      "learning rate = 0.0001\n",
      "Epoch 1/10\n",
      "  Train Loss: 4.3266, Train Acc: 0.1163\n",
      "  Val Loss: 4.1773, Val Acc: 0.2347\n",
      "Checkpoint saved: food_effnet_v21_01_0.235.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 3.8348, Train Acc: 0.2410\n",
      "  Val Loss: 3.8594, Val Acc: 0.3453\n",
      "Checkpoint saved: food_effnet_v21_02_0.345.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 3.5993, Train Acc: 0.2987\n",
      "  Val Loss: 3.6232, Val Acc: 0.4040\n",
      "Checkpoint saved: food_effnet_v21_03_0.404.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 3.3893, Train Acc: 0.3585\n",
      "  Val Loss: 3.3764, Val Acc: 0.4387\n",
      "Checkpoint saved: food_effnet_v21_04_0.439.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 3.2355, Train Acc: 0.3807\n",
      "  Val Loss: 3.1853, Val Acc: 0.4560\n",
      "Checkpoint saved: food_effnet_v21_05_0.456.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 3.0766, Train Acc: 0.3940\n",
      "  Val Loss: 3.0558, Val Acc: 0.4780\n",
      "Checkpoint saved: food_effnet_v21_06_0.478.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 2.9499, Train Acc: 0.4200\n",
      "  Val Loss: 2.8989, Val Acc: 0.4967\n",
      "Checkpoint saved: food_effnet_v21_07_0.497.pth\n",
      "Epoch 8/10\n",
      "  Train Loss: 2.8484, Train Acc: 0.4253\n",
      "  Val Loss: 2.8589, Val Acc: 0.4973\n",
      "Checkpoint saved: food_effnet_v21_08_0.497.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 2.7574, Train Acc: 0.4297\n",
      "  Val Loss: 2.7239, Val Acc: 0.5140\n",
      "Checkpoint saved: food_effnet_v21_09_0.514.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 2.6559, Train Acc: 0.4578\n",
      "  Val Loss: 2.6008, Val Acc: 0.5280\n",
      "Checkpoint saved: food_effnet_v21_10_0.528.pth\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for lr in [0.1, 0.01, 0.001, 0.0001]:\n",
    "    print(\"learning rate =\", lr)\n",
    "    model, optimizer = make_model(lr)\n",
    "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3bb0061-95d2-473b-b206-3b8e5d237b2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T15:42:46.905050Z",
     "iopub.status.busy": "2025-12-26T15:42:46.904011Z",
     "iopub.status.idle": "2025-12-26T15:42:46.910882Z",
     "shell.execute_reply": "2025-12-26T15:42:46.908820Z",
     "shell.execute_reply.started": "2025-12-26T15:42:46.905050Z"
    }
   },
   "outputs": [],
   "source": [
    "# best lr : 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847d48a-4492-40ae-8d05-39ad29336560",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tuning the Number of Inner Layers to be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "60c998f4-c449-4059-996c-38f49cdcf0e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T03:48:55.664040Z",
     "iopub.status.busy": "2025-12-27T03:48:55.663063Z",
     "iopub.status.idle": "2025-12-27T03:48:55.675155Z",
     "shell.execute_reply": "2025-12-27T03:48:55.673097Z",
     "shell.execute_reply.started": "2025-12-27T03:48:55.664040Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodClassifierEffNet(nn.Module):\n",
    "    def __init__(self, size_inner=100, num_classes=131):\n",
    "        super(FoodClassifierEffNet, self).__init__()\n",
    "\n",
    "        # load pre-trained effnet\n",
    "        self.base_model = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # freeze base model parameters\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove original classifier\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "\n",
    "        # add custom layers\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # add inner layers\n",
    "        self.inner = nn.Linear(1280, size_inner)  # New inner layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.inner(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_model(\n",
    "        learning_rate=0.001,\n",
    "        size_inner=100\n",
    "):\n",
    "    model = FoodClassifierEffNet(\n",
    "        num_classes=131,\n",
    "        size_inner=size_inner\n",
    "    )\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7055760-ab52-4751-ac07-22646005d9b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T01:38:53.504086Z",
     "iopub.status.busy": "2025-12-27T01:38:53.504086Z",
     "iopub.status.idle": "2025-12-27T03:47:55.346318Z",
     "shell.execute_reply": "2025-12-27T03:47:55.344106Z",
     "shell.execute_reply.started": "2025-12-27T01:38:53.504086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_inner : 1000\n",
      "Epoch 1/10\n",
      "  Train Loss: 2.8462, Train Acc: 0.3553\n",
      "  Val Loss: 1.8857, Val Acc: 0.5453\n",
      "Checkpoint saved: food_effnet_v22_01_0.545.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 1.9414, Train Acc: 0.5120\n",
      "  Val Loss: 1.5681, Val Acc: 0.6080\n",
      "Checkpoint saved: food_effnet_v22_02_0.608.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.7070, Train Acc: 0.5578\n",
      "  Val Loss: 1.4477, Val Acc: 0.6260\n",
      "Checkpoint saved: food_effnet_v22_03_0.626.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.6109, Train Acc: 0.5755\n",
      "  Val Loss: 1.4325, Val Acc: 0.6100\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.5295, Train Acc: 0.5890\n",
      "  Val Loss: 1.4073, Val Acc: 0.6340\n",
      "Checkpoint saved: food_effnet_v22_05_0.634.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.4479, Train Acc: 0.6077\n",
      "  Val Loss: 1.3562, Val Acc: 0.6547\n",
      "Checkpoint saved: food_effnet_v22_06_0.655.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.3825, Train Acc: 0.6270\n",
      "  Val Loss: 1.3834, Val Acc: 0.6447\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.3320, Train Acc: 0.6313\n",
      "  Val Loss: 1.4052, Val Acc: 0.6473\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.2942, Train Acc: 0.6477\n",
      "  Val Loss: 1.4212, Val Acc: 0.6480\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.2919, Train Acc: 0.6462\n",
      "  Val Loss: 1.4290, Val Acc: 0.6633\n",
      "Checkpoint saved: food_effnet_v22_10_0.663.pth\n",
      "\n",
      "size_inner : 500\n",
      "Epoch 1/10\n",
      "  Train Loss: 2.9674, Train Acc: 0.3415\n",
      "  Val Loss: 1.9825, Val Acc: 0.5253\n",
      "Checkpoint saved: food_effnet_v22_01_0.525.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.0384, Train Acc: 0.4995\n",
      "  Val Loss: 1.6258, Val Acc: 0.6073\n",
      "Checkpoint saved: food_effnet_v22_02_0.607.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.7994, Train Acc: 0.5420\n",
      "  Val Loss: 1.4971, Val Acc: 0.6113\n",
      "Checkpoint saved: food_effnet_v22_03_0.611.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.6787, Train Acc: 0.5642\n",
      "  Val Loss: 1.4131, Val Acc: 0.6400\n",
      "Checkpoint saved: food_effnet_v22_04_0.640.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.5760, Train Acc: 0.5853\n",
      "  Val Loss: 1.3616, Val Acc: 0.6573\n",
      "Checkpoint saved: food_effnet_v22_05_0.657.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.4699, Train Acc: 0.6085\n",
      "  Val Loss: 1.3337, Val Acc: 0.6500\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.3943, Train Acc: 0.6187\n",
      "  Val Loss: 1.3320, Val Acc: 0.6493\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.3785, Train Acc: 0.6227\n",
      "  Val Loss: 1.2968, Val Acc: 0.6793\n",
      "Checkpoint saved: food_effnet_v22_08_0.679.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.2828, Train Acc: 0.6413\n",
      "  Val Loss: 1.2650, Val Acc: 0.6853\n",
      "Checkpoint saved: food_effnet_v22_09_0.685.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.3050, Train Acc: 0.6438\n",
      "  Val Loss: 1.2831, Val Acc: 0.6807\n",
      "\n",
      "size_inner : 200\n",
      "Epoch 1/10\n",
      "  Train Loss: 3.2061, Train Acc: 0.3067\n",
      "  Val Loss: 2.2772, Val Acc: 0.4940\n",
      "Checkpoint saved: food_effnet_v22_01_0.494.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.2147, Train Acc: 0.4747\n",
      "  Val Loss: 1.8297, Val Acc: 0.5813\n",
      "Checkpoint saved: food_effnet_v22_02_0.581.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 1.9248, Train Acc: 0.5215\n",
      "  Val Loss: 1.5882, Val Acc: 0.6020\n",
      "Checkpoint saved: food_effnet_v22_03_0.602.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.7682, Train Acc: 0.5557\n",
      "  Val Loss: 1.4915, Val Acc: 0.6267\n",
      "Checkpoint saved: food_effnet_v22_04_0.627.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.6354, Train Acc: 0.5835\n",
      "  Val Loss: 1.4175, Val Acc: 0.6460\n",
      "Checkpoint saved: food_effnet_v22_05_0.646.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.5957, Train Acc: 0.5850\n",
      "  Val Loss: 1.3706, Val Acc: 0.6527\n",
      "Checkpoint saved: food_effnet_v22_06_0.653.pth\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.5185, Train Acc: 0.6030\n",
      "  Val Loss: 1.3724, Val Acc: 0.6393\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.4735, Train Acc: 0.6103\n",
      "  Val Loss: 1.3588, Val Acc: 0.6460\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.4706, Train Acc: 0.6122\n",
      "  Val Loss: 1.3438, Val Acc: 0.6600\n",
      "Checkpoint saved: food_effnet_v22_09_0.660.pth\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.3697, Train Acc: 0.6327\n",
      "  Val Loss: 1.3240, Val Acc: 0.6640\n",
      "Checkpoint saved: food_effnet_v22_10_0.664.pth\n",
      "\n",
      "size_inner : 100\n",
      "Epoch 1/10\n",
      "  Train Loss: 3.3993, Train Acc: 0.2778\n",
      "  Val Loss: 2.4522, Val Acc: 0.4653\n",
      "Checkpoint saved: food_effnet_v22_01_0.465.pth\n",
      "Epoch 2/10\n",
      "  Train Loss: 2.3684, Train Acc: 0.4440\n",
      "  Val Loss: 1.9865, Val Acc: 0.5453\n",
      "Checkpoint saved: food_effnet_v22_02_0.545.pth\n",
      "Epoch 3/10\n",
      "  Train Loss: 2.0694, Train Acc: 0.5027\n",
      "  Val Loss: 1.7491, Val Acc: 0.5867\n",
      "Checkpoint saved: food_effnet_v22_03_0.587.pth\n",
      "Epoch 4/10\n",
      "  Train Loss: 1.8907, Train Acc: 0.5327\n",
      "  Val Loss: 1.6507, Val Acc: 0.5947\n",
      "Checkpoint saved: food_effnet_v22_04_0.595.pth\n",
      "Epoch 5/10\n",
      "  Train Loss: 1.7685, Train Acc: 0.5597\n",
      "  Val Loss: 1.5033, Val Acc: 0.6400\n",
      "Checkpoint saved: food_effnet_v22_05_0.640.pth\n",
      "Epoch 6/10\n",
      "  Train Loss: 1.7126, Train Acc: 0.5675\n",
      "  Val Loss: 1.4717, Val Acc: 0.6327\n",
      "Epoch 7/10\n",
      "  Train Loss: 1.6029, Train Acc: 0.5822\n",
      "  Val Loss: 1.4238, Val Acc: 0.6393\n",
      "Epoch 8/10\n",
      "  Train Loss: 1.5761, Train Acc: 0.5918\n",
      "  Val Loss: 1.4159, Val Acc: 0.6513\n",
      "Checkpoint saved: food_effnet_v22_08_0.651.pth\n",
      "Epoch 9/10\n",
      "  Train Loss: 1.5412, Train Acc: 0.5955\n",
      "  Val Loss: 1.3841, Val Acc: 0.6447\n",
      "Epoch 10/10\n",
      "  Train Loss: 1.4743, Train Acc: 0.6140\n",
      "  Val Loss: 1.3468, Val Acc: 0.6520\n",
      "Checkpoint saved: food_effnet_v22_10_0.652.pth\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for size_inner in [1000, 500, 200, 100]:\n",
    "    print(f\"size_inner : {size_inner}\")\n",
    "    model, optimizer = make_model(\n",
    "        learning_rate=0.001,\n",
    "        size_inner=size_inner\n",
    "    )\n",
    "    \n",
    "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba9a4f1-49c2-4aa9-93f5-718bb420a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best inner layers size : 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59c469-5738-42df-9b9e-7f6626e4affb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tuning the Drop Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "593fec61-d9e0-42c3-ae7f-1e199bd0e443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T03:49:05.007205Z",
     "iopub.status.busy": "2025-12-27T03:49:05.007205Z",
     "iopub.status.idle": "2025-12-27T03:49:05.016154Z",
     "shell.execute_reply": "2025-12-27T03:49:05.014121Z",
     "shell.execute_reply.started": "2025-12-27T03:49:05.007205Z"
    }
   },
   "outputs": [],
   "source": [
    "class FoodClassifierEffNet(nn.Module):\n",
    "    def __init__(self, size_inner=500, droprate=0.2, num_classes=131):\n",
    "        super(FoodClassifierEffNet, self).__init__()\n",
    "\n",
    "        # load pre-trained eff_net\n",
    "        self.base_model = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # freeze base model parameters\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove original classifier\n",
    "        self.base_model.classifier = nn.Identity()\n",
    "\n",
    "        # add custom layers\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1,1))\n",
    "        # add inner layers\n",
    "        self.inner = nn.Linear(1280, size_inner)  # New inner layer\n",
    "        self.relu = nn.ReLU()\n",
    "        # add dropout\n",
    "        self.dropout = nn.Dropout(droprate)\n",
    "        self.output_layer = nn.Linear(size_inner, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.features(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.inner(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # apply dropout\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_model(\n",
    "        learning_rate=0.01,\n",
    "        size_inner=500,\n",
    "        droprate=0.2\n",
    "):\n",
    "    model = FoodClassifierEffNet(\n",
    "        num_classes=131,\n",
    "        size_inner=size_inner,\n",
    "        droprate=droprate\n",
    "    )\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "751e21d3-c821-41c0-b1dd-caaca99c9d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-27T03:49:09.000231Z",
     "iopub.status.busy": "2025-12-27T03:49:08.999219Z",
     "iopub.status.idle": "2025-12-27T14:22:58.768181Z",
     "shell.execute_reply": "2025-12-27T14:22:58.768181Z",
     "shell.execute_reply.started": "2025-12-27T03:49:09.000231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_rate : 0.1\n",
      "Epoch 1/40\n",
      "  Train Loss: 3.0088, Train Acc: 0.3297\n",
      "  Val Loss: 2.0578, Val Acc: 0.5213\n",
      "Checkpoint saved: food_effnet_v23_01_0.521.pth\n",
      "Epoch 2/40\n",
      "  Train Loss: 2.0867, Train Acc: 0.4882\n",
      "  Val Loss: 1.6176, Val Acc: 0.6060\n",
      "Checkpoint saved: food_effnet_v23_02_0.606.pth\n",
      "Epoch 3/40\n",
      "  Train Loss: 1.8119, Train Acc: 0.5423\n",
      "  Val Loss: 1.4795, Val Acc: 0.6293\n",
      "Checkpoint saved: food_effnet_v23_03_0.629.pth\n",
      "Epoch 4/40\n",
      "  Train Loss: 1.7139, Train Acc: 0.5578\n",
      "  Val Loss: 1.3892, Val Acc: 0.6513\n",
      "Checkpoint saved: food_effnet_v23_04_0.651.pth\n",
      "Epoch 5/40\n",
      "  Train Loss: 1.5703, Train Acc: 0.5853\n",
      "  Val Loss: 1.3855, Val Acc: 0.6407\n",
      "Epoch 6/40\n",
      "  Train Loss: 1.5266, Train Acc: 0.5930\n",
      "  Val Loss: 1.3304, Val Acc: 0.6607\n",
      "Checkpoint saved: food_effnet_v23_06_0.661.pth\n",
      "Epoch 7/40\n",
      "  Train Loss: 1.4455, Train Acc: 0.6098\n",
      "  Val Loss: 1.3359, Val Acc: 0.6507\n",
      "Epoch 8/40\n",
      "  Train Loss: 1.3987, Train Acc: 0.6202\n",
      "  Val Loss: 1.2725, Val Acc: 0.6747\n",
      "Checkpoint saved: food_effnet_v23_08_0.675.pth\n",
      "Epoch 9/40\n",
      "  Train Loss: 1.3753, Train Acc: 0.6307\n",
      "  Val Loss: 1.3057, Val Acc: 0.6607\n",
      "Epoch 10/40\n",
      "  Train Loss: 1.3524, Train Acc: 0.6318\n",
      "  Val Loss: 1.3347, Val Acc: 0.6507\n",
      "Epoch 11/40\n",
      "  Train Loss: 1.2988, Train Acc: 0.6470\n",
      "  Val Loss: 1.3231, Val Acc: 0.6560\n",
      "Epoch 12/40\n",
      "  Train Loss: 1.2535, Train Acc: 0.6553\n",
      "  Val Loss: 1.3309, Val Acc: 0.6513\n",
      "Epoch 13/40\n",
      "  Train Loss: 1.2382, Train Acc: 0.6630\n",
      "  Val Loss: 1.3218, Val Acc: 0.6600\n",
      "Epoch 14/40\n",
      "  Train Loss: 1.2070, Train Acc: 0.6655\n",
      "  Val Loss: 1.2831, Val Acc: 0.6780\n",
      "Checkpoint saved: food_effnet_v23_14_0.678.pth\n",
      "Epoch 15/40\n",
      "  Train Loss: 1.2109, Train Acc: 0.6650\n",
      "  Val Loss: 1.2844, Val Acc: 0.6727\n",
      "Epoch 16/40\n",
      "  Train Loss: 1.1814, Train Acc: 0.6750\n",
      "  Val Loss: 1.3203, Val Acc: 0.6700\n",
      "Epoch 17/40\n",
      "  Train Loss: 1.1876, Train Acc: 0.6630\n",
      "  Val Loss: 1.3428, Val Acc: 0.6673\n",
      "Epoch 18/40\n",
      "  Train Loss: 1.1633, Train Acc: 0.6830\n",
      "  Val Loss: 1.3040, Val Acc: 0.6767\n",
      "Epoch 19/40\n",
      "  Train Loss: 1.1193, Train Acc: 0.6958\n",
      "  Val Loss: 1.3354, Val Acc: 0.6793\n",
      "Checkpoint saved: food_effnet_v23_19_0.679.pth\n",
      "Epoch 20/40\n",
      "  Train Loss: 1.1014, Train Acc: 0.6945\n",
      "  Val Loss: 1.3074, Val Acc: 0.6833\n",
      "Checkpoint saved: food_effnet_v23_20_0.683.pth\n",
      "Epoch 21/40\n",
      "  Train Loss: 1.1122, Train Acc: 0.6833\n",
      "  Val Loss: 1.3159, Val Acc: 0.6800\n",
      "Epoch 22/40\n",
      "  Train Loss: 1.0811, Train Acc: 0.6995\n",
      "  Val Loss: 1.3116, Val Acc: 0.6927\n",
      "Checkpoint saved: food_effnet_v23_22_0.693.pth\n",
      "Epoch 23/40\n",
      "  Train Loss: 1.0646, Train Acc: 0.7030\n",
      "  Val Loss: 1.3222, Val Acc: 0.6827\n",
      "Epoch 24/40\n",
      "  Train Loss: 1.0892, Train Acc: 0.6985\n",
      "  Val Loss: 1.3847, Val Acc: 0.6713\n",
      "Epoch 25/40\n",
      "  Train Loss: 1.0500, Train Acc: 0.7085\n",
      "  Val Loss: 1.4024, Val Acc: 0.6787\n",
      "Epoch 26/40\n",
      "  Train Loss: 1.0594, Train Acc: 0.7117\n",
      "  Val Loss: 1.3865, Val Acc: 0.6847\n",
      "Epoch 27/40\n",
      "  Train Loss: 1.0461, Train Acc: 0.7127\n",
      "  Val Loss: 1.4274, Val Acc: 0.6840\n",
      "Epoch 28/40\n",
      "  Train Loss: 1.0287, Train Acc: 0.7107\n",
      "  Val Loss: 1.4081, Val Acc: 0.6867\n",
      "Epoch 29/40\n",
      "  Train Loss: 0.9902, Train Acc: 0.7250\n",
      "  Val Loss: 1.4503, Val Acc: 0.6820\n",
      "Epoch 30/40\n",
      "  Train Loss: 0.9990, Train Acc: 0.7157\n",
      "  Val Loss: 1.4686, Val Acc: 0.6847\n",
      "Epoch 31/40\n",
      "  Train Loss: 0.9995, Train Acc: 0.7175\n",
      "  Val Loss: 1.4585, Val Acc: 0.6920\n",
      "Epoch 32/40\n",
      "  Train Loss: 1.0341, Train Acc: 0.7093\n",
      "  Val Loss: 1.5239, Val Acc: 0.6773\n",
      "Epoch 33/40\n",
      "  Train Loss: 1.0028, Train Acc: 0.7228\n",
      "  Val Loss: 1.4678, Val Acc: 0.6833\n",
      "Epoch 34/40\n",
      "  Train Loss: 1.0009, Train Acc: 0.7197\n",
      "  Val Loss: 1.4595, Val Acc: 0.6953\n",
      "Checkpoint saved: food_effnet_v23_34_0.695.pth\n",
      "Epoch 35/40\n",
      "  Train Loss: 0.9614, Train Acc: 0.7350\n",
      "  Val Loss: 1.4594, Val Acc: 0.6900\n",
      "Epoch 36/40\n",
      "  Train Loss: 0.9700, Train Acc: 0.7335\n",
      "  Val Loss: 1.4849, Val Acc: 0.6913\n",
      "Epoch 37/40\n",
      "  Train Loss: 0.9648, Train Acc: 0.7375\n",
      "  Val Loss: 1.5447, Val Acc: 0.6727\n",
      "Epoch 38/40\n",
      "  Train Loss: 0.9740, Train Acc: 0.7295\n",
      "  Val Loss: 1.4875, Val Acc: 0.6887\n",
      "Epoch 39/40\n",
      "  Train Loss: 0.9528, Train Acc: 0.7350\n",
      "  Val Loss: 1.5430, Val Acc: 0.6873\n",
      "Epoch 40/40\n",
      "  Train Loss: 0.9784, Train Acc: 0.7230\n",
      "  Val Loss: 1.5273, Val Acc: 0.6840\n",
      "\n",
      "drop_rate : 0.2\n",
      "Epoch 1/40\n",
      "  Train Loss: 3.0468, Train Acc: 0.3293\n",
      "  Val Loss: 2.0613, Val Acc: 0.5287\n",
      "Checkpoint saved: food_effnet_v23_01_0.529.pth\n",
      "Epoch 2/40\n",
      "  Train Loss: 2.1149, Train Acc: 0.4892\n",
      "  Val Loss: 1.6913, Val Acc: 0.5847\n",
      "Checkpoint saved: food_effnet_v23_02_0.585.pth\n",
      "Epoch 3/40\n",
      "  Train Loss: 1.8680, Train Acc: 0.5257\n",
      "  Val Loss: 1.5043, Val Acc: 0.6280\n",
      "Checkpoint saved: food_effnet_v23_03_0.628.pth\n",
      "Epoch 4/40\n",
      "  Train Loss: 1.7372, Train Acc: 0.5485\n",
      "  Val Loss: 1.4319, Val Acc: 0.6413\n",
      "Checkpoint saved: food_effnet_v23_04_0.641.pth\n",
      "Epoch 5/40\n",
      "  Train Loss: 1.6303, Train Acc: 0.5690\n",
      "  Val Loss: 1.4087, Val Acc: 0.6500\n",
      "Checkpoint saved: food_effnet_v23_05_0.650.pth\n",
      "Epoch 6/40\n",
      "  Train Loss: 1.5210, Train Acc: 0.6022\n",
      "  Val Loss: 1.3460, Val Acc: 0.6573\n",
      "Checkpoint saved: food_effnet_v23_06_0.657.pth\n",
      "Epoch 7/40\n",
      "  Train Loss: 1.4974, Train Acc: 0.5962\n",
      "  Val Loss: 1.3075, Val Acc: 0.6713\n",
      "Checkpoint saved: food_effnet_v23_07_0.671.pth\n",
      "Epoch 8/40\n",
      "  Train Loss: 1.4404, Train Acc: 0.6080\n",
      "  Val Loss: 1.3107, Val Acc: 0.6733\n",
      "Checkpoint saved: food_effnet_v23_08_0.673.pth\n",
      "Epoch 9/40\n",
      "  Train Loss: 1.4496, Train Acc: 0.6072\n",
      "  Val Loss: 1.3195, Val Acc: 0.6633\n",
      "Epoch 10/40\n",
      "  Train Loss: 1.3885, Train Acc: 0.6277\n",
      "  Val Loss: 1.2906, Val Acc: 0.6780\n",
      "Checkpoint saved: food_effnet_v23_10_0.678.pth\n",
      "Epoch 11/40\n",
      "  Train Loss: 1.3569, Train Acc: 0.6347\n",
      "  Val Loss: 1.2708, Val Acc: 0.6793\n",
      "Checkpoint saved: food_effnet_v23_11_0.679.pth\n",
      "Epoch 12/40\n",
      "  Train Loss: 1.3378, Train Acc: 0.6433\n",
      "  Val Loss: 1.3313, Val Acc: 0.6733\n",
      "Epoch 13/40\n",
      "  Train Loss: 1.3142, Train Acc: 0.6412\n",
      "  Val Loss: 1.3201, Val Acc: 0.6680\n",
      "Epoch 14/40\n",
      "  Train Loss: 1.2888, Train Acc: 0.6495\n",
      "  Val Loss: 1.3191, Val Acc: 0.6613\n",
      "Epoch 15/40\n",
      "  Train Loss: 1.3009, Train Acc: 0.6440\n",
      "  Val Loss: 1.3281, Val Acc: 0.6820\n",
      "Checkpoint saved: food_effnet_v23_15_0.682.pth\n",
      "Epoch 16/40\n",
      "  Train Loss: 1.2402, Train Acc: 0.6575\n",
      "  Val Loss: 1.3361, Val Acc: 0.6693\n",
      "Epoch 17/40\n",
      "  Train Loss: 1.2261, Train Acc: 0.6583\n",
      "  Val Loss: 1.3774, Val Acc: 0.6813\n",
      "Epoch 18/40\n",
      "  Train Loss: 1.2139, Train Acc: 0.6687\n",
      "  Val Loss: 1.3416, Val Acc: 0.6807\n",
      "Epoch 19/40\n",
      "  Train Loss: 1.2083, Train Acc: 0.6643\n",
      "  Val Loss: 1.3504, Val Acc: 0.6760\n",
      "Epoch 20/40\n",
      "  Train Loss: 1.1819, Train Acc: 0.6720\n",
      "  Val Loss: 1.3694, Val Acc: 0.6847\n",
      "Checkpoint saved: food_effnet_v23_20_0.685.pth\n",
      "Epoch 21/40\n",
      "  Train Loss: 1.1531, Train Acc: 0.6802\n",
      "  Val Loss: 1.4350, Val Acc: 0.6707\n",
      "Epoch 22/40\n",
      "  Train Loss: 1.1558, Train Acc: 0.6832\n",
      "  Val Loss: 1.3662, Val Acc: 0.6847\n",
      "Epoch 23/40\n",
      "  Train Loss: 1.1894, Train Acc: 0.6733\n",
      "  Val Loss: 1.3843, Val Acc: 0.6813\n",
      "Epoch 24/40\n",
      "  Train Loss: 1.1338, Train Acc: 0.6830\n",
      "  Val Loss: 1.3985, Val Acc: 0.6813\n",
      "Epoch 25/40\n",
      "  Train Loss: 1.1087, Train Acc: 0.6878\n",
      "  Val Loss: 1.3744, Val Acc: 0.6840\n",
      "Epoch 26/40\n",
      "  Train Loss: 1.1520, Train Acc: 0.6775\n",
      "  Val Loss: 1.3909, Val Acc: 0.6747\n",
      "Epoch 27/40\n",
      "  Train Loss: 1.1169, Train Acc: 0.6928\n",
      "  Val Loss: 1.4277, Val Acc: 0.6760\n",
      "Epoch 28/40\n",
      "  Train Loss: 1.0626, Train Acc: 0.7012\n",
      "  Val Loss: 1.4460, Val Acc: 0.6773\n",
      "Epoch 29/40\n",
      "  Train Loss: 1.0599, Train Acc: 0.7052\n",
      "  Val Loss: 1.4171, Val Acc: 0.6847\n",
      "Epoch 30/40\n",
      "  Train Loss: 1.0708, Train Acc: 0.6975\n",
      "  Val Loss: 1.4320, Val Acc: 0.6847\n",
      "Epoch 31/40\n",
      "  Train Loss: 1.0721, Train Acc: 0.7003\n",
      "  Val Loss: 1.4317, Val Acc: 0.6820\n",
      "Epoch 32/40\n",
      "  Train Loss: 1.0649, Train Acc: 0.7045\n",
      "  Val Loss: 1.4366, Val Acc: 0.6833\n",
      "Epoch 33/40\n",
      "  Train Loss: 1.0727, Train Acc: 0.7042\n",
      "  Val Loss: 1.4637, Val Acc: 0.6833\n",
      "Epoch 34/40\n",
      "  Train Loss: 1.0863, Train Acc: 0.7078\n",
      "  Val Loss: 1.4719, Val Acc: 0.6693\n",
      "Epoch 35/40\n",
      "  Train Loss: 1.0310, Train Acc: 0.7175\n",
      "  Val Loss: 1.5242, Val Acc: 0.6753\n",
      "Epoch 36/40\n",
      "  Train Loss: 1.0317, Train Acc: 0.7098\n",
      "  Val Loss: 1.5103, Val Acc: 0.6880\n",
      "Checkpoint saved: food_effnet_v23_36_0.688.pth\n",
      "Epoch 37/40\n",
      "  Train Loss: 1.0348, Train Acc: 0.7178\n",
      "  Val Loss: 1.4907, Val Acc: 0.6653\n",
      "Epoch 38/40\n",
      "  Train Loss: 1.0319, Train Acc: 0.7142\n",
      "  Val Loss: 1.4890, Val Acc: 0.6840\n",
      "Epoch 39/40\n",
      "  Train Loss: 1.0141, Train Acc: 0.7160\n",
      "  Val Loss: 1.4947, Val Acc: 0.6887\n",
      "Checkpoint saved: food_effnet_v23_39_0.689.pth\n",
      "Epoch 40/40\n",
      "  Train Loss: 1.0052, Train Acc: 0.7208\n",
      "  Val Loss: 1.5311, Val Acc: 0.6853\n",
      "\n",
      "drop_rate : 0.3\n",
      "Epoch 1/40\n",
      "  Train Loss: 3.0969, Train Acc: 0.3137\n",
      "  Val Loss: 2.1283, Val Acc: 0.5000\n",
      "Checkpoint saved: food_effnet_v23_01_0.500.pth\n",
      "Epoch 2/40\n",
      "  Train Loss: 2.1586, Train Acc: 0.4813\n",
      "  Val Loss: 1.7389, Val Acc: 0.5813\n",
      "Checkpoint saved: food_effnet_v23_02_0.581.pth\n",
      "Epoch 3/40\n",
      "  Train Loss: 1.9446, Train Acc: 0.5075\n",
      "  Val Loss: 1.5457, Val Acc: 0.6200\n",
      "Checkpoint saved: food_effnet_v23_03_0.620.pth\n",
      "Epoch 4/40\n",
      "  Train Loss: 1.7875, Train Acc: 0.5410\n",
      "  Val Loss: 1.4807, Val Acc: 0.6147\n",
      "Epoch 5/40\n",
      "  Train Loss: 1.7009, Train Acc: 0.5618\n",
      "  Val Loss: 1.4426, Val Acc: 0.6300\n",
      "Checkpoint saved: food_effnet_v23_05_0.630.pth\n",
      "Epoch 6/40\n",
      "  Train Loss: 1.6246, Train Acc: 0.5722\n",
      "  Val Loss: 1.3794, Val Acc: 0.6467\n",
      "Checkpoint saved: food_effnet_v23_06_0.647.pth\n",
      "Epoch 7/40\n",
      "  Train Loss: 1.5819, Train Acc: 0.5842\n",
      "  Val Loss: 1.3442, Val Acc: 0.6547\n",
      "Checkpoint saved: food_effnet_v23_07_0.655.pth\n",
      "Epoch 8/40\n",
      "  Train Loss: 1.5031, Train Acc: 0.5960\n",
      "  Val Loss: 1.3180, Val Acc: 0.6660\n",
      "Checkpoint saved: food_effnet_v23_08_0.666.pth\n",
      "Epoch 9/40\n",
      "  Train Loss: 1.4969, Train Acc: 0.5983\n",
      "  Val Loss: 1.3150, Val Acc: 0.6747\n",
      "Checkpoint saved: food_effnet_v23_09_0.675.pth\n",
      "Epoch 10/40\n",
      "  Train Loss: 1.4690, Train Acc: 0.6032\n",
      "  Val Loss: 1.3428, Val Acc: 0.6753\n",
      "Checkpoint saved: food_effnet_v23_10_0.675.pth\n",
      "Epoch 11/40\n",
      "  Train Loss: 1.4157, Train Acc: 0.6110\n",
      "  Val Loss: 1.3067, Val Acc: 0.6653\n",
      "Epoch 12/40\n",
      "  Train Loss: 1.3853, Train Acc: 0.6193\n",
      "  Val Loss: 1.3098, Val Acc: 0.6680\n",
      "Epoch 13/40\n",
      "  Train Loss: 1.3860, Train Acc: 0.6255\n",
      "  Val Loss: 1.2924, Val Acc: 0.6733\n",
      "Epoch 14/40\n",
      "  Train Loss: 1.3713, Train Acc: 0.6285\n",
      "  Val Loss: 1.2876, Val Acc: 0.6813\n",
      "Checkpoint saved: food_effnet_v23_14_0.681.pth\n",
      "Epoch 15/40\n",
      "  Train Loss: 1.2781, Train Acc: 0.6473\n",
      "  Val Loss: 1.2986, Val Acc: 0.6900\n",
      "Checkpoint saved: food_effnet_v23_15_0.690.pth\n",
      "Epoch 16/40\n",
      "  Train Loss: 1.3090, Train Acc: 0.6470\n",
      "  Val Loss: 1.3169, Val Acc: 0.6800\n",
      "Epoch 17/40\n",
      "  Train Loss: 1.2786, Train Acc: 0.6423\n",
      "  Val Loss: 1.3548, Val Acc: 0.6653\n",
      "Epoch 18/40\n",
      "  Train Loss: 1.2864, Train Acc: 0.6495\n",
      "  Val Loss: 1.3217, Val Acc: 0.6767\n",
      "Epoch 19/40\n",
      "  Train Loss: 1.2733, Train Acc: 0.6482\n",
      "  Val Loss: 1.3272, Val Acc: 0.6847\n",
      "Epoch 20/40\n",
      "  Train Loss: 1.2415, Train Acc: 0.6620\n",
      "  Val Loss: 1.3335, Val Acc: 0.6853\n",
      "Epoch 21/40\n",
      "  Train Loss: 1.2184, Train Acc: 0.6607\n",
      "  Val Loss: 1.3133, Val Acc: 0.6893\n",
      "Epoch 22/40\n",
      "  Train Loss: 1.2175, Train Acc: 0.6632\n",
      "  Val Loss: 1.3472, Val Acc: 0.6847\n",
      "Epoch 23/40\n",
      "  Train Loss: 1.2588, Train Acc: 0.6587\n",
      "  Val Loss: 1.4159, Val Acc: 0.6713\n",
      "Epoch 24/40\n",
      "  Train Loss: 1.2341, Train Acc: 0.6622\n",
      "  Val Loss: 1.3433, Val Acc: 0.6853\n",
      "Epoch 25/40\n",
      "  Train Loss: 1.2056, Train Acc: 0.6670\n",
      "  Val Loss: 1.3500, Val Acc: 0.6927\n",
      "Checkpoint saved: food_effnet_v23_25_0.693.pth\n",
      "Epoch 26/40\n",
      "  Train Loss: 1.1790, Train Acc: 0.6812\n",
      "  Val Loss: 1.3560, Val Acc: 0.6980\n",
      "Checkpoint saved: food_effnet_v23_26_0.698.pth\n",
      "Epoch 27/40\n",
      "  Train Loss: 1.1998, Train Acc: 0.6680\n",
      "  Val Loss: 1.3490, Val Acc: 0.6947\n",
      "Epoch 28/40\n",
      "  Train Loss: 1.1651, Train Acc: 0.6813\n",
      "  Val Loss: 1.3715, Val Acc: 0.6893\n",
      "Epoch 29/40\n",
      "  Train Loss: 1.1789, Train Acc: 0.6765\n",
      "  Val Loss: 1.4126, Val Acc: 0.6847\n",
      "Epoch 30/40\n",
      "  Train Loss: 1.1809, Train Acc: 0.6823\n",
      "  Val Loss: 1.4057, Val Acc: 0.6893\n",
      "Epoch 31/40\n",
      "  Train Loss: 1.1649, Train Acc: 0.6815\n",
      "  Val Loss: 1.3964, Val Acc: 0.6807\n",
      "Epoch 32/40\n",
      "  Train Loss: 1.1382, Train Acc: 0.6898\n",
      "  Val Loss: 1.4270, Val Acc: 0.6940\n",
      "Epoch 33/40\n",
      "  Train Loss: 1.1163, Train Acc: 0.6905\n",
      "  Val Loss: 1.4433, Val Acc: 0.6900\n",
      "Epoch 34/40\n",
      "  Train Loss: 1.1334, Train Acc: 0.6830\n",
      "  Val Loss: 1.4993, Val Acc: 0.6713\n",
      "Epoch 35/40\n",
      "  Train Loss: 1.1430, Train Acc: 0.6863\n",
      "  Val Loss: 1.4826, Val Acc: 0.6853\n",
      "Epoch 36/40\n",
      "  Train Loss: 1.1186, Train Acc: 0.6915\n",
      "  Val Loss: 1.5213, Val Acc: 0.6840\n",
      "Epoch 37/40\n",
      "  Train Loss: 1.1359, Train Acc: 0.6780\n",
      "  Val Loss: 1.5333, Val Acc: 0.6847\n",
      "Epoch 38/40\n",
      "  Train Loss: 1.1010, Train Acc: 0.6908\n",
      "  Val Loss: 1.4936, Val Acc: 0.6713\n",
      "Epoch 39/40\n",
      "  Train Loss: 1.0960, Train Acc: 0.6935\n",
      "  Val Loss: 1.4816, Val Acc: 0.6967\n",
      "Epoch 40/40\n",
      "  Train Loss: 1.0912, Train Acc: 0.6978\n",
      "  Val Loss: 1.4668, Val Acc: 0.7073\n",
      "Checkpoint saved: food_effnet_v23_40_0.707.pth\n",
      "\n",
      "drop_rate : 0.4\n",
      "Epoch 1/40\n",
      "  Train Loss: 3.1671, Train Acc: 0.3067\n",
      "  Val Loss: 2.2134, Val Acc: 0.4940\n",
      "Checkpoint saved: food_effnet_v23_01_0.494.pth\n",
      "Epoch 2/40\n",
      "  Train Loss: 2.2709, Train Acc: 0.4525\n",
      "  Val Loss: 1.7510, Val Acc: 0.5840\n",
      "Checkpoint saved: food_effnet_v23_02_0.584.pth\n",
      "Epoch 3/40\n",
      "  Train Loss: 1.9917, Train Acc: 0.4995\n",
      "  Val Loss: 1.5904, Val Acc: 0.6033\n",
      "Checkpoint saved: food_effnet_v23_03_0.603.pth\n",
      "Epoch 4/40\n",
      "  Train Loss: 1.8911, Train Acc: 0.5235\n",
      "  Val Loss: 1.5242, Val Acc: 0.6147\n",
      "Checkpoint saved: food_effnet_v23_04_0.615.pth\n",
      "Epoch 5/40\n",
      "  Train Loss: 1.7798, Train Acc: 0.5437\n",
      "  Val Loss: 1.4437, Val Acc: 0.6247\n",
      "Checkpoint saved: food_effnet_v23_05_0.625.pth\n",
      "Epoch 6/40\n",
      "  Train Loss: 1.7132, Train Acc: 0.5498\n",
      "  Val Loss: 1.3911, Val Acc: 0.6493\n",
      "Checkpoint saved: food_effnet_v23_06_0.649.pth\n",
      "Epoch 7/40\n",
      "  Train Loss: 1.6417, Train Acc: 0.5703\n",
      "  Val Loss: 1.3648, Val Acc: 0.6560\n",
      "Checkpoint saved: food_effnet_v23_07_0.656.pth\n",
      "Epoch 8/40\n",
      "  Train Loss: 1.5925, Train Acc: 0.5793\n",
      "  Val Loss: 1.3793, Val Acc: 0.6520\n",
      "Epoch 9/40\n",
      "  Train Loss: 1.5733, Train Acc: 0.5812\n",
      "  Val Loss: 1.3164, Val Acc: 0.6733\n",
      "Checkpoint saved: food_effnet_v23_09_0.673.pth\n",
      "Epoch 10/40\n",
      "  Train Loss: 1.5464, Train Acc: 0.5837\n",
      "  Val Loss: 1.2886, Val Acc: 0.6727\n",
      "Epoch 11/40\n",
      "  Train Loss: 1.4912, Train Acc: 0.5968\n",
      "  Val Loss: 1.3571, Val Acc: 0.6607\n",
      "Epoch 12/40\n",
      "  Train Loss: 1.5123, Train Acc: 0.5985\n",
      "  Val Loss: 1.3090, Val Acc: 0.6787\n",
      "Checkpoint saved: food_effnet_v23_12_0.679.pth\n",
      "Epoch 13/40\n",
      "  Train Loss: 1.4185, Train Acc: 0.6193\n",
      "  Val Loss: 1.2980, Val Acc: 0.6820\n",
      "Checkpoint saved: food_effnet_v23_13_0.682.pth\n",
      "Epoch 14/40\n",
      "  Train Loss: 1.4228, Train Acc: 0.6157\n",
      "  Val Loss: 1.3154, Val Acc: 0.6720\n",
      "Epoch 15/40\n",
      "  Train Loss: 1.3999, Train Acc: 0.6237\n",
      "  Val Loss: 1.2854, Val Acc: 0.6867\n",
      "Checkpoint saved: food_effnet_v23_15_0.687.pth\n",
      "Epoch 16/40\n",
      "  Train Loss: 1.3853, Train Acc: 0.6255\n",
      "  Val Loss: 1.2773, Val Acc: 0.6867\n",
      "Epoch 17/40\n",
      "  Train Loss: 1.3819, Train Acc: 0.6218\n",
      "  Val Loss: 1.3045, Val Acc: 0.6753\n",
      "Epoch 18/40\n",
      "  Train Loss: 1.4034, Train Acc: 0.6235\n",
      "  Val Loss: 1.3154, Val Acc: 0.6767\n",
      "Epoch 19/40\n",
      "  Train Loss: 1.3574, Train Acc: 0.6265\n",
      "  Val Loss: 1.2923, Val Acc: 0.6940\n",
      "Checkpoint saved: food_effnet_v23_19_0.694.pth\n",
      "Epoch 20/40\n",
      "  Train Loss: 1.3620, Train Acc: 0.6260\n",
      "  Val Loss: 1.3423, Val Acc: 0.6740\n",
      "Epoch 21/40\n",
      "  Train Loss: 1.3251, Train Acc: 0.6478\n",
      "  Val Loss: 1.3247, Val Acc: 0.6980\n",
      "Checkpoint saved: food_effnet_v23_21_0.698.pth\n",
      "Epoch 22/40\n",
      "  Train Loss: 1.3097, Train Acc: 0.6372\n",
      "  Val Loss: 1.3282, Val Acc: 0.6780\n",
      "Epoch 23/40\n",
      "  Train Loss: 1.3015, Train Acc: 0.6363\n",
      "  Val Loss: 1.3218, Val Acc: 0.6947\n",
      "Epoch 24/40\n",
      "  Train Loss: 1.2830, Train Acc: 0.6513\n",
      "  Val Loss: 1.3655, Val Acc: 0.6800\n",
      "Epoch 25/40\n",
      "  Train Loss: 1.2707, Train Acc: 0.6467\n",
      "  Val Loss: 1.3444, Val Acc: 0.6853\n",
      "Epoch 26/40\n",
      "  Train Loss: 1.2936, Train Acc: 0.6423\n",
      "  Val Loss: 1.4088, Val Acc: 0.6733\n",
      "Epoch 27/40\n",
      "  Train Loss: 1.3003, Train Acc: 0.6443\n",
      "  Val Loss: 1.3625, Val Acc: 0.6873\n",
      "Epoch 28/40\n",
      "  Train Loss: 1.2936, Train Acc: 0.6445\n",
      "  Val Loss: 1.4090, Val Acc: 0.6880\n",
      "Epoch 29/40\n",
      "  Train Loss: 1.2443, Train Acc: 0.6573\n",
      "  Val Loss: 1.4231, Val Acc: 0.6740\n",
      "Epoch 30/40\n",
      "  Train Loss: 1.2727, Train Acc: 0.6482\n",
      "  Val Loss: 1.4032, Val Acc: 0.6913\n",
      "Epoch 31/40\n",
      "  Train Loss: 1.2351, Train Acc: 0.6593\n",
      "  Val Loss: 1.3707, Val Acc: 0.6880\n",
      "Epoch 32/40\n",
      "  Train Loss: 1.2620, Train Acc: 0.6537\n",
      "  Val Loss: 1.4136, Val Acc: 0.6913\n",
      "Epoch 33/40\n",
      "  Train Loss: 1.2205, Train Acc: 0.6607\n",
      "  Val Loss: 1.4258, Val Acc: 0.6887\n",
      "Epoch 34/40\n",
      "  Train Loss: 1.2308, Train Acc: 0.6660\n",
      "  Val Loss: 1.4614, Val Acc: 0.6827\n",
      "Epoch 35/40\n",
      "  Train Loss: 1.2353, Train Acc: 0.6585\n",
      "  Val Loss: 1.4347, Val Acc: 0.6893\n",
      "Epoch 36/40\n",
      "  Train Loss: 1.2080, Train Acc: 0.6765\n",
      "  Val Loss: 1.3971, Val Acc: 0.6920\n",
      "Epoch 37/40\n",
      "  Train Loss: 1.2239, Train Acc: 0.6670\n",
      "  Val Loss: 1.4109, Val Acc: 0.6980\n",
      "Epoch 38/40\n",
      "  Train Loss: 1.2249, Train Acc: 0.6640\n",
      "  Val Loss: 1.4131, Val Acc: 0.6993\n",
      "Checkpoint saved: food_effnet_v23_38_0.699.pth\n",
      "Epoch 39/40\n",
      "  Train Loss: 1.2382, Train Acc: 0.6602\n",
      "  Val Loss: 1.4130, Val Acc: 0.7053\n",
      "Checkpoint saved: food_effnet_v23_39_0.705.pth\n",
      "Epoch 40/40\n",
      "  Train Loss: 1.2233, Train Acc: 0.6662\n",
      "  Val Loss: 1.4451, Val Acc: 0.6973\n",
      "\n",
      "drop_rate : 0.5\n",
      "Epoch 1/40\n",
      "  Train Loss: 3.2413, Train Acc: 0.2927\n",
      "  Val Loss: 2.2390, Val Acc: 0.4980\n",
      "Checkpoint saved: food_effnet_v23_01_0.498.pth\n",
      "Epoch 2/40\n",
      "  Train Loss: 2.3443, Train Acc: 0.4413\n",
      "  Val Loss: 1.8511, Val Acc: 0.5520\n",
      "Checkpoint saved: food_effnet_v23_02_0.552.pth\n",
      "Epoch 3/40\n",
      "  Train Loss: 2.0575, Train Acc: 0.4967\n",
      "  Val Loss: 1.6389, Val Acc: 0.5973\n",
      "Checkpoint saved: food_effnet_v23_03_0.597.pth\n",
      "Epoch 4/40\n",
      "  Train Loss: 1.9362, Train Acc: 0.5097\n",
      "  Val Loss: 1.5217, Val Acc: 0.6233\n",
      "Checkpoint saved: food_effnet_v23_04_0.623.pth\n",
      "Epoch 5/40\n",
      "  Train Loss: 1.8332, Train Acc: 0.5282\n",
      "  Val Loss: 1.4886, Val Acc: 0.6247\n",
      "Checkpoint saved: food_effnet_v23_05_0.625.pth\n",
      "Epoch 6/40\n",
      "  Train Loss: 1.8043, Train Acc: 0.5418\n",
      "  Val Loss: 1.4442, Val Acc: 0.6387\n",
      "Checkpoint saved: food_effnet_v23_06_0.639.pth\n",
      "Epoch 7/40\n",
      "  Train Loss: 1.7600, Train Acc: 0.5457\n",
      "  Val Loss: 1.4085, Val Acc: 0.6380\n",
      "Epoch 8/40\n",
      "  Train Loss: 1.6886, Train Acc: 0.5628\n",
      "  Val Loss: 1.3937, Val Acc: 0.6573\n",
      "Checkpoint saved: food_effnet_v23_08_0.657.pth\n",
      "Epoch 9/40\n",
      "  Train Loss: 1.6272, Train Acc: 0.5692\n",
      "  Val Loss: 1.3769, Val Acc: 0.6507\n",
      "Epoch 10/40\n",
      "  Train Loss: 1.6514, Train Acc: 0.5742\n",
      "  Val Loss: 1.3512, Val Acc: 0.6600\n",
      "Checkpoint saved: food_effnet_v23_10_0.660.pth\n",
      "Epoch 11/40\n",
      "  Train Loss: 1.5918, Train Acc: 0.5773\n",
      "  Val Loss: 1.3484, Val Acc: 0.6680\n",
      "Checkpoint saved: food_effnet_v23_11_0.668.pth\n",
      "Epoch 12/40\n",
      "  Train Loss: 1.5591, Train Acc: 0.5903\n",
      "  Val Loss: 1.3467, Val Acc: 0.6653\n",
      "Epoch 13/40\n",
      "  Train Loss: 1.6031, Train Acc: 0.5833\n",
      "  Val Loss: 1.3288, Val Acc: 0.6800\n",
      "Checkpoint saved: food_effnet_v23_13_0.680.pth\n",
      "Epoch 14/40\n",
      "  Train Loss: 1.5198, Train Acc: 0.5917\n",
      "  Val Loss: 1.3737, Val Acc: 0.6627\n",
      "Epoch 15/40\n",
      "  Train Loss: 1.4893, Train Acc: 0.6027\n",
      "  Val Loss: 1.3520, Val Acc: 0.6780\n",
      "Epoch 16/40\n",
      "  Train Loss: 1.4872, Train Acc: 0.5957\n",
      "  Val Loss: 1.3236, Val Acc: 0.6820\n",
      "Checkpoint saved: food_effnet_v23_16_0.682.pth\n",
      "Epoch 17/40\n",
      "  Train Loss: 1.4937, Train Acc: 0.5908\n",
      "  Val Loss: 1.3529, Val Acc: 0.6707\n",
      "Epoch 18/40\n",
      "  Train Loss: 1.5214, Train Acc: 0.5907\n",
      "  Val Loss: 1.3375, Val Acc: 0.6860\n",
      "Checkpoint saved: food_effnet_v23_18_0.686.pth\n",
      "Epoch 19/40\n",
      "  Train Loss: 1.4789, Train Acc: 0.6043\n",
      "  Val Loss: 1.3894, Val Acc: 0.6607\n",
      "Epoch 20/40\n",
      "  Train Loss: 1.4593, Train Acc: 0.6040\n",
      "  Val Loss: 1.3459, Val Acc: 0.6807\n",
      "Epoch 21/40\n",
      "  Train Loss: 1.4705, Train Acc: 0.6020\n",
      "  Val Loss: 1.3306, Val Acc: 0.6867\n",
      "Checkpoint saved: food_effnet_v23_21_0.687.pth\n",
      "Epoch 22/40\n",
      "  Train Loss: 1.4138, Train Acc: 0.6152\n",
      "  Val Loss: 1.3974, Val Acc: 0.6833\n",
      "Epoch 23/40\n",
      "  Train Loss: 1.4206, Train Acc: 0.6065\n",
      "  Val Loss: 1.3921, Val Acc: 0.6793\n",
      "Epoch 24/40\n",
      "  Train Loss: 1.4297, Train Acc: 0.6157\n",
      "  Val Loss: 1.4053, Val Acc: 0.6860\n",
      "Epoch 25/40\n",
      "  Train Loss: 1.4193, Train Acc: 0.6197\n",
      "  Val Loss: 1.3678, Val Acc: 0.6893\n",
      "Checkpoint saved: food_effnet_v23_25_0.689.pth\n",
      "Epoch 26/40\n",
      "  Train Loss: 1.3763, Train Acc: 0.6233\n",
      "  Val Loss: 1.4231, Val Acc: 0.6880\n",
      "Epoch 27/40\n",
      "  Train Loss: 1.3945, Train Acc: 0.6205\n",
      "  Val Loss: 1.3768, Val Acc: 0.6933\n",
      "Checkpoint saved: food_effnet_v23_27_0.693.pth\n",
      "Epoch 28/40\n",
      "  Train Loss: 1.3969, Train Acc: 0.6222\n",
      "  Val Loss: 1.4263, Val Acc: 0.6707\n",
      "Epoch 29/40\n",
      "  Train Loss: 1.4200, Train Acc: 0.6148\n",
      "  Val Loss: 1.3646, Val Acc: 0.7007\n",
      "Checkpoint saved: food_effnet_v23_29_0.701.pth\n",
      "Epoch 30/40\n",
      "  Train Loss: 1.3939, Train Acc: 0.6243\n",
      "  Val Loss: 1.4163, Val Acc: 0.6887\n",
      "Epoch 31/40\n",
      "  Train Loss: 1.3336, Train Acc: 0.6328\n",
      "  Val Loss: 1.4024, Val Acc: 0.6953\n",
      "Epoch 32/40\n",
      "  Train Loss: 1.4091, Train Acc: 0.6158\n",
      "  Val Loss: 1.4072, Val Acc: 0.6907\n",
      "Epoch 33/40\n",
      "  Train Loss: 1.3670, Train Acc: 0.6322\n",
      "  Val Loss: 1.4263, Val Acc: 0.6840\n",
      "Epoch 34/40\n",
      "  Train Loss: 1.3690, Train Acc: 0.6297\n",
      "  Val Loss: 1.4499, Val Acc: 0.6840\n",
      "Epoch 35/40\n",
      "  Train Loss: 1.3543, Train Acc: 0.6298\n",
      "  Val Loss: 1.4269, Val Acc: 0.6867\n",
      "Epoch 36/40\n",
      "  Train Loss: 1.2964, Train Acc: 0.6397\n",
      "  Val Loss: 1.4383, Val Acc: 0.6913\n",
      "Epoch 37/40\n",
      "  Train Loss: 1.3141, Train Acc: 0.6388\n",
      "  Val Loss: 1.4596, Val Acc: 0.6853\n",
      "Epoch 38/40\n",
      "  Train Loss: 1.3281, Train Acc: 0.6420\n",
      "  Val Loss: 1.4712, Val Acc: 0.6833\n",
      "Epoch 39/40\n",
      "  Train Loss: 1.3222, Train Acc: 0.6407\n",
      "  Val Loss: 1.4636, Val Acc: 0.6740\n",
      "Epoch 40/40\n",
      "  Train Loss: 1.3226, Train Acc: 0.6398\n",
      "  Val Loss: 1.5205, Val Acc: 0.6840\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "for drop_rate in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "    print(f\"drop_rate : {drop_rate}\")\n",
    "    model, optimizer = make_model(\n",
    "        learning_rate=0.001,\n",
    "        size_inner=500,\n",
    "        droprate=drop_rate\n",
    "    )\n",
    "    \n",
    "    train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f3e12e4-59bf-4a26-8ba9-0cb4aa878354",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T05:48:56.123531Z",
     "iopub.status.busy": "2025-12-28T05:48:56.119532Z",
     "iopub.status.idle": "2025-12-28T05:48:56.151324Z",
     "shell.execute_reply": "2025-12-28T05:48:56.150317Z",
     "shell.execute_reply.started": "2025-12-28T05:48:56.123531Z"
    }
   },
   "outputs": [],
   "source": [
    "# best drop rate : 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edf59f-f798-417d-9ef0-fceff6493e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final training on best hyperparameters\n",
    "# num_epochs = 50\n",
    "# model, optimizer = make_model(\n",
    "#     learning_rate=0.001,\n",
    "#     size_inner=500,\n",
    "#     droprate=0.3\n",
    "# )\n",
    "\n",
    "# train_and_evaluate(model, optimizer, train_loader, val_loader, criterion, num_epochs, device)\n",
    "\n",
    "\n",
    "# ## Exporting to ONNX for serverles model deployment\n",
    "# dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "\n",
    "# # Export to ONNX\n",
    "# onnx_path = \"food_classifier_mobilenet_v2.onnx\"\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     dummy_input,\n",
    "#     onnx_path,\n",
    "#     verbose=True,\n",
    "#     input_names=['input'],\n",
    "#     output_names=['output'],\n",
    "#     dynamic_axes={\n",
    "#         'input': {0: 'batch_size'},\n",
    "#         'output': {0: 'batch_size'}\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfeed13-b87e-4109-96aa-fbed19d1928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417969a-70e3-47e1-b507-bd970d6c41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## load model from a checkpoint\n",
    "# path = './clothing_v4_23_0.830.pth'\n",
    "# model = FoodClassifierEffNet(size_inner=100, droprate=0.2, num_classes=131)\n",
    "# model.load_state_dict(torch.load(path))\n",
    "# model.to(device)\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7bebe7-4b3d-4c07-8be6-e6b060826922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20b0fd4-c0ec-4174-9aab-0085385e1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = val_transforms(img)\n",
    "# batch_t = torch.unsqueeze(x, 0).to(device)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(batch_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b8325-76fa-4955-b0f6-9ffe84013152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict(zip(classes, output[0].to('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
